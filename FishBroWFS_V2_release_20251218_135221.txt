================================================================================
FishBroWFS_V2 Release Package
Generated: 2025-12-18 13:52:21
================================================================================

DIRECTORY STRUCTURE
--------------------------------------------------------------------------------
FishBroWFS_V2/
    â”œâ”€â”€ GM_Huang/
    â”‚   â”œâ”€â”€ clean_repo_caches.py
    â”‚   â””â”€â”€ release_tool.py
    â”œâ”€â”€ docs/
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ perf_direct.py
    â”‚   â””â”€â”€ perf_grid.py
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ FishBroWFS_V2/
    â”‚       â”œâ”€â”€ config/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ constants.py
    â”‚       â”‚   â””â”€â”€ dtypes.py
    â”‚       â”œâ”€â”€ data/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â””â”€â”€ layout.py
    â”‚       â”œâ”€â”€ engine/
    â”‚       â”‚   â”œâ”€â”€ kernels/
    â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”‚   â”œâ”€â”€ cursor_kernel.py
    â”‚       â”‚   â”‚   â””â”€â”€ reference_kernel.py
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ constants.py
    â”‚       â”‚   â”œâ”€â”€ constitution.py
    â”‚       â”‚   â”œâ”€â”€ engine_jit.py
    â”‚       â”‚   â”œâ”€â”€ matcher_core.py
    â”‚       â”‚   â”œâ”€â”€ metrics_from_fills.py
    â”‚       â”‚   â”œâ”€â”€ order_id.py
    â”‚       â”‚   â”œâ”€â”€ simulate.py
    â”‚       â”‚   â””â”€â”€ types.py
    â”‚       â”œâ”€â”€ indicators/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â””â”€â”€ numba_indicators.py
    â”‚       â”œâ”€â”€ perf/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ cost_model.py
    â”‚       â”‚   â”œâ”€â”€ profile_report.py
    â”‚       â”‚   â”œâ”€â”€ scenario_control.py
    â”‚       â”‚   â””â”€â”€ timers.py
    â”‚       â”œâ”€â”€ pipeline/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ funnel.py
    â”‚       â”‚   â”œâ”€â”€ metrics_schema.py
    â”‚       â”‚   â”œâ”€â”€ param_sort.py
    â”‚       â”‚   â”œâ”€â”€ runner_grid.py
    â”‚       â”‚   â”œâ”€â”€ stage0_runner.py
    â”‚       â”‚   â”œâ”€â”€ stage2_runner.py
    â”‚       â”‚   â””â”€â”€ topk.py
    â”‚       â”œâ”€â”€ stage0/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ ma_proxy.py
    â”‚       â”‚   â””â”€â”€ proxies.py
    â”‚       â”œâ”€â”€ strategy/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ entry_builder_nb.py
    â”‚       â”‚   â”œâ”€â”€ kernel.py
    â”‚       â”‚   â””â”€â”€ runner_single.py
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â””â”€â”€ version.py
    â””â”€â”€ tests/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ conftest.py
        â”œâ”€â”€ test_baseline_lock.py
        â”œâ”€â”€ test_builder_sparse_contract.py
        â”œâ”€â”€ test_data_layout.py
        â”œâ”€â”€ test_dtype_compression_contract.py
        â”œâ”€â”€ test_engine_constitution.py
        â”œâ”€â”€ test_engine_gaps_and_priority.py
        â”œâ”€â”€ test_engine_jit_active_book_contract.py
        â”œâ”€â”€ test_funnel_smoke_contract.py
        â”œâ”€â”€ test_funnel_topk_determinism.py
        â”œâ”€â”€ test_funnel_topk_no_human_contract.py
        â”œâ”€â”€ test_golden_kernel_verification.py
        â”œâ”€â”€ test_grid_runner_smoke.py
        â”œâ”€â”€ test_indicators_consistency.py
        â”œâ”€â”€ test_indicators_precompute_bit_exact.py
        â”œâ”€â”€ test_kernel_parity_contract.py
        â”œâ”€â”€ test_perf_breakdown_contract.py
        â”œâ”€â”€ test_perf_env_config_contract.py
        â”œâ”€â”€ test_perf_evidence_chain.py
        â”œâ”€â”€ test_perf_grid_profile_report.py
        â”œâ”€â”€ test_perf_obs_contract.py
        â”œâ”€â”€ test_perf_trigger_rate_contract.py
        â”œâ”€â”€ test_runner_grid_perf_observability.py
        â”œâ”€â”€ test_sparse_intents_contract.py
        â”œâ”€â”€ test_sparse_intents_mvp_contract.py
        â”œâ”€â”€ test_stage0_contract.py
        â”œâ”€â”€ test_stage0_ma_proxy.py
        â”œâ”€â”€ test_stage0_no_pnl_contract.py
        â”œâ”€â”€ test_stage0_proxies.py
        â”œâ”€â”€ test_stage0_proxy_rank_corr.py
        â”œâ”€â”€ test_stage2_params_influence.py
        â”œâ”€â”€ test_trigger_rate_param_subsample_contract.py
        â””â”€â”€ test_vectorization_parity.py

================================================================================
PYTHON FILES AND CODE
================================================================================


================================================================================
FILE: GM_Huang/clean_repo_caches.py
================================================================================

#!/usr/bin/env python3
from __future__ import annotations

import os
from pathlib import Path


def _is_under(path: Path, parent: Path) -> bool:
    try:
        path.resolve().relative_to(parent.resolve())
        return True
    except Exception:
        return False


def clean_repo_caches(repo_root: Path, dry_run: bool = False) -> tuple[int, int]:
    """
    Remove Python bytecode caches inside repo_root:
      - __pycache__ directories
      - *.pyc, *.pyo
    Does NOT touch anything outside repo_root.
    """
    removed_dirs = 0
    removed_files = 0

    for p in repo_root.rglob("__pycache__"):
        if not p.is_dir():
            continue
        if not _is_under(p, repo_root):
            continue
        if dry_run:
            print(f"[DRY] rmdir: {p}")
        else:
            for child in p.rglob("*"):
                try:
                    if child.is_file() or child.is_symlink():
                        child.unlink(missing_ok=True)
                        removed_files += 1
                except Exception:
                    pass
            try:
                p.rmdir()
                removed_dirs += 1
            except Exception:
                pass

    for ext in ("*.pyc", "*.pyo"):
        for p in repo_root.rglob(ext):
            if not p.is_file() and not p.is_symlink():
                continue
            if not _is_under(p, repo_root):
                continue
            if dry_run:
                print(f"[DRY] rm: {p}")
            else:
                try:
                    p.unlink(missing_ok=True)
                    removed_files += 1
                except Exception:
                    pass

    return removed_dirs, removed_files


def main() -> None:
    repo_root = Path(__file__).resolve().parents[1]
    dry_run = os.environ.get("FISHBRO_DRY_RUN", "").strip() == "1"
    removed_dirs, removed_files = clean_repo_caches(repo_root, dry_run=dry_run)

    if dry_run:
        print("[DRY] Done.")
        return

    print(f"Cleaned {removed_dirs} __pycache__ directories and {removed_files} bytecode files.")


if __name__ == "__main__":
    main()


================================================================================
FILE: GM_Huang/release_tool.py
================================================================================

#!/usr/bin/env python3
"""
Release tool for FishBroWFS_V2.

Generates release packages (txt or zip) excluding sensitive information like .git
"""

from __future__ import annotations

import os
import zipfile
from datetime import datetime
from pathlib import Path


def should_exclude(path: Path, repo_root: Path) -> bool:
    """
    Check if a path should be excluded from release.
    
    Excludes:
    - .git directory and all its contents
    - __pycache__ directories
    - .pyc, .pyo files
    - Common build/test artifacts
    """
    path_str = str(path)
    path_parts = path.parts
    
    # Exclude .git directory
    if '.git' in path_parts:
        return True
    
    # Exclude cache directories
    if '__pycache__' in path_parts:
        return True
    
    # Exclude bytecode files
    if path.suffix in ('.pyc', '.pyo'):
        return True
    
    # Exclude common build/test artifacts
    exclude_names = {
        '.pytest_cache', '.mypy_cache', '.ruff_cache',
        '.coverage', 'htmlcov', '.tox', 'dist', 'build',
        '*.egg-info', '.eggs'
    }
    
    for name in exclude_names:
        if name in path_parts or path.name.startswith(name.replace('*', '')):
            return True
    
    # Exclude GM_Huang itself from the release (optional, but makes sense)
    # Actually, let's include it since it's part of the project structure
    
    return False


def get_python_files(repo_root: Path) -> list[Path]:
    """Get all Python files in the repository, excluding sensitive paths."""
    python_files = []
    
    for py_file in repo_root.rglob('*.py'):
        if not should_exclude(py_file, repo_root):
            python_files.append(py_file)
    
    return sorted(python_files)


def get_directory_structure(repo_root: Path) -> str:
    """Generate a text representation of directory structure."""
    lines = []
    
    def walk_tree(directory: Path, prefix: str = '', is_last: bool = True):
        """Recursively walk directory tree and build structure."""
        if should_exclude(directory, repo_root):
            return
        
        # Skip if it's the repo root itself
        if directory == repo_root:
            lines.append(f"{directory.name}/")
        else:
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            lines.append(f"{prefix}{connector}{directory.name}/")
        
        # Get subdirectories and files
        try:
            items = sorted([p for p in directory.iterdir() 
                          if not should_exclude(p, repo_root)])
            dirs = [p for p in items if p.is_dir()]
            files = [p for p in items if p.is_file() and p.suffix == '.py']
            
            # Process directories
            for i, item in enumerate(dirs):
                is_last_item = (i == len(dirs) - 1) and len(files) == 0
                extension = "    " if is_last else "â”‚   "
                walk_tree(item, prefix + extension, is_last_item)
            
            # Process Python files
            for i, file in enumerate(files):
                is_last_item = i == len(files) - 1
                connector = "â””â”€â”€ " if is_last_item else "â”œâ”€â”€ "
                lines.append(f"{prefix}{'    ' if is_last else 'â”‚   '}{connector}{file.name}")
        except PermissionError:
            pass
    
    walk_tree(repo_root)
    return "\n".join(lines)


def generate_release_txt(repo_root: Path, output_path: Path) -> None:
    """Generate a text file with directory structure and Python code."""
    print(f"Generating release TXT: {output_path}")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        # Header
        f.write("=" * 80 + "\n")
        f.write(f"FishBroWFS_V2 Release Package\n")
        f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
        
        # Directory structure
        f.write("DIRECTORY STRUCTURE\n")
        f.write("-" * 80 + "\n")
        f.write(get_directory_structure(repo_root))
        f.write("\n\n")
        
        # Python files and their content
        f.write("=" * 80 + "\n")
        f.write("PYTHON FILES AND CODE\n")
        f.write("=" * 80 + "\n\n")
        
        python_files = get_python_files(repo_root)
        
        for py_file in python_files:
            relative_path = py_file.relative_to(repo_root)
            f.write(f"\n{'=' * 80}\n")
            f.write(f"FILE: {relative_path}\n")
            f.write(f"{'=' * 80}\n\n")
            
            try:
                content = py_file.read_text(encoding='utf-8')
                f.write(content)
                if not content.endswith('\n'):
                    f.write('\n')
            except Exception as e:
                f.write(f"[ERROR: Could not read file: {e}]\n")
            
            f.write("\n")
    
    print(f"âœ“ Release TXT generated: {output_path}")


def generate_release_zip(repo_root: Path, output_path: Path) -> None:
    """Generate a zip file of the project, excluding sensitive information."""
    print(f"Generating release ZIP: {output_path}")
    
    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        python_files = get_python_files(repo_root)
        
        # Also include non-Python files that are important
        important_extensions = {'.toml', '.txt', '.md', '.yml', '.yaml'}
        important_files = []
        
        for ext in important_extensions:
            for file in repo_root.rglob(f'*{ext}'):
                if not should_exclude(file, repo_root):
                    important_files.append(file)
        
        all_files = sorted(set(python_files + important_files))
        
        for file_path in all_files:
            relative_path = file_path.relative_to(repo_root)
            zipf.write(file_path, relative_path)
            print(f"  Added: {relative_path}")
    
    print(f"âœ“ Release ZIP generated: {output_path}")
    print(f"  Total files: {len(all_files)}")


def main() -> None:
    """Main entry point."""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python release_tool.py [txt|zip]")
        sys.exit(1)
    
    mode = sys.argv[1].lower()
    
    # Get repo root (parent of GM_Huang)
    script_dir = Path(__file__).resolve().parent
    repo_root = script_dir.parent
    
    # Generate output filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    project_name = repo_root.name
    
    if mode == 'txt':
        output_path = repo_root / f"{project_name}_release_{timestamp}.txt"
        generate_release_txt(repo_root, output_path)
    elif mode == 'zip':
        output_path = repo_root / f"{project_name}_release_{timestamp}.zip"
        generate_release_zip(repo_root, output_path)
    else:
        print(f"Unknown mode: {mode}. Use 'txt' or 'zip'")
        sys.exit(1)


if __name__ == "__main__":
    main()



================================================================================
FILE: scripts/perf_direct.py
================================================================================

#!/usr/bin/env python3
"""
FishBro WFS - Direct Engine Benchmark
ç”¨é€”: ç¹žéŽæ‰€æœ‰ Harness/Subprocess è¤‡é›œåº¦ï¼Œç›´æŽ¥ import engine æ¸¬é€Ÿ
"""
import sys
import time
import gc
import numpy as np
from pathlib import Path

# 1. å¼·åˆ¶è¨­å®šè·¯å¾‘ (æŒ‡å‘ src)
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

print(f"python_path: {sys.path[0]}")

try:
    # Correct src-based package name in this repo:
    # src/FishBroWFS_V2/pipeline/runner_grid.py
    from FishBroWFS_V2.pipeline.runner_grid import run_grid  # type: ignore
    print("âœ… Engine imported successfully (FishBroWFS_V2.pipeline.runner_grid).")
except ImportError as e:
    print(f"âŒ FATAL: Cannot import engine: {e}")
    sys.exit(1)

# 2. è¨­å®šè¦æ¨¡ (å°è¦æ¨¡ Smoke Test)
BARS = 20_000
PARAMS = 5_000
HOT_RUNS = 5

def generate_data(n_bars, n_params):
    print(f"generating data: {n_bars} bars, {n_params} params...")
    rng = np.random.default_rng(42)
    
    close = 10000 + np.cumsum(rng.standard_normal(n_bars)) * 10
    # ä½¿ç”¨ np.abs é¿å… AttributeError
    high = close + np.abs(rng.standard_normal(n_bars)) * 5
    low = close - np.abs(rng.standard_normal(n_bars)) * 5
    open_ = (high + low) / 2 + rng.standard_normal(n_bars)
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # Generate Params (runner_grid contract: params_matrix must be (n, >=3))
    w1 = rng.integers(10, 100, size=n_params)
    w2 = rng.integers(5, 50, size=n_params)
    w3 = rng.integers(2, 30, size=n_params)
    params = np.column_stack((w1, w2, w3))
    
    # Layout check
    data_arrays = [open_, high, low, close, params]
    final_arrays = []
    for arr in data_arrays:
        arr = arr.astype(np.float64)
        if not arr.flags['C_CONTIGUOUS']:
            arr = np.ascontiguousarray(arr)
        final_arrays.append(arr)
        
    return final_arrays[0], final_arrays[1], final_arrays[2], final_arrays[3], final_arrays[4]

def main():
    opens, highs, lows, closes, params = generate_data(BARS, PARAMS)
    
    print("-" * 40)
    print(f"Start Benchmark: {BARS} bars x {PARAMS} params")
    print("-" * 40)

    # COLD RUN
    print("ðŸ¥¶ Cold run (compiling)...", end="", flush=True)
    t0 = time.perf_counter()
    _ = run_grid(
        open_=opens,
        high=highs,
        low=lows,
        close=closes,
        params_matrix=params,
        commission=0.0,
        slip=0.0,
        sort_params=False,
    )
    print(f" Done in {time.perf_counter() - t0:.4f}s")

    # HOT RUNS
    times = []
    print(f"ðŸ”¥ Hot runs ({HOT_RUNS} times, GC off)...")
    gc.disable()
    for i in range(HOT_RUNS):
        t_start = time.perf_counter()
        _ = run_grid(
            open_=opens,
            high=highs,
            low=lows,
            close=closes,
            params_matrix=params,
            commission=0.0,
            slip=0.0,
            sort_params=False,
        )
        dt = time.perf_counter() - t_start
        times.append(dt)
        print(f"   Run {i+1}: {dt:.4f}s")
    gc.enable()
    
    min_time = min(times)
    total_ops = BARS * PARAMS
    tput = total_ops / min_time
    
    print("-" * 40)
    print(f"MIN TIME:   {min_time:.4f}s")
    print(f"THROUGHPUT: {int(tput):,} pair-bars/sec")
    print("-" * 40)

if __name__ == "__main__":
    main()


================================================================================
FILE: scripts/perf_grid.py
================================================================================

#!/usr/bin/env python3
"""
FishBro WFS Perf Harness (Red Team Spec v1.0)
ç‹€æ…‹: âœ… File-based IPC / JIT-First / Observable
ç”¨é€”: é‡æ¸¬ JIT Grid Runner çš„ç©©æ…‹åžåé‡ (Steady-state Throughput)

ä¿®æ­£ç´€éŒ„:
- v1.1: ä¿®å¾© numpy generator abs éŒ¯èª¤
- v1.2: Hotfix: è§£æ±º subprocess Import Errorï¼Œå¼·åˆ¶æ³¨å…¥ PYTHONPATH ä¸¦å¢žå¼· debug info
"""
import os
import sys
import time
import gc
import json
import cProfile
import argparse
import subprocess
import tempfile
import statistics
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional

import numpy as np

from FishBroWFS_V2.perf.cost_model import estimate_seconds
from FishBroWFS_V2.perf.profile_report import _format_profile_report

# ==========================================
# 1. é…ç½®èˆ‡å¸¸æ•¸ (Tiers)
# ==========================================

@dataclass
class PerfConfig:
    name: str
    n_bars: int
    n_params: int
    hot_runs: int
    timeout: int
    disable_jit: bool
    sort_params: bool

# Baseline Tier (default): Fast, suitable for commit-to-commit comparison
# Can be overridden via FISHBRO_PERF_BARS and FISHBRO_PERF_PARAMS env vars
TIER_JIT_BARS = int(os.environ.get("FISHBRO_PERF_BARS", "20000"))
TIER_JIT_PARAMS = int(os.environ.get("FISHBRO_PERF_PARAMS", "1000"))
TIER_JIT_HOT_RUNS = int(os.environ.get("FISHBRO_PERF_HOTRUNS", "5"))
TIER_JIT_TIMEOUT = int(os.environ.get("FISHBRO_PERF_TIMEOUT_S", "600"))

# Stress Tier: Optional, for extreme throughput testing (requires larger timeout or skip-cold)
TIER_STRESS_BARS = int(os.environ.get("FISHBRO_PERF_STRESS_BARS", "200000"))
TIER_STRESS_PARAMS = int(os.environ.get("FISHBRO_PERF_STRESS_PARAMS", "10000"))

TIER_TOY_BARS = 2_000
TIER_TOY_PARAMS = 10
TIER_TOY_HOT_RUNS = 1
TIER_TOY_TIMEOUT = 60

# Warmup compile tier (for skip-cold mode)
TIER_WARMUP_COMPILE_BARS = 2_000
TIER_WARMUP_COMPILE_PARAMS = 200

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# ==========================================
# 2. è³‡æ–™ç”Ÿæˆ (Deterministic)
# ==========================================

def generate_synthetic_data(n_bars: int, seed: int = 42) -> Dict[str, np.ndarray]:
    """
    Generate synthetic OHLC data for perf harness.
    
    Uses float32 for Stage0/perf optimization (memory bandwidth reduction).
    """
    from FishBroWFS_V2.config.dtypes import PRICE_DTYPE_STAGE0
    
    rng = np.random.default_rng(seed)
    close = 10000 + np.cumsum(rng.standard_normal(n_bars)) * 10
    high = close + np.abs(rng.standard_normal(n_bars)) * 5
    low = close - np.abs(rng.standard_normal(n_bars)) * 5
    open_ = (high + low) / 2 + rng.standard_normal(n_bars)
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # Use float32 for perf harness (Stage0 optimization)
    data = {
        "open": open_.astype(PRICE_DTYPE_STAGE0),
        "high": high.astype(PRICE_DTYPE_STAGE0),
        "low": low.astype(PRICE_DTYPE_STAGE0),
        "close": close.astype(PRICE_DTYPE_STAGE0),
    }
    
    for k, v in data.items():
        if not v.flags['C_CONTIGUOUS']:
            data[k] = np.ascontiguousarray(v, dtype=PRICE_DTYPE_STAGE0)
    return data

def generate_params(n_params: int, seed: int = 999) -> np.ndarray:
    """
    Generate parameter matrix for perf harness.
    
    Uses float32 for Stage0 optimization (memory bandwidth reduction).
    """
    from FishBroWFS_V2.config.dtypes import PRICE_DTYPE_STAGE0
    
    rng = np.random.default_rng(seed)
    w1 = rng.integers(10, 100, size=n_params)
    w2 = rng.integers(5, 50, size=n_params)
    # runner_grid contract: params_matrix must be (n, >=3)
    # Provide a minimal 3-column schema for perf harness.
    w3 = rng.integers(2, 30, size=n_params)
    params = np.column_stack((w1, w2, w3)).astype(PRICE_DTYPE_STAGE0)
    if not params.flags['C_CONTIGUOUS']:
        params = np.ascontiguousarray(params, dtype=PRICE_DTYPE_STAGE0)
    return params

# ==========================================
# 3. Worker é‚è¼¯ (Child Process)
# ==========================================

def worker_log(msg: str):
    print(f"[worker] {msg}", flush=True)


def _env_flag(name: str) -> bool:
    return os.environ.get(name, "").strip() == "1"


def _env_int(name: str, default: int) -> int:
    try:
        return int(os.environ.get(name, str(default)))
    except Exception:
        return default


def _env_float(name: str, default: float) -> float:
    try:
        return float(os.environ.get(name, str(default)))
    except Exception:
        return default


# NOTE: _format_profile_report moved to src/FishBroWFS_V2/perf/profile_report.py

def _run_microbench_numba_indicators(closes: np.ndarray, hot_runs: int) -> Dict[str, Any]:
    """
    Perf-only microbench:
      - Prove Numba is active in worker process.
      - Measure pure numeric kernels (no Python object loop) baseline.
    """
    try:
        import numba as nb  # type: ignore
    except Exception:  # pragma: no cover
        return {"microbench": "numba_missing"}

    from FishBroWFS_V2.indicators import numba_indicators as ni  # type: ignore

    # Use a fixed window; keep deterministic and cheap.
    length = 14
    x = np.ascontiguousarray(closes, dtype=np.float64)

    # Warmup compile (first call triggers compilation if JIT enabled).
    _ = ni.rolling_max(x, length)

    # Hot runs
    times: List[float] = []
    for _i in range(max(1, hot_runs)):
        t0 = time.perf_counter()
        _ = ni.rolling_max(x, length)
        times.append(time.perf_counter() - t0)

    best = min(times) if times else 0.0
    n = int(x.shape[0])
    # rolling_max visits each element once -> treat as "ops" ~= n
    tput = (n / best) if best > 0 else 0.0
    return {
        "microbench": "rolling_max",
        "n": n,
        "best_s": best,
        "ops_per_s": tput,
        "nb_disable_jit": int(getattr(nb.config, "DISABLE_JIT", -1)),
    }


def run_worker(
    npz_path: str,
    hot_runs: int,
    skip_cold: bool = False,
    warmup_bars: int = 0,
    warmup_params: int = 0,
    microbench: bool = False,
):
    try:
        # Stage P2-1.6: Parse trigger_rate env var
        trigger_rate = _env_float("FISHBRO_PERF_TRIGGER_RATE", 1.0)
        if trigger_rate < 0.0 or trigger_rate > 1.0:
            raise ValueError(f"FISHBRO_PERF_TRIGGER_RATE must be in [0, 1], got {trigger_rate}")
        worker_log(f"trigger_rate={trigger_rate}")
        
        worker_log(f"Starting. Loading input: {npz_path}")
        
        with np.load(npz_path, allow_pickle=False) as data:
            opens = data['open']
            highs = data['high']
            lows = data['low']
            closes = data['close']
            params = data['params']
            
        worker_log(f"Data loaded. Bars: {len(opens)}, Params: {len(params)}")

        if microbench:
            worker_log("MICROBENCH enabled: running numba indicator microbench.")
            res = _run_microbench_numba_indicators(closes, hot_runs=hot_runs)
            print("__RESULT_JSON_START__")
            print(json.dumps({"mode": "microbench", "result": res}))
            print("__RESULT_JSON_END__")
            return
        
        try:
            # Phase 3B Grid Runner (correct target)
            # src/FishBroWFS_V2/pipeline/runner_grid.py
            from FishBroWFS_V2.pipeline.runner_grid import run_grid  # type: ignore
            worker_log("Grid runner imported successfully (FishBroWFS_V2.pipeline.runner_grid).")
            # Enable runner_grid observability payload in returned dict (timings + jit truth + counts).
            os.environ["FISHBRO_PROFILE_GRID"] = "1"

            # ---- JIT truth report (perf-only) ----
            worker_log(f"ENV NUMBA_DISABLE_JIT={os.environ.get('NUMBA_DISABLE_JIT','')!r}")
            try:
                import numba as _nb  # type: ignore
                worker_log(f"Numba present. nb.config.DISABLE_JIT={getattr(_nb.config,'DISABLE_JIT',None)!r}")
            except Exception as _e:
                worker_log(f"Numba import failed: {_e!r}")

            # run_grid itself might be Python; report what it is.
            worker_log(f"run_grid type={type(run_grid)} has_signatures={hasattr(run_grid,'signatures')}")
            if hasattr(run_grid, "signatures"):
                worker_log(f"run_grid.signatures(before)={getattr(run_grid,'signatures',None)!r}")
            # --------------------------------------
        except ImportError as e:
            worker_log(f"FATAL: Import grid runner failed: {e!r}")
            
            # --- DEBUG INFO ---
            worker_log(f"Current sys.path: {sys.path}")
            src_path = Path(__file__).resolve().parent.parent / "src"
            if src_path.exists():
                worker_log(f"Listing {src_path}:")
                try:
                    for p in src_path.iterdir():
                        worker_log(f" - {p.name}")
                        if p.is_dir() and (p / "__init__.py").exists():
                             worker_log(f"   (package content): {[sub.name for sub in p.iterdir()]}")
                except Exception as ex:
                    worker_log(f"   Error listing dir: {ex}")
            else:
                worker_log(f"Src path not found at: {src_path}")
            # ------------------
            sys.exit(1)
        
        # Warmup run (perf-only): compile/JIT on a tiny slice so the real run measures steady-state.
        # IMPORTANT: respect CLI-provided warmup_{bars,params}. If 0, fall back to defaults.
        if warmup_bars and warmup_bars > 0:
            wb = min(int(warmup_bars), len(opens))
        else:
            wb = min(2000, len(opens))

        if warmup_params and warmup_params > 0:
            wp = min(int(warmup_params), len(params))
        else:
            wp = min(200, len(params))
        if wb >= 10 and wp >= 10:
            worker_log(f"Starting WARMUP run (bars={wb}, params={wp})...")
            _ = run_grid(
                open_=opens[:wb],
                high=highs[:wb],
                low=lows[:wb],
                close=closes[:wb],
                params_matrix=params[:wp],
                commission=0.0,
                slip=0.0,
                sort_params=False,
            )
            worker_log("WARMUP finished.")
            if hasattr(run_grid, "signatures"):
                worker_log(f"run_grid.signatures(after)={getattr(run_grid,'signatures',None)!r}")
        
        lane_sort = os.environ.get("FISHBRO_PERF_LANE_SORT", "0").strip() == "1"
        lane_id = os.environ.get("FISHBRO_PERF_LANE_ID", "?").strip()
        do_profile = _env_flag("FISHBRO_PERF_PROFILE")
        topn = _env_int("FISHBRO_PERF_PROFILE_TOP", 40)
        mode = os.environ.get("FISHBRO_PERF_PROFILE_MODE", "").strip()
        jit_enabled = os.environ.get("NUMBA_DISABLE_JIT", "").strip() != "1"
        cold_time = 0.0
        if skip_cold:
            # Skip-cold mode: warmup already done, skip full cold run
            worker_log("Skip-cold mode: skipping full cold run (warmup already completed)")
        else:
            # Full cold run
            worker_log("Starting COLD run...")
            t0 = time.perf_counter()
            _ = run_grid(
                open_=opens,
                high=highs,
                low=lows,
                close=closes,
                params_matrix=params,
                commission=0.0,
                slip=0.0,
                sort_params=lane_sort,
            )
            cold_time = time.perf_counter() - t0
            worker_log(f"COLD run finished: {cold_time:.4f}s")
        
        worker_log(f"Starting {hot_runs} HOT runs (GC disabled)...")
        hot_times = []
        last_out: Optional[Dict[str, Any]] = None
        gc.disable()
        try:
            for i in range(hot_runs):
                t_start = time.perf_counter()
                if do_profile and i == 0:
                    pr = cProfile.Profile()
                    pr.enable()
                    last_out = run_grid(
                        open_=opens,
                        high=highs,
                        low=lows,
                        close=closes,
                        params_matrix=params,
                        commission=0.0,
                        slip=0.0,
                        sort_params=lane_sort,
                    )
                    pr.disable()
                    print(
                        _format_profile_report(
                            lane_id=lane_id,
                            n_bars=int(len(opens)),
                            n_params=int(len(params)),
                            jit_enabled=bool(jit_enabled),
                            sort_params=bool(lane_sort),
                            topn=int(topn),
                            mode=mode,
                            pr=pr,
                        ),
                        end="",
                    )
                else:
                    last_out = run_grid(
                        open_=opens,
                        high=highs,
                        low=lows,
                        close=closes,
                        params_matrix=params,
                        commission=0.0,
                        slip=0.0,
                        sort_params=lane_sort,
                    )
                t_end = time.perf_counter()
                hot_times.append(t_end - t_start)
        finally:
            gc.enable()
        
        avg_hot = statistics.mean(hot_times) if hot_times else 0.0
        min_hot = min(hot_times) if hot_times else 0.0
        
        result = {
            "cold_time": cold_time,
            "hot_times": hot_times,
            "avg_hot_time": avg_hot,
            "min_hot_time": min_hot,
            "n_bars": len(opens),
            "n_params": len(params),
            "throughput": (len(opens) * len(params)) / min_hot if min_hot > 0 else 0,
        }

        # Attach runner_grid observability payload (timings + jit truth + counts)
        if isinstance(last_out, dict) and "perf" in last_out:
            result["perf"] = last_out["perf"]
            # Stage P2-1.6: Add trigger_rate_configured to perf dict
            if isinstance(result["perf"], dict):
                result["perf"]["trigger_rate_configured"] = float(trigger_rate)
        
        # Stage P2-1.8: Debug timing keys (only if PERF_DEBUG=1)
        if os.environ.get("PERF_DEBUG", "").strip() == "1":
            perf_keys = sorted(result.get("perf", {}).keys()) if isinstance(result.get("perf"), dict) else []
            worker_log(f"DEBUG: perf keys count={len(perf_keys)}, has t_total_kernel_s={'t_total_kernel_s' in perf_keys}")
            if len(perf_keys) > 0:
                worker_log(f"DEBUG: perf keys sample: {perf_keys[:20]}")
        
        print(f"__RESULT_JSON_START__")
        print(json.dumps(result))
        print(f"__RESULT_JSON_END__")
        
    except Exception as e:
        worker_log(f"CRASH: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

# ==========================================
# 4. Controller é‚è¼¯ (Host Process)
# ==========================================

def run_lane(
    lane_id: int,
    cfg: PerfConfig,
    tmp_dir: str,
    ohlc_data: Dict[str, np.ndarray],
    microbench: bool = False,
) -> Dict[str, Any]:
    print(f"\n>>> Running Lane {lane_id}: {cfg.name}")
    print(f"    Config: Bars={cfg.n_bars}, Params={cfg.n_params}, JIT={not cfg.disable_jit}, Sort={cfg.sort_params}")
    
    params = generate_params(cfg.n_params)
    # Do not pre-sort here; sorting behavior must be owned by runner_grid(sort_params=...).
    # For no-sort lane, we shuffle to simulate random access order.
    if not cfg.sort_params:
        np.random.shuffle(params)
        print("    Params shuffled (random access simulation).")
    else:
        print("    Params left unsorted; runner_grid(sort_params=True) will apply cache-friendly sort.")
        
    npz_path = os.path.join(tmp_dir, f"input_lane_{lane_id}.npz")
    np.savez_compressed(
        npz_path, 
        open=ohlc_data["open"][:cfg.n_bars],
        high=ohlc_data["high"][:cfg.n_bars],
        low=ohlc_data["low"][:cfg.n_bars],
        close=ohlc_data["close"][:cfg.n_bars],
        params=params
    )
    
    env = os.environ.copy()
    
    # é—œéµä¿®æ­£: å¼·åˆ¶æ³¨å…¥ PYTHONPATH ç¢ºä¿å­é€²ç¨‹çœ‹å¾—åˆ° src
    src_path = str(PROJECT_ROOT / "src")
    if "PYTHONPATH" in env:
        env["PYTHONPATH"] = f"{src_path}:{env['PYTHONPATH']}"
    else:
        env["PYTHONPATH"] = src_path
        
    if cfg.disable_jit:
        env["NUMBA_DISABLE_JIT"] = "1"
    else:
        env.pop("NUMBA_DISABLE_JIT", None)
    
    # Stage P2-1.6: Pass FISHBRO_PERF_TRIGGER_RATE to worker if set
    # (env.copy() already includes it, but we ensure it's explicitly passed)
    trigger_rate_env = os.environ.get("FISHBRO_PERF_TRIGGER_RATE")
    if trigger_rate_env:
        env["FISHBRO_PERF_TRIGGER_RATE"] = trigger_rate_env
        
    # Build worker command
    cmd = [
        sys.executable,
        __file__,
        "--worker",
        "--input",
        npz_path,
        "--hot-runs",
        str(cfg.hot_runs),
    ]
    if microbench:
        cmd.append("--microbench")
    # Pass lane sort flag to worker via env (avoid CLI churn)
    env["FISHBRO_PERF_LANE_SORT"] = "1" if cfg.sort_params else "0"
    env["FISHBRO_PERF_LANE_ID"] = str(lane_id)
    
    # Add skip-cold and warmup params if needed
    skip_cold = os.environ.get("FISHBRO_PERF_SKIP_COLD", "").lower() == "true"
    if skip_cold:
        cmd.extend(["--skip-cold"])
        warmup_bars = int(os.environ.get("FISHBRO_PERF_WARMUP_BARS", str(TIER_WARMUP_COMPILE_BARS)))
        warmup_params = int(os.environ.get("FISHBRO_PERF_WARMUP_PARAMS", str(TIER_WARMUP_COMPILE_PARAMS)))
        cmd.extend(["--warmup-bars", str(warmup_bars), "--warmup-params", str(warmup_params)])
    
    try:
        proc = subprocess.run(
            cmd,
            env=env,
            capture_output=True,
            text=True,
            timeout=cfg.timeout,
            check=True
        )
        
        stdout = proc.stdout
        # Print worker stdout (includes JIT truth report)
        print(stdout, end="")
        
        result_json = None
        lines = stdout.splitlines()
        capture = False
        json_str = ""
        
        for line in lines:
            if line.strip() == "__RESULT_JSON_END__":
                capture = False
            if capture:
                json_str += line
            if line.strip() == "__RESULT_JSON_START__":
                capture = True
                
        if json_str:
            result_json = json.loads(json_str)
            
            # Phase 3.0-C: FAIL-FAST defense - detect fallback to object mode
            strict_arrays = os.environ.get("FISHBRO_PERF_STRICT_ARRAYS", "1").strip() == "1"
            if strict_arrays and isinstance(result_json, dict):
                perf = result_json.get("perf")
                if isinstance(perf, dict):
                    intent_mode = perf.get("intent_mode")
                    if intent_mode != "arrays":
                        # Handle None or any non-"arrays" value
                        intent_mode_str = str(intent_mode) if intent_mode is not None else "None"
                        error_msg = (
                            f"ERROR: intent_mode expected 'arrays' but got '{intent_mode_str}' (lane {lane_id})\n"
                            f"This indicates the kernel fell back to object mode, which is a performance regression.\n"
                            f"To disable this check, set FISHBRO_PERF_STRICT_ARRAYS=0"
                        )
                        print(f"âŒ {error_msg}", file=sys.stderr)
                        raise RuntimeError(error_msg)
            
            return result_json
        else:
            print("âŒ Error: Worker finished but no JSON result found.")
            print("--- Worker Stdout ---")
            print(stdout)
            print("--- Worker Stderr ---")
            print(proc.stderr)
            return {}
            
    except subprocess.TimeoutExpired as e:
        print(f"âŒ Error: Lane {lane_id} Timeout ({cfg.timeout}s).")
        if e.stdout: print(e.stdout)
        if e.stderr: print(e.stderr)
        return {}
    except subprocess.CalledProcessError as e:
        print(f"âŒ Error: Lane {lane_id} Crashed (Exit {e.returncode}).")
        print("--- Worker Stdout ---")
        print(e.stdout)
        print("--- Worker Stderr ---")
        print(e.stderr)
        return {}
    except Exception as e:
        print(f"âŒ Error: System error {e}")
        return {}

def print_report(results: List[Dict[str, Any]]):
    print("\n\n=== FishBro WFS Perf Harness Report ===")
    print("| Lane | Mode | Sort | Bars | Params | Cold(s) | Hot(s) | Tput (Ops/s) | Speedup |")
    print("|---|---|---|---|---|---|---|---|---|")
    
    jit_no_sort_tput = 0
    for r in results:
        if not r or "res" not in r or "lane_id" not in r: continue
        lane_id = r.get('lane_id', 0)
        name = r.get('name', 'Unknown')
        bars = r['res'].get('n_bars', 0)
        params = r['res'].get('n_params', 0)
        cold = r['res'].get('cold_time', 0)
        hot = r['res'].get('min_hot_time', 0)
        tput = r['res'].get('throughput', 0)
        
        if lane_id == 3:
            jit_no_sort_tput = tput
            speedup = "1.0x (Base)"
        elif jit_no_sort_tput > 0 and tput > 0:
            ratio = tput / jit_no_sort_tput
            speedup = f"{ratio:.2f}x"
        else:
            speedup = "-"
            
        mode = "Py" if r.get("disable_jit", False) else "JIT"
        sort = "Yes" if r.get("sort_params", False) else "No"
        print(f"| {lane_id} | {mode} | {sort} | {bars} | {params} | {cold:.4f} | {hot:.4f} | {int(tput):,} | {speedup} |")
    print("\nNote: Tput = (Bars * Params) / Min Hot Run Time")
    
    # Phase 4 Stage E: Cost Model Output
    print("\n=== Cost Model (Predictable Cost Estimation) ===")
    for r in results:
        if not r or "res" not in r or "lane_id" not in r: continue
        lane_id = r.get('lane_id', 0)
        res = r.get('res', {})
        bars = res.get('n_bars', 0)
        params = res.get('n_params', 0)
        min_hot_time = res.get('min_hot_time', 0)
        
        if min_hot_time > 0 and params > 0:
            # Calculate cost per parameter (milliseconds)
            cost_ms_per_param = (min_hot_time / params) * 1000.0
            
            # Calculate params per second
            params_per_sec = params / min_hot_time
            
            # Estimate time for 50k params
            estimated_time_for_50k_params = estimate_seconds(
                bars=bars,
                params=50000,
                cost_ms_per_param=cost_ms_per_param,
            )
            
            # Output cost model fields (stdout)
            print(f"\nLane {lane_id} Cost Model:")
            print(f"  bars: {bars}")
            print(f"  params: {params}")
            print(f"  best_time_s: {min_hot_time:.6f}")
            print(f"  params_per_sec: {params_per_sec:,.2f}")
            print(f"  cost_ms_per_param: {cost_ms_per_param:.6f}")
            print(f"  estimated_time_for_50k_params: {estimated_time_for_50k_params:.2f}")
            
            # Stage P2-1.5: Entry Sparse Observability
            perf = res.get('perf', {})
            if isinstance(perf, dict):
                entry_valid_mask_sum = perf.get('entry_valid_mask_sum')
                entry_intents_total = perf.get('entry_intents_total')
                entry_intents_per_bar_avg = perf.get('entry_intents_per_bar_avg')
                intents_total_reported = perf.get('intents_total_reported')
                trigger_rate_configured = perf.get('trigger_rate_configured')
                
                # Always output if perf dict exists (fields should always be present)
                if entry_valid_mask_sum is not None or entry_intents_total is not None:
                    print(f"\nLane {lane_id} Entry Sparse Observability:")
                    # Stage P2-1.6: Display trigger_rate_configured
                    if trigger_rate_configured is not None:
                        print(f"  trigger_rate_configured: {trigger_rate_configured:.6f}")
                    print(f"  entry_valid_mask_sum: {entry_valid_mask_sum if entry_valid_mask_sum is not None else 0}")
                    print(f"  entry_intents_total: {entry_intents_total if entry_intents_total is not None else 0}")
                    if entry_intents_per_bar_avg is not None:
                        print(f"  entry_intents_per_bar_avg: {entry_intents_per_bar_avg:.6f}")
                    else:
                        # Calculate if missing
                        if entry_intents_total is not None and bars > 0:
                            print(f"  entry_intents_per_bar_avg: {entry_intents_total / bars:.6f}")
                    print(f"  intents_total_reported: {intents_total_reported if intents_total_reported is not None else perf.get('intents_total', 0)}")
                
                # Stage P2-3: Sparse Builder Scaling (for scaling verification)
                allowed_bars = perf.get('allowed_bars')
                selected_params = perf.get('selected_params')
                intents_generated = perf.get('intents_generated')
                
                if allowed_bars is not None or selected_params is not None or intents_generated is not None:
                    print(f"\nLane {lane_id} Sparse Builder Scaling:")
                    if allowed_bars is not None:
                        print(f"  allowed_bars: {allowed_bars:,}")
                    if selected_params is not None:
                        print(f"  selected_params: {selected_params:,}")
                    if intents_generated is not None:
                        print(f"  intents_generated: {intents_generated:,}")
                    # Calculate scaling ratio if both available
                    if allowed_bars is not None and intents_generated is not None and allowed_bars > 0:
                        scaling_ratio = intents_generated / allowed_bars
                        print(f"  scaling_ratio (intents/allowed): {scaling_ratio:.4f}")
    
    # Stage P2-1.8: Breakdown (Kernel Stage Timings)
    print("\n=== Breakdown (Kernel Stage Timings) ===")
    for r in results:
        if not r or "res" not in r or "lane_id" not in r: continue
        lane_id = r.get('lane_id', 0)
        res = r.get('res', {})
        perf = res.get('perf', {})
        
        if isinstance(perf, dict):
            trigger_rate = perf.get('trigger_rate_configured')
            t_ind_donchian = perf.get('t_ind_donchian_s')
            t_ind_atr = perf.get('t_ind_atr_s')
            t_build_entry = perf.get('t_build_entry_intents_s')
            t_sim_entry = perf.get('t_simulate_entry_s')
            t_calc_exits = perf.get('t_calc_exits_s')
            t_sim_exit = perf.get('t_simulate_exit_s')
            t_total_kernel = perf.get('t_total_kernel_s')
            
            print(f"\nLane {lane_id} Breakdown:")
            if trigger_rate is not None:
                print(f"  trigger_rate_configured: {trigger_rate:.6f}")
            
            # Helper to format timing with "(missing)" if None
            def fmt_time(key: str, val) -> str:
                if val is None:
                    return f"  {key}: (missing)"
                return f"  {key}: {val:.6f}"
            
            # Stage P2-2 Step A: Micro-profiling indicators
            print(fmt_time("t_ind_donchian_s", t_ind_donchian))
            print(fmt_time("t_ind_atr_s", t_ind_atr))
            print(fmt_time("t_build_entry_intents_s", t_build_entry))
            print(fmt_time("t_simulate_entry_s", t_sim_entry))
            print(fmt_time("t_calc_exits_s", t_calc_exits))
            print(fmt_time("t_simulate_exit_s", t_sim_exit))
            print(fmt_time("t_total_kernel_s", t_total_kernel))
            
            # Print percentages if t_total_kernel is available and > 0
            if t_total_kernel is not None and t_total_kernel > 0:
                def fmt_pct(key: str, val, total: float) -> str:
                    if val is None:
                        return f"    {key}: (missing)"
                    pct = (val / total) * 100.0
                    return f"    {key}: {pct:.1f}%"
                
                print("  Percentages:")
                print(fmt_pct("t_ind_donchian_s", t_ind_donchian, t_total_kernel))
                print(fmt_pct("t_ind_atr_s", t_ind_atr, t_total_kernel))
                print(fmt_pct("t_build_entry_intents_s", t_build_entry, t_total_kernel))
                print(fmt_pct("t_simulate_entry_s", t_sim_entry, t_total_kernel))
                print(fmt_pct("t_calc_exits_s", t_calc_exits, t_total_kernel))
                print(fmt_pct("t_simulate_exit_s", t_sim_exit, t_total_kernel))
            
            # Stage P2-2 Step A: Memoization potential assessment
            unique_ch = perf.get('unique_channel_len_count')
            unique_atr = perf.get('unique_atr_len_count')
            unique_pair = perf.get('unique_ch_atr_pair_count')
            
            if unique_ch is not None or unique_atr is not None or unique_pair is not None:
                print(f"\nLane {lane_id} Memoization Potential:")
                if unique_ch is not None:
                    print(f"  unique_channel_len_count: {unique_ch}")
                else:
                    print(f"  unique_channel_len_count: (missing)")
                if unique_atr is not None:
                    print(f"  unique_atr_len_count: {unique_atr}")
                else:
                    print(f"  unique_atr_len_count: (missing)")
                if unique_pair is not None:
                    print(f"  unique_ch_atr_pair_count: {unique_pair}")
                else:
                    print(f"  unique_ch_atr_pair_count: (missing)")
            
            # Stage P2-1.8: Display downstream counts
            entry_fills_total = perf.get('entry_fills_total')
            exit_intents_total = perf.get('exit_intents_total')
            exit_fills_total = perf.get('exit_fills_total')
            
            if entry_fills_total is not None or exit_intents_total is not None or exit_fills_total is not None:
                print(f"\nLane {lane_id} Downstream Observability:")
                if entry_fills_total is not None:
                    print(f"  entry_fills_total: {entry_fills_total}")
                else:
                    print(f"  entry_fills_total: (missing)")
                if exit_intents_total is not None:
                    print(f"  exit_intents_total: {exit_intents_total}")
                else:
                    print(f"  exit_intents_total: (missing)")
                if exit_fills_total is not None:
                    print(f"  exit_fills_total: {exit_fills_total}")
                else:
                    print(f"  exit_fills_total: (missing)")

def run_matcherbench() -> None:
    """
    Matcher-only microbenchmark.
    Purpose:
      - Measure true throughput of cursor-based matcher kernel
      - Avoid runner_grid / Python orchestration overhead
    """
    from FishBroWFS_V2.engine.engine_jit import simulate
    from FishBroWFS_V2.engine.types import (
        BarArrays,
        OrderIntent,
        OrderKind,
        OrderRole,
        Side,
    )

    # ---- config (safe defaults) ----
    n_bars = int(os.environ.get("FISHBRO_MB_BARS", "20000"))
    intents_per_bar = int(os.environ.get("FISHBRO_MB_INTENTS_PER_BAR", "2"))
    hot_runs = int(os.environ.get("FISHBRO_MB_HOTRUNS", "3"))

    print(
        f"[matcherbench] bars={n_bars}, intents_per_bar={intents_per_bar}, hot_runs={hot_runs}"
    )

    # ---- synthetic OHLC ----
    rng = np.random.default_rng(42)
    close = 10000 + np.cumsum(rng.standard_normal(n_bars))
    high = close + 5.0
    low = close - 5.0
    open_ = (high + low) * 0.5

    bars = BarArrays(
        open=open_.astype(np.float64),
        high=high.astype(np.float64),
        low=low.astype(np.float64),
        close=close.astype(np.float64),
    )

    # ---- generate intents: created_bar = t-1 ----
    intents = []
    oid = 1
    for t in range(1, n_bars):
        for _ in range(intents_per_bar):
            # ENTRY
            intents.append(
                OrderIntent(
                    order_id=oid,
                    created_bar=t - 1,
                    role=OrderRole.ENTRY,
                    kind=OrderKind.STOP,
                    side=Side.BUY,
                    price=float(high[t - 1]),
                    qty=1,
                )
            )
            oid += 1
            # EXIT
            intents.append(
                OrderIntent(
                    order_id=oid,
                    created_bar=t - 1,
                    role=OrderRole.EXIT,
                    kind=OrderKind.STOP,
                    side=Side.SELL,
                    price=float(low[t - 1]),
                    qty=1,
                )
            )
            oid += 1

    print(f"[matcherbench] total_intents={len(intents)}")

    # ---- warmup (compile) ----
    simulate(bars, intents)

    # ---- hot runs ----
    times = []
    gc.disable()
    try:
        for _ in range(hot_runs):
            t0 = time.perf_counter()
            fills = simulate(bars, intents)
            dt = time.perf_counter() - t0
            times.append(dt)
    finally:
        gc.enable()

    best = min(times)
    bars_per_s = n_bars / best
    intents_scanned = len(intents)
    intents_per_s = intents_scanned / best
    fills_per_s = len(fills) / best

    print("\n=== MATCHERBENCH RESULT ===")
    print(f"best_time_s      : {best:.6f}")
    print(f"bars_per_sec     : {bars_per_s:,.0f}")
    print(f"intents_per_sec  : {intents_per_s:,.0f}")
    print(f"fills_per_sec    : {fills_per_s:,.0f}")


def main():
    parser = argparse.ArgumentParser(description="FishBro WFS Perf Harness")
    parser.add_argument("--worker", action="store_true", help="Run as worker")
    parser.add_argument("--input", type=str, help="Path to input NPZ")
    parser.add_argument("--hot-runs", type=int, default=5, help="Hot runs")
    parser.add_argument("--skip-cold", action="store_true", help="Skip full cold run, use warmup compile instead")
    parser.add_argument("--warmup-bars", type=int, default=0, help="Warmup compile bars (for skip-cold)")
    parser.add_argument("--warmup-params", type=int, default=0, help="Warmup compile params (for skip-cold)")
    parser.add_argument("--microbench", action="store_true", help="Run microbench only (numba indicator baseline)")
    parser.add_argument("--include-python-baseline", action="store_true", help="Include Toy Tier")
    parser.add_argument(
        "--matcherbench",
        action="store_true",
        help="Benchmark matcher kernel only (engine_jit.simulate), no runner_grid",
    )
    parser.add_argument("--stress-tier", action="store_true", help="Use stress tier (200kÃ—10k) instead of warmup tier")
    args = parser.parse_args()
    
    if args.matcherbench:
        run_matcherbench()
        return

    if args.worker:
        if not args.input: sys.exit(1)
        run_worker(
            args.input,
            args.hot_runs,
            args.skip_cold,
            args.warmup_bars,
            args.warmup_params,
            args.microbench,
        )
        return

    print("Initializing Perf Harness...")
    
    # Stage P2-1.6: Parse and display trigger_rate in main process
    trigger_rate = _env_float("FISHBRO_PERF_TRIGGER_RATE", 1.0)
    if trigger_rate < 0.0 or trigger_rate > 1.0:
        raise ValueError(f"FISHBRO_PERF_TRIGGER_RATE must be in [0, 1], got {trigger_rate}")
    print(f"trigger_rate={trigger_rate}")
    
    lanes_cfg: List[PerfConfig] = []
    
    # Select tier based on stress-tier flag
    if args.stress_tier:
        jit_bars = TIER_STRESS_BARS
        jit_params = TIER_STRESS_PARAMS
        print(f"Using STRESS tier: {jit_bars:,} bars Ã— {jit_params:,} params")
    else:
        jit_bars = TIER_JIT_BARS
        jit_params = TIER_JIT_PARAMS
        print(f"Using WARMUP tier: {jit_bars:,} bars Ã— {jit_params:,} params")
    
    if args.include_python_baseline:
        lanes_cfg.append(PerfConfig("Lane 1 (Py, No Sort)", TIER_TOY_BARS, TIER_TOY_PARAMS, TIER_TOY_HOT_RUNS, TIER_TOY_TIMEOUT, True, False))
        lanes_cfg.append(PerfConfig("Lane 2 (Py, Sort)", TIER_TOY_BARS, TIER_TOY_PARAMS, TIER_TOY_HOT_RUNS, TIER_TOY_TIMEOUT, True, True))
        
    lanes_cfg.append(PerfConfig("Lane 3 (JIT, No Sort)", jit_bars, jit_params, TIER_JIT_HOT_RUNS, TIER_JIT_TIMEOUT, False, False))
    lanes_cfg.append(PerfConfig("Lane 4 (JIT, Sort)", jit_bars, jit_params, TIER_JIT_HOT_RUNS, TIER_JIT_TIMEOUT, False, True))
    
    max_bars = max(c.n_bars for c in lanes_cfg)
    print(f"Generating synthetic data (Max Bars: {max_bars})...")
    ohlc_data = generate_synthetic_data(max_bars)
    
    results = []
    try:
        with tempfile.TemporaryDirectory() as tmp_dir:
            print(f"Created temp dir for IPC: {tmp_dir}")
            for i, cfg in enumerate(lanes_cfg):
                lane_id = i + 1
                if not args.include_python_baseline: lane_id += 2 
                res = run_lane(lane_id, cfg, tmp_dir, ohlc_data, microbench=args.microbench)
                if res:
                    results.append(
                        {
                            "lane_id": lane_id,
                            "name": cfg.name,
                            "res": res,
                            "disable_jit": cfg.disable_jit,
                            "sort_params": cfg.sort_params,
                        }
                    )
                else: results.append({})
                
        print_report(results)
    except RuntimeError as e:
        # Phase 3.0-C: FAIL-FAST - exit with non-zero code on intent_mode violation
        print(f"\nâŒ FAIL-FAST triggered: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()


================================================================================
FILE: src/FishBroWFS_V2/__init__.py
================================================================================




================================================================================
FILE: src/FishBroWFS_V2/config/__init__.py
================================================================================

"""Configuration constants for FishBroWFS_V2."""


================================================================================
FILE: src/FishBroWFS_V2/config/constants.py
================================================================================

"""Phase 4 constants definition.

These constants define the core parameters for Phase 4 Funnel v1 pipeline.
"""

# Top-K selection parameter
TOPK_K: int = 20

# Stage0 proxy name (must match the proxy implementation name)
STAGE0_PROXY_NAME: str = "ma_proxy_v0"


================================================================================
FILE: src/FishBroWFS_V2/config/dtypes.py
================================================================================

"""Dtype configuration for memory optimization.

Centralized dtype definitions to avoid hardcoding throughout the codebase.
These dtypes are optimized for memory bandwidth while maintaining precision where needed.
"""

import numpy as np

# Stage0: Use float32 for price arrays to reduce memory bandwidth
PRICE_DTYPE_STAGE0 = np.float32

# Stage2: Keep float64 for final PnL accumulation (conservative)
PRICE_DTYPE_STAGE2 = np.float64

# Intent arrays: Use float64 for prices (strict parity), uint8 for enums
INTENT_PRICE_DTYPE = np.float64
INTENT_ENUM_DTYPE = np.uint8  # For role, kind, side

# Index arrays: Use int32 instead of int64 where possible
INDEX_DTYPE = np.int32  # For bar_index, param_id (if within int32 range)


================================================================================
FILE: src/FishBroWFS_V2/data/__init__.py
================================================================================




================================================================================
FILE: src/FishBroWFS_V2/data/layout.py
================================================================================

import numpy as np
from FishBroWFS_V2.engine.types import BarArrays


def ensure_float64_contiguous(x: np.ndarray) -> np.ndarray:
    arr = np.asarray(x, dtype=np.float64)
    if not arr.flags["C_CONTIGUOUS"]:
        arr = np.ascontiguousarray(arr)
    return arr


def normalize_bars(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
) -> BarArrays:
    arrays = [open_, high, low, close]
    for a in arrays:
        if np.isnan(a).any():
            raise ValueError("NaN detected in input data")

    o = ensure_float64_contiguous(open_)
    h = ensure_float64_contiguous(high)
    l = ensure_float64_contiguous(low)
    c = ensure_float64_contiguous(close)

    return BarArrays(open=o, high=h, low=l, close=c)



================================================================================
FILE: src/FishBroWFS_V2/engine/__init__.py
================================================================================

"""Engine module - unified simulate entry point."""

from FishBroWFS_V2.engine.simulate import simulate_run

__all__ = ["simulate_run"]


================================================================================
FILE: src/FishBroWFS_V2/engine/constants.py
================================================================================

"""
Engine integer constants (hot-path friendly).

These constants are used in array/SoA pathways to avoid Enum.value lookups in tight loops.
"""

ROLE_EXIT = 0
ROLE_ENTRY = 1

KIND_STOP = 0
KIND_LIMIT = 1

SIDE_SELL = -1
SIDE_BUY = 1




================================================================================
FILE: src/FishBroWFS_V2/engine/constitution.py
================================================================================

"""
Engine Constitution v1.1 (FROZEN)

Activation:
- Orders are created at Bar[T] close and become active at Bar[T+1].

STOP fills (Open==price is treated as GAP branch):
Buy Stop @ S:
- if Open >= S: fill = Open
- elif High >= S: fill = S
Sell Stop @ S:
- if Open <= S: fill = Open
- elif Low <= S: fill = S

LIMIT fills (Open==price is treated as GAP branch):
Buy Limit @ L:
- if Open <= L: fill = Open
- elif Low <= L: fill = L
Sell Limit @ L:
- if Open >= L: fill = Open
- elif High >= L: fill = L

Priority:
- STOP wins over LIMIT (risk-first pessimism).

Same-bar In/Out:
- If entry and exit are both triggerable in the same bar, execute Entry then Exit.

Same-kind tie rule:
- If multiple orders of the same role are triggerable in the same bar, execute EXIT-first.
- Within the same role+kind, use deterministic order: smaller order_id first.
"""

NEXT_BAR_ACTIVE = True
PRIORITY_STOP_OVER_LIMIT = True
SAME_BAR_ENTRY_THEN_EXIT = True
SAME_KIND_TIE_EXIT_FIRST = True



================================================================================
FILE: src/FishBroWFS_V2/engine/engine_jit.py
================================================================================

from __future__ import annotations

from dataclasses import asdict
from typing import Iterable, List, Tuple

import numpy as np

# Engine JIT matcher kernel contract:
# - Complexity target: O(B + I + A), where:
#     B = bars, I = intents, A = per-bar active-book scan.
# - Forbidden: scanning all intents per bar (O(B*I)).
# - Extension point: ttl_bars (0=GTC, 1=one-shot next-bar-only, future: >1).

try:
    import numba as nb
except Exception:  # pragma: no cover
    nb = None  # type: ignore

from FishBroWFS_V2.engine.types import (
    BarArrays,
    Fill,
    OrderIntent,
    OrderKind,
    OrderRole,
    Side,
)
from FishBroWFS_V2.engine.matcher_core import simulate as simulate_py
from FishBroWFS_V2.engine.constants import (
    KIND_LIMIT,
    KIND_STOP,
    ROLE_ENTRY,
    ROLE_EXIT,
    SIDE_BUY,
    SIDE_SELL,
)

# Side enum codes for uint8 encoding (avoid -1 cast deprecation)
SIDE_BUY_CODE = 1
SIDE_SELL_CODE = 255  # SIDE_SELL (-1) encoded as uint8

STATUS_OK = 0
STATUS_ERROR_UNSORTED = 1

# JIT truth (debug/perf observability)
JIT_PATH_USED_LAST = False
JIT_KERNEL_SIGNATURES_LAST = None  # type: ignore


def get_jit_truth() -> dict:
    """
    Debug helper: returns whether the last simulate() call used the JIT kernel,
    and (if available) the kernel signatures snapshot.
    """
    return {
        "jit_path_used": bool(JIT_PATH_USED_LAST),
        "kernel_signatures": JIT_KERNEL_SIGNATURES_LAST,
    }


def _to_int(x) -> int:
    # Enum values are int/str; we convert deterministically.
    if isinstance(x, Side):
        return int(x.value)
    if isinstance(x, OrderRole):
        # EXIT first tie-break relies on role; map explicitly.
        return 0 if x == OrderRole.EXIT else 1
    if isinstance(x, OrderKind):
        return 0 if x == OrderKind.STOP else 1
    return int(x)


def _to_kind_int(k: OrderKind) -> int:
    return 0 if k == OrderKind.STOP else 1


def _to_role_int(r: OrderRole) -> int:
    return 0 if r == OrderRole.EXIT else 1


def _to_side_int(s: Side) -> int:
    """
    Convert Side enum to integer code for uint8 encoding.
    
    Returns:
        SIDE_BUY_CODE (1) for Side.BUY
        SIDE_SELL_CODE (255) for Side.SELL (avoid -1 cast deprecation)
    """
    if s == Side.BUY:
        return SIDE_BUY_CODE
    elif s == Side.SELL:
        return SIDE_SELL_CODE
    else:
        raise ValueError(f"Unknown Side enum: {s}")


def _kind_from_int(v: int) -> OrderKind:
    """
    Decode kind enum from integer value (strict mode).
    
    Allowed values:
    - 0 (KIND_STOP) -> OrderKind.STOP
    - 1 (KIND_LIMIT) -> OrderKind.LIMIT
    
    Raises ValueError for any other value to catch silent corruption.
    """
    if v == KIND_STOP:  # 0
        return OrderKind.STOP
    elif v == KIND_LIMIT:  # 1
        return OrderKind.LIMIT
    else:
        raise ValueError(
            f"Invalid kind enum value: {v}. Allowed values are {KIND_STOP} (STOP) or {KIND_LIMIT} (LIMIT)"
        )


def _role_from_int(v: int) -> OrderRole:
    """
    Decode role enum from integer value (strict mode).
    
    Allowed values:
    - 0 (ROLE_EXIT) -> OrderRole.EXIT
    - 1 (ROLE_ENTRY) -> OrderRole.ENTRY
    
    Raises ValueError for any other value to catch silent corruption.
    """
    if v == ROLE_EXIT:  # 0
        return OrderRole.EXIT
    elif v == ROLE_ENTRY:  # 1
        return OrderRole.ENTRY
    else:
        raise ValueError(
            f"Invalid role enum value: {v}. Allowed values are {ROLE_EXIT} (EXIT) or {ROLE_ENTRY} (ENTRY)"
        )


def _side_from_int(v: int) -> Side:
    """
    Decode side enum from integer value (strict mode).
    
    Allowed values:
    - SIDE_BUY_CODE (1) -> Side.BUY
    - SIDE_SELL_CODE (255) -> Side.SELL
    
    Raises ValueError for any other value to catch silent corruption.
    """
    if v == SIDE_BUY_CODE:  # 1
        return Side.BUY
    elif v == SIDE_SELL_CODE:  # 255
        return Side.SELL
    else:
        raise ValueError(
            f"Invalid side enum value: {v}. Allowed values are {SIDE_BUY_CODE} (BUY) or {SIDE_SELL_CODE} (SELL)"
        )


def _pack_intents(intents: Iterable[OrderIntent]):
    """
    Pack intents into plain arrays for numba.

    Fields (optimized dtypes):
      order_id: int32 (INDEX_DTYPE)
      created_bar: int32 (INDEX_DTYPE)
      role: uint8 (INTENT_ENUM_DTYPE, 0=EXIT,1=ENTRY)
      kind: uint8 (INTENT_ENUM_DTYPE, 0=STOP,1=LIMIT)
      side: uint8 (INTENT_ENUM_DTYPE, SIDE_BUY_CODE=BUY, SIDE_SELL_CODE=SELL)
      price: float64 (INTENT_PRICE_DTYPE)
      qty: int32 (INDEX_DTYPE)
    """
    from FishBroWFS_V2.config.dtypes import (
        INDEX_DTYPE,
        INTENT_ENUM_DTYPE,
        INTENT_PRICE_DTYPE,
    )
    
    it = list(intents)
    n = len(it)
    order_id = np.empty(n, dtype=INDEX_DTYPE)
    created_bar = np.empty(n, dtype=INDEX_DTYPE)
    role = np.empty(n, dtype=INTENT_ENUM_DTYPE)
    kind = np.empty(n, dtype=INTENT_ENUM_DTYPE)
    side = np.empty(n, dtype=INTENT_ENUM_DTYPE)
    price = np.empty(n, dtype=INTENT_PRICE_DTYPE)
    qty = np.empty(n, dtype=INDEX_DTYPE)

    for i, x in enumerate(it):
        order_id[i] = int(x.order_id)
        created_bar[i] = int(x.created_bar)
        role[i] = INTENT_ENUM_DTYPE(_to_role_int(x.role))
        kind[i] = INTENT_ENUM_DTYPE(_to_kind_int(x.kind))
        side[i] = INTENT_ENUM_DTYPE(_to_side_int(x.side))
        price[i] = INTENT_PRICE_DTYPE(x.price)
        qty[i] = int(x.qty)

    return order_id, created_bar, role, kind, side, price, qty


def _sort_packed_by_created_bar(
    packed: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Sort packed intent arrays by (created_bar, order_id).

    Why:
      - Cursor + active-book kernel requires activate_bar=(created_bar+1) and order_id to be non-decreasing.
      - Determinism is preserved because selection is still based on (kind priority, order_id).
    """
    order_id, created_bar, role, kind, side, price, qty = packed
    # lexsort uses last key as primary -> (created_bar primary, order_id secondary)
    idx = np.lexsort((order_id, created_bar))
    return (
        order_id[idx],
        created_bar[idx],
        role[idx],
        kind[idx],
        side[idx],
        price[idx],
        qty[idx],
    )


def simulate(
    bars: BarArrays,
    intents: Iterable[OrderIntent],
) -> List[Fill]:
    """
    Phase 2A: JIT accelerated matcher.

    Kill switch:
      - If numba is unavailable OR NUMBA_DISABLE_JIT=1, fall back to Python reference.
    """
    global JIT_PATH_USED_LAST, JIT_KERNEL_SIGNATURES_LAST

    if nb is None:
        JIT_PATH_USED_LAST = False
        JIT_KERNEL_SIGNATURES_LAST = None
        return simulate_py(bars, intents)

    # If numba is disabled, keep behavior stable.
    # Numba respects NUMBA_DISABLE_JIT; but we short-circuit to be safe.
    import os

    if os.environ.get("NUMBA_DISABLE_JIT", "").strip() == "1":
        JIT_PATH_USED_LAST = False
        JIT_KERNEL_SIGNATURES_LAST = None
        return simulate_py(bars, intents)

    packed = _sort_packed_by_created_bar(_pack_intents(intents))
    status, fills_arr = _simulate_kernel(
        bars.open,
        bars.high,
        bars.low,
        packed[0],
        packed[1],
        packed[2],
        packed[3],
        packed[4],
        packed[5],
        packed[6],
        np.int64(1),  # ttl_bars=1 keeps Phase-2 semantics (next-bar only)
    )
    if int(status) != STATUS_OK:
        JIT_PATH_USED_LAST = True
        raise RuntimeError(f"engine_jit kernel error: status={int(status)}")

    # record JIT truth (best-effort)
    JIT_PATH_USED_LAST = True
    try:
        sigs = getattr(_simulate_kernel, "signatures", None)
        if sigs is not None:
            JIT_KERNEL_SIGNATURES_LAST = list(sigs)
        else:
            JIT_KERNEL_SIGNATURES_LAST = None
    except Exception:
        JIT_KERNEL_SIGNATURES_LAST = None

    # Convert to Fill objects (drop unused capacity)
    out: List[Fill] = []
    m = fills_arr.shape[0]
    for i in range(m):
        row = fills_arr[i]
        out.append(
            Fill(
                bar_index=int(row[0]),
                role=_role_from_int(int(row[1])),
                kind=_kind_from_int(int(row[2])),
                side=_side_from_int(int(row[3])),
                price=float(row[4]),
                qty=int(row[5]),
                order_id=int(row[6]),
            )
        )
    return out


def simulate_arrays(
    bars: BarArrays,
    *,
    order_id: np.ndarray,
    created_bar: np.ndarray,
    role: np.ndarray,
    kind: np.ndarray,
    side: np.ndarray,
    price: np.ndarray,
    qty: np.ndarray,
    ttl_bars: int = 1,
) -> List[Fill]:
    """
    Array/SoA entry point: bypass OrderIntent objects and _pack_intents hot-path.

    Arrays must be 1D and same length. Dtypes are expected (optimized):
      order_id: int32 (INDEX_DTYPE)
      created_bar: int32 (INDEX_DTYPE)
      role: uint8 (INTENT_ENUM_DTYPE)
      kind: uint8 (INTENT_ENUM_DTYPE)
      side: uint8 (INTENT_ENUM_DTYPE)
      price: float64 (INTENT_PRICE_DTYPE)
      qty: int32 (INDEX_DTYPE)

    ttl_bars:
      1 => one-shot next-bar-only (Phase 2 semantics)
      0 => GTC extension point (debug/tests)
    """
    from FishBroWFS_V2.config.dtypes import (
        INDEX_DTYPE,
        INTENT_ENUM_DTYPE,
        INTENT_PRICE_DTYPE,
    )
    
    global JIT_PATH_USED_LAST, JIT_KERNEL_SIGNATURES_LAST

    # Normalize/ensure arrays are numpy with the expected dtypes (cold path).
    oid = np.asarray(order_id, dtype=INDEX_DTYPE)
    cb = np.asarray(created_bar, dtype=INDEX_DTYPE)
    rl = np.asarray(role, dtype=INTENT_ENUM_DTYPE)
    kd = np.asarray(kind, dtype=INTENT_ENUM_DTYPE)
    sd = np.asarray(side, dtype=INTENT_ENUM_DTYPE)
    px = np.asarray(price, dtype=INTENT_PRICE_DTYPE)
    qy = np.asarray(qty, dtype=INDEX_DTYPE)

    if nb is None:
        JIT_PATH_USED_LAST = False
        JIT_KERNEL_SIGNATURES_LAST = None
        intents: List[OrderIntent] = []
        n = int(oid.shape[0])
        for i in range(n):
            # Strict decoding: fail fast on invalid enum values
            rl_val = int(rl[i])
            if rl_val == ROLE_EXIT:
                r = OrderRole.EXIT
            elif rl_val == ROLE_ENTRY:
                r = OrderRole.ENTRY
            else:
                raise ValueError(f"Invalid role enum value: {rl_val}. Allowed: {ROLE_EXIT} (EXIT) or {ROLE_ENTRY} (ENTRY)")
            
            kd_val = int(kd[i])
            if kd_val == KIND_STOP:
                k = OrderKind.STOP
            elif kd_val == KIND_LIMIT:
                k = OrderKind.LIMIT
            else:
                raise ValueError(f"Invalid kind enum value: {kd_val}. Allowed: {KIND_STOP} (STOP) or {KIND_LIMIT} (LIMIT)")
            
            sd_val = int(sd[i])
            if sd_val == SIDE_BUY_CODE:  # 1
                s = Side.BUY
            elif sd_val == SIDE_SELL_CODE:  # 255
                s = Side.SELL
            else:
                raise ValueError(f"Invalid side enum value: {sd_val}. Allowed: {SIDE_BUY_CODE} (BUY) or {SIDE_SELL_CODE} (SELL)")
            intents.append(
                OrderIntent(
                    order_id=int(oid[i]),
                    created_bar=int(cb[i]),
                    role=r,
                    kind=k,
                    side=s,
                    price=float(px[i]),
                    qty=int(qy[i]),
                )
            )
        return simulate_py(bars, intents)

    import os

    if os.environ.get("NUMBA_DISABLE_JIT", "").strip() == "1":
        JIT_PATH_USED_LAST = False
        JIT_KERNEL_SIGNATURES_LAST = None
        intents: List[OrderIntent] = []
        n = int(oid.shape[0])
        for i in range(n):
            # Strict decoding: fail fast on invalid enum values
            rl_val = int(rl[i])
            if rl_val == ROLE_EXIT:
                r = OrderRole.EXIT
            elif rl_val == ROLE_ENTRY:
                r = OrderRole.ENTRY
            else:
                raise ValueError(f"Invalid role enum value: {rl_val}. Allowed: {ROLE_EXIT} (EXIT) or {ROLE_ENTRY} (ENTRY)")
            
            kd_val = int(kd[i])
            if kd_val == KIND_STOP:
                k = OrderKind.STOP
            elif kd_val == KIND_LIMIT:
                k = OrderKind.LIMIT
            else:
                raise ValueError(f"Invalid kind enum value: {kd_val}. Allowed: {KIND_STOP} (STOP) or {KIND_LIMIT} (LIMIT)")
            
            sd_val = int(sd[i])
            if sd_val == SIDE_BUY_CODE:  # 1
                s = Side.BUY
            elif sd_val == SIDE_SELL_CODE:  # 255
                s = Side.SELL
            else:
                raise ValueError(f"Invalid side enum value: {sd_val}. Allowed: {SIDE_BUY_CODE} (BUY) or {SIDE_SELL_CODE} (SELL)")
            intents.append(
                OrderIntent(
                    order_id=int(oid[i]),
                    created_bar=int(cb[i]),
                    role=r,
                    kind=k,
                    side=s,
                    price=float(px[i]),
                    qty=int(qy[i]),
                )
            )
        return simulate_py(bars, intents)

    packed = _sort_packed_by_created_bar((oid, cb, rl, kd, sd, px, qy))
    status, fills_arr = _simulate_kernel(
        bars.open,
        bars.high,
        bars.low,
        packed[0],
        packed[1],
        packed[2],
        packed[3],
        packed[4],
        packed[5],
        packed[6],
        np.int64(ttl_bars),
    )
    if int(status) != STATUS_OK:
        JIT_PATH_USED_LAST = True
        raise RuntimeError(f"engine_jit kernel error: status={int(status)}")

    JIT_PATH_USED_LAST = True
    try:
        sigs = getattr(_simulate_kernel, "signatures", None)
        if sigs is not None:
            JIT_KERNEL_SIGNATURES_LAST = list(sigs)
        else:
            JIT_KERNEL_SIGNATURES_LAST = None
    except Exception:
        JIT_KERNEL_SIGNATURES_LAST = None

    out: List[Fill] = []
    m = fills_arr.shape[0]
    for i in range(m):
        row = fills_arr[i]
        out.append(
            Fill(
                bar_index=int(row[0]),
                role=_role_from_int(int(row[1])),
                kind=_kind_from_int(int(row[2])),
                side=_side_from_int(int(row[3])),
                price=float(row[4]),
                qty=int(row[5]),
                order_id=int(row[6]),
            )
        )
    return out


def _simulate_with_ttl(bars: BarArrays, intents: Iterable[OrderIntent], ttl_bars: int) -> List[Fill]:
    """
    Internal helper (tests/dev): run JIT matcher with a custom ttl_bars.
    ttl_bars=0 => GTC, ttl_bars=1 => one-shot next-bar-only (default).
    """
    if nb is None:
        return simulate_py(bars, intents)

    import os

    if os.environ.get("NUMBA_DISABLE_JIT", "").strip() == "1":
        return simulate_py(bars, intents)

    packed = _sort_packed_by_created_bar(_pack_intents(intents))
    status, fills_arr = _simulate_kernel(
        bars.open,
        bars.high,
        bars.low,
        packed[0],
        packed[1],
        packed[2],
        packed[3],
        packed[4],
        packed[5],
        packed[6],
        np.int64(ttl_bars),
    )
    if int(status) != STATUS_OK:
        raise RuntimeError(f"engine_jit kernel error: status={int(status)}")

    out: List[Fill] = []
    m = fills_arr.shape[0]
    for i in range(m):
        row = fills_arr[i]
        out.append(
            Fill(
                bar_index=int(row[0]),
                role=_role_from_int(int(row[1])),
                kind=_kind_from_int(int(row[2])),
                side=_side_from_int(int(row[3])),
                price=float(row[4]),
                qty=int(row[5]),
                order_id=int(row[6]),
            )
        )
    return out


# ----------------------------
# Numba Kernel
# ----------------------------

if nb is not None:

    @nb.njit(cache=False)
    def _stop_fill(side: int, stop_price: float, o: float, h: float, l: float) -> float:
        # returns nan if no fill
        if side == 1:  # BUY
            if o >= stop_price:
                return o
            if h >= stop_price:
                return stop_price
            return np.nan
        else:  # SELL
            if o <= stop_price:
                return o
            if l <= stop_price:
                return stop_price
            return np.nan

    @nb.njit(cache=False)
    def _limit_fill(side: int, limit_price: float, o: float, h: float, l: float) -> float:
        # returns nan if no fill
        if side == 1:  # BUY
            if o <= limit_price:
                return o
            if l <= limit_price:
                return limit_price
            return np.nan
        else:  # SELL
            if o >= limit_price:
                return o
            if h >= limit_price:
                return limit_price
            return np.nan

    @nb.njit(cache=False)
    def _fill_price(kind: int, side: int, px: float, o: float, h: float, l: float) -> float:
        # kind: 0=STOP, 1=LIMIT
        if kind == 0:
            return _stop_fill(side, px, o, h, l)
        return _limit_fill(side, px, o, h, l)

    @nb.njit(cache=False)
    def _simulate_kernel(
        open_: np.ndarray,
        high: np.ndarray,
        low: np.ndarray,
        order_id: np.ndarray,
        created_bar: np.ndarray,
        role: np.ndarray,
        kind: np.ndarray,
        side: np.ndarray,
        price: np.ndarray,
        qty: np.ndarray,
        ttl_bars: np.int64,
    ):
        """
        Cursor + Active Book kernel (O(B + I + A)).

        Output columns (float64):
          0 bar_index
          1 role_int (0=EXIT,1=ENTRY)
          2 kind_int (0=STOP,1=LIMIT)
          3 side_int (1=BUY,-1=SELL)
          4 fill_price
          5 qty
          6 order_id

        Assumption:
          - intents are sorted by (created_bar, order_id) before calling this kernel.
        """
        n_bars = open_.shape[0]
        n_intents = order_id.shape[0]

        max_fills = n_bars * 2
        out = np.empty((max_fills, 7), dtype=np.float64)
        out_n = 0

        # -------------------------
        # Fail-fast monotonicity check (activate_bar, order_id)
        # -------------------------
        prev_activate = np.int64(-1)
        prev_order = np.int64(-1)
        for i in range(n_intents):
            a = np.int64(created_bar[i]) + np.int64(1)
            o = np.int64(order_id[i])
            if a < prev_activate or (a == prev_activate and o < prev_order):
                return np.int64(STATUS_ERROR_UNSORTED), out[:0]
            prev_activate = a
            prev_order = o

        # Active Book (indices into intent arrays)
        active_indices = np.empty(n_intents, dtype=np.int64)
        active_count = np.int64(0)
        global_cursor = np.int64(0)

        pos = np.int64(0)  # 0 flat, 1 long, -1 short

        for t in range(n_bars):
            o = float(open_[t])
            h = float(high[t])
            l = float(low[t])

            # Step A â€” Injection (cursor inject intents activating at this bar)
            while global_cursor < n_intents:
                a = np.int64(created_bar[global_cursor]) + np.int64(1)
                if a == np.int64(t):
                    active_indices[active_count] = global_cursor
                    active_count += np.int64(1)
                    global_cursor += np.int64(1)
                    continue
                if a > np.int64(t):
                    break
                # a < t should not happen if monotonicity check passed
                return np.int64(STATUS_ERROR_UNSORTED), out[:0]

            # Step B â€” Pass 1 (ENTRY scan, best-pick, swap-remove)
            # Deterministic selection: STOP(0) before LIMIT(1), then order_id asc.
            if pos == 0 and active_count > 0:
                best_k = np.int64(-1)
                best_kind = np.int64(99)
                best_oid = np.int64(2**62)
                best_fp = np.nan

                k = np.int64(0)
                while k < active_count:
                    idx = active_indices[k]
                    if np.int64(role[idx]) != np.int64(1):  # ENTRY
                        k += np.int64(1)
                        continue

                    kk = np.int64(kind[idx])
                    oo = np.int64(order_id[idx])
                    if kk < best_kind or (kk == best_kind and oo < best_oid):
                        fp = _fill_price(int(kk), int(side[idx]), float(price[idx]), o, h, l)
                        if not np.isnan(fp):
                            best_k = k
                            best_kind = kk
                            best_oid = oo
                            best_fp = fp
                    k += np.int64(1)

                if best_k != np.int64(-1):
                    idx = active_indices[best_k]
                    out[out_n, 0] = float(t)
                    out[out_n, 1] = float(role[idx])
                    out[out_n, 2] = float(kind[idx])
                    out[out_n, 3] = float(side[idx])
                    out[out_n, 4] = float(best_fp)
                    out[out_n, 5] = float(qty[idx])
                    out[out_n, 6] = float(order_id[idx])
                    out_n += 1

                    pos = np.int64(1) if np.int64(side[idx]) == np.int64(1) else np.int64(-1)

                    # swap-remove filled intent
                    active_indices[best_k] = active_indices[active_count - 1]
                    active_count -= np.int64(1)

            # Step C â€” Pass 2 (EXIT scan, best-pick, swap-remove)
            # Deterministic selection: STOP(0) before LIMIT(1), then order_id asc.
            if pos != 0 and active_count > 0:
                best_k = np.int64(-1)
                best_kind = np.int64(99)
                best_oid = np.int64(2**62)
                best_fp = np.nan

                k = np.int64(0)
                while k < active_count:
                    idx = active_indices[k]
                    if np.int64(role[idx]) != np.int64(0):  # EXIT
                        k += np.int64(1)
                        continue

                    s = np.int64(side[idx])
                    # long exits are SELL(-1), short exits are BUY(1)
                    if pos == np.int64(1) and s != np.int64(-1):
                        k += np.int64(1)
                        continue
                    if pos == np.int64(-1) and s != np.int64(1):
                        k += np.int64(1)
                        continue

                    kk = np.int64(kind[idx])
                    oo = np.int64(order_id[idx])
                    if kk < best_kind or (kk == best_kind and oo < best_oid):
                        fp = _fill_price(int(kk), int(s), float(price[idx]), o, h, l)
                        if not np.isnan(fp):
                            best_k = k
                            best_kind = kk
                            best_oid = oo
                            best_fp = fp
                    k += np.int64(1)

                if best_k != np.int64(-1):
                    idx = active_indices[best_k]
                    out[out_n, 0] = float(t)
                    out[out_n, 1] = float(role[idx])
                    out[out_n, 2] = float(kind[idx])
                    out[out_n, 3] = float(side[idx])
                    out[out_n, 4] = float(best_fp)
                    out[out_n, 5] = float(qty[idx])
                    out[out_n, 6] = float(order_id[idx])
                    out_n += 1

                    pos = np.int64(0)

                    # swap-remove filled intent
                    active_indices[best_k] = active_indices[active_count - 1]
                    active_count -= np.int64(1)

            # Step D â€” Housekeeping (TTL/GTC extension point)
            if ttl_bars > np.int64(0) and active_count > 0:
                k = np.int64(0)
                while k < active_count:
                    idx = active_indices[k]
                    activate_bar = np.int64(created_bar[idx]) + np.int64(1)
                    expire_bar = activate_bar + (ttl_bars - np.int64(1))
                    if np.int64(t) > expire_bar:
                        active_indices[k] = active_indices[active_count - 1]
                        active_count -= np.int64(1)
                        continue
                    k += np.int64(1)

        return np.int64(STATUS_OK), out[:out_n]



================================================================================
FILE: src/FishBroWFS_V2/engine/kernels/__init__.py
================================================================================

"""Kernel implementations for simulation."""


================================================================================
FILE: src/FishBroWFS_V2/engine/kernels/cursor_kernel.py
================================================================================

"""Cursor kernel - main simulation path for Phase 4.

This is the primary kernel implementation, optimized for performance.
It uses array/struct inputs and deterministic cursor-based matching.
"""

from __future__ import annotations

from typing import Iterable, List

from FishBroWFS_V2.engine.types import BarArrays, Fill, OrderIntent, SimResult
from FishBroWFS_V2.engine.engine_jit import simulate as simulate_jit


def simulate_cursor_kernel(
    bars: BarArrays,
    intents: Iterable[OrderIntent],
) -> SimResult:
    """
    Cursor kernel - main simulation path.
    
    This is the primary kernel for Phase 4. It uses the optimized JIT implementation
    from engine_jit, which provides O(B + I + A) complexity.
    
    Args:
        bars: OHLC bar arrays
        intents: Iterable of order intents
        
    Returns:
        SimResult containing the fills from simulation
        
    Note:
        - Uses arrays/structs internally, no class callbacks
        - Naming and fields are stable for pipeline usage
        - Deterministic behavior guaranteed
    """
    fills: List[Fill] = simulate_jit(bars, intents)
    return SimResult(fills=fills)


================================================================================
FILE: src/FishBroWFS_V2/engine/kernels/reference_kernel.py
================================================================================

"""Reference kernel - adapter for matcher_core (testing/debugging only).

This kernel wraps matcher_core.simulate() and should only be used for:
- Testing alignment between kernels
- Debugging semantic correctness
- Reference implementation verification

It is NOT the main path for production simulation.
"""

from __future__ import annotations

from typing import Iterable, List

from FishBroWFS_V2.engine.types import BarArrays, Fill, OrderIntent, SimResult
from FishBroWFS_V2.engine.matcher_core import simulate as simulate_reference


def simulate_reference_matcher(
    bars: BarArrays,
    intents: Iterable[OrderIntent],
) -> SimResult:
    """
    Reference matcher adapter - wraps matcher_core.simulate().
    
    This is an adapter that wraps the reference implementation in matcher_core.
    It should only be used for testing/debugging, not as the main simulation path.
    
    Args:
        bars: OHLC bar arrays
        intents: Iterable of order intents
        
    Returns:
        SimResult containing the fills from simulation
        
    Note:
        - This wraps matcher_core.simulate() which is the semantic truth source
        - Use only for tests/debug, not for production
    """
    fills: List[Fill] = simulate_reference(bars, intents)
    return SimResult(fills=fills)


================================================================================
FILE: src/FishBroWFS_V2/engine/matcher_core.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List, Optional, Tuple

import numpy as np

from FishBroWFS_V2.engine.types import (
    BarArrays,
    Fill,
    OrderIntent,
    OrderKind,
    OrderRole,
    Side,
)


@dataclass
class PositionState:
    """
    Minimal single-position state for Phase 1 tests.
    pos: 0 = flat, 1 = long, -1 = short
    """
    pos: int = 0


def _is_active(intent: OrderIntent, bar_index: int) -> bool:
    return bar_index == intent.created_bar + 1


def _stop_fill_price(side: Side, stop_price: float, o: float, h: float, l: float) -> Optional[float]:
    # Open==price goes to GAP branch by definition.
    if side == Side.BUY:
        if o >= stop_price:
            return o
        if h >= stop_price:
            return stop_price
        return None
    else:
        if o <= stop_price:
            return o
        if l <= stop_price:
            return stop_price
        return None


def _limit_fill_price(side: Side, limit_price: float, o: float, h: float, l: float) -> Optional[float]:
    # Open==price goes to GAP branch by definition.
    if side == Side.BUY:
        if o <= limit_price:
            return o
        if l <= limit_price:
            return limit_price
        return None
    else:
        if o >= limit_price:
            return o
        if h >= limit_price:
            return limit_price
        return None


def _intent_fill_price(intent: OrderIntent, o: float, h: float, l: float) -> Optional[float]:
    if intent.kind == OrderKind.STOP:
        return _stop_fill_price(intent.side, intent.price, o, h, l)
    return _limit_fill_price(intent.side, intent.price, o, h, l)


def _sort_key(intent: OrderIntent) -> Tuple[int, int, int]:
    """
    Deterministic priority:
    1) Role: EXIT first when selecting within same-stage bucket.
    2) Kind: STOP before LIMIT.
    3) order_id: ascending.
    Note: Entry-vs-Exit ordering is handled at a higher level (Entry then Exit).
    """
    role_rank = 0 if intent.role == OrderRole.EXIT else 1
    kind_rank = 0 if intent.kind == OrderKind.STOP else 1
    return (role_rank, kind_rank, intent.order_id)


def simulate(
    bars: BarArrays,
    intents: Iterable[OrderIntent],
) -> List[Fill]:
    """
    Phase 1 slow reference matcher.

    Rules enforced:
    - next-bar active only (bar_index == created_bar + 1)
    - STOP/LIMIT gap behavior at Open
    - STOP over LIMIT
    - Same-bar Entry then Exit
    - Same-kind tie: EXIT-first, order_id ascending
    """
    o = bars.open
    h = bars.high
    l = bars.low
    n = int(o.shape[0])

    intents_list = list(intents)
    fills: List[Fill] = []
    state = PositionState(pos=0)

    for t in range(n):
        ot = float(o[t])
        ht = float(h[t])
        lt = float(l[t])

        active = [x for x in intents_list if _is_active(x, t)]
        if not active:
            continue

        # Partition by role for same-bar entry then exit.
        entry_intents = [x for x in active if x.role == OrderRole.ENTRY]
        exit_intents = [x for x in active if x.role == OrderRole.EXIT]

        # Stage 1: ENTRY stage
        if entry_intents:
            # Among entries: STOP before LIMIT, then order_id.
            entry_sorted = sorted(entry_intents, key=lambda x: (0 if x.kind == OrderKind.STOP else 1, x.order_id))
            for it in entry_sorted:
                if state.pos != 0:
                    break  # single-position only
                px = _intent_fill_price(it, ot, ht, lt)
                if px is None:
                    continue
                fills.append(
                    Fill(
                        bar_index=t,
                        role=it.role,
                        kind=it.kind,
                        side=it.side,
                        price=float(px),
                        qty=int(it.qty),
                        order_id=int(it.order_id),
                    )
                )
                # Apply position change
                if it.side == Side.BUY:
                    state.pos = 1
                else:
                    state.pos = -1
                break  # at most one entry fill per bar in Phase 1 reference

        # Stage 2: EXIT stage (after entry)
        if exit_intents and state.pos != 0:
            # Same-kind tie rule: EXIT-first already, and STOP before LIMIT, then order_id
            exit_sorted = sorted(exit_intents, key=_sort_key)
            for it in exit_sorted:
                # Only allow exits that reduce/close current position in this minimal model:
                # long exits are SELL, short exits are BUY.
                if state.pos == 1 and it.side != Side.SELL:
                    continue
                if state.pos == -1 and it.side != Side.BUY:
                    continue

                px = _intent_fill_price(it, ot, ht, lt)
                if px is None:
                    continue
                fills.append(
                    Fill(
                        bar_index=t,
                        role=it.role,
                        kind=it.kind,
                        side=it.side,
                        price=float(px),
                        qty=int(it.qty),
                        order_id=int(it.order_id),
                    )
                )
                state.pos = 0
                break  # at most one exit fill per bar in Phase 1 reference

    return fills



================================================================================
FILE: src/FishBroWFS_V2/engine/metrics_from_fills.py
================================================================================

from __future__ import annotations

from typing import List, Tuple

import numpy as np

from FishBroWFS_V2.engine.types import Fill, OrderRole, Side


def _max_drawdown(equity: np.ndarray) -> float:
    """
    Vectorized max drawdown on an equity curve.
    Handles empty arrays gracefully.
    """
    if equity.size == 0:
        return 0.0
    peak = np.maximum.accumulate(equity)
    dd = equity - peak
    mdd = float(np.min(dd))  # negative or 0
    return mdd


def compute_metrics_from_fills(
    fills: List[Fill],
    commission: float,
    slip: float,
    qty: int,
) -> Tuple[float, int, float, np.ndarray]:
    """
    Compute metrics from fills list.
    
    This is the unified source of truth for metrics computation from fills.
    Both object-mode and array-mode kernels should use this helper to ensure parity.
    
    Args:
        fills: List of Fill objects (can be empty)
        commission: Commission cost per trade (absolute)
        slip: Slippage cost per trade (absolute)
        qty: Order quantity (used for PnL calculation)
    
    Returns:
        Tuple of (net_profit, trades, max_dd, equity):
            - net_profit: float - Total net profit (sum of all round-trip PnL)
            - trades: int - Number of trades (count of ENTRY fills)
            - max_dd: float - Maximum drawdown from equity curve
            - equity: np.ndarray - Cumulative equity curve (cumsum of per-trade PnL)
    
    Note:
        - trades is defined as len([fill for fill in fills if fill.role==ENTRY])
        - Only LONG trades are supported (BUY entry, SELL exit)
        - Costs are applied per fill (entry + exit each incur cost)
    """
    # Count trades (number of ENTRY fills)
    trades = len([fill for fill in fills if fill.role == OrderRole.ENTRY])
    
    if trades == 0:
        # No trades: return zeros
        return (0.0, 0, 0.0, np.empty(0, dtype=np.float64))
    
    # Extract entry/exit prices for round trips
    # Pairing rule: take fills in chronological order, pair BUY(ENTRY) then SELL(EXIT)
    entry_prices = []
    exit_prices = []
    for f in fills:
        if f.role == OrderRole.ENTRY and f.side == Side.BUY:
            entry_prices.append(float(f.price))
        elif f.role == OrderRole.EXIT and f.side == Side.SELL:
            exit_prices.append(float(f.price))
    
    # Match entry/exit pairs (take minimum to handle unpaired entries)
    k = min(len(entry_prices), len(exit_prices))
    if k == 0:
        # No complete round trips
        return (0.0, trades, 0.0, np.empty(0, dtype=np.float64))
    
    ep = np.asarray(entry_prices[:k], dtype=np.float64)
    xp = np.asarray(exit_prices[:k], dtype=np.float64)
    
    # Costs applied per fill (entry + exit)
    costs = (float(commission) + float(slip)) * 2.0
    pnl = (xp - ep) * float(qty) - costs
    equity = np.cumsum(pnl)
    
    net_profit = float(np.sum(pnl)) if pnl.size else 0.0
    max_dd = _max_drawdown(equity)
    
    return (net_profit, trades, max_dd, equity)


================================================================================
FILE: src/FishBroWFS_V2/engine/order_id.py
================================================================================

"""
Deterministic Order ID Generation (CURSOR TASK 5)

Provides pure function for generating deterministic order IDs that do not depend
on generation order or counters. Used by both object-mode and array-mode kernels.
"""
from __future__ import annotations

import numpy as np

from FishBroWFS_V2.config.dtypes import INDEX_DTYPE
from FishBroWFS_V2.engine.constants import KIND_STOP, ROLE_ENTRY, ROLE_EXIT, SIDE_BUY, SIDE_SELL


def generate_order_id(
    created_bar: int,
    param_idx: int = 0,
    role: int = ROLE_ENTRY,
    kind: int = KIND_STOP,
    side: int = SIDE_BUY,
) -> int:
    """
    Generate deterministic order ID from intent attributes.
    
    Uses reversible packing to ensure deterministic IDs that do not depend on
    generation order or counters. This ensures parity between object-mode and
    array-mode kernels.
    
    Formula:
        order_id = created_bar * 1_000_000 + param_idx * 100 + role_code * 10 + kind_code * 2 + side_code_bit
    
    Args:
        created_bar: Bar index where intent is created (0-indexed)
        param_idx: Parameter index (0-indexed, default 0 for single-param kernels)
        role: Role code (ROLE_ENTRY or ROLE_EXIT)
        kind: Kind code (KIND_STOP or KIND_LIMIT)
        side: Side code (SIDE_BUY or SIDE_SELL)
    
    Returns:
        Deterministic order ID (int32)
    
    Note:
        - Maximum created_bar: 2,147,483 (within int32 range)
        - Maximum param_idx: 21,474,836 (within int32 range)
        - This packing scheme ensures uniqueness for typical use cases
    """
    # Map role to code: ENTRY=0, EXIT=1
    role_code = 0 if role == ROLE_ENTRY else 1
    
    # Map kind to code: STOP=0, LIMIT=1 (assuming KIND_STOP=0, KIND_LIMIT=1)
    kind_code = 0 if kind == KIND_STOP else 1
    
    # Map side to bit: BUY=0, SELL=1
    side_bit = 0 if side == SIDE_BUY else 1
    
    # Pack: created_bar * 1_000_000 + param_idx * 100 + role_code * 10 + kind_code * 2 + side_bit
    order_id = (
        created_bar * 1_000_000 +
        param_idx * 100 +
        role_code * 10 +
        kind_code * 2 +
        side_bit
    )
    
    return int(order_id)


def generate_order_ids_array(
    created_bar: np.ndarray,
    param_idx: int = 0,
    role: np.ndarray | None = None,
    kind: np.ndarray | None = None,
    side: np.ndarray | None = None,
) -> np.ndarray:
    """
    Generate deterministic order IDs for array of intents.
    
    Vectorized version of generate_order_id for array-mode kernels.
    
    Args:
        created_bar: Array of created bar indices (int32, shape (n,))
        param_idx: Parameter index (default 0 for single-param kernels)
        role: Array of role codes (uint8, shape (n,)). If None, defaults to ROLE_ENTRY.
        kind: Array of kind codes (uint8, shape (n,)). If None, defaults to KIND_STOP.
        side: Array of side codes (uint8, shape (n,)). If None, defaults to SIDE_BUY.
    
    Returns:
        Array of deterministic order IDs (int32, shape (n,))
    """
    n = len(created_bar)
    
    # Default values if not provided
    if role is None:
        role = np.full(n, ROLE_ENTRY, dtype=np.uint8)
    if kind is None:
        kind = np.full(n, KIND_STOP, dtype=np.uint8)
    if side is None:
        side = np.full(n, SIDE_BUY, dtype=np.uint8)
    
    # Map to codes
    role_code = np.where(role == ROLE_ENTRY, 0, 1).astype(np.int32)
    kind_code = np.where(kind == KIND_STOP, 0, 1).astype(np.int32)
    side_bit = np.where(side == SIDE_BUY, 0, 1).astype(np.int32)
    
    # Pack: created_bar * 1_000_000 + param_idx * 100 + role_code * 10 + kind_code * 2 + side_bit
    order_id = (
        created_bar.astype(np.int32) * 1_000_000 +
        param_idx * 100 +
        role_code * 10 +
        kind_code * 2 +
        side_bit
    )
    
    return order_id.astype(INDEX_DTYPE)


================================================================================
FILE: src/FishBroWFS_V2/engine/simulate.py
================================================================================

"""Unified simulate entry point for Phase 4.

This module provides the single entry point simulate_run() which routes to
the Cursor kernel (main path) or Reference kernel (testing/debugging only).
"""

from __future__ import annotations

from typing import Iterable

from FishBroWFS_V2.engine.types import BarArrays, OrderIntent, SimResult
from FishBroWFS_V2.engine.kernels.cursor_kernel import simulate_cursor_kernel
from FishBroWFS_V2.engine.kernels.reference_kernel import simulate_reference_matcher


def simulate_run(
    bars: BarArrays,
    intents: Iterable[OrderIntent],
    *,
    use_reference: bool = False,
) -> SimResult:
    """
    Unified simulate entry point - Phase 4 main API.
    
    This is the single entry point for all simulation calls. By default, it uses
    the Cursor kernel (main path). The Reference kernel is only available for
    testing/debugging purposes.
    
    Args:
        bars: OHLC bar arrays
        intents: Iterable of order intents
        use_reference: If True, use reference kernel (testing/debug only).
                      Default False uses Cursor kernel (main path).
        
    Returns:
        SimResult containing the fills from simulation
        
    Note:
        - Cursor kernel is the main path for production
        - Reference kernel should only be used for tests/debug
        - This API is stable for pipeline usage
    """
    if use_reference:
        return simulate_reference_matcher(bars, intents)
    return simulate_cursor_kernel(bars, intents)


================================================================================
FILE: src/FishBroWFS_V2/engine/types.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum
from typing import List, Optional

import numpy as np


@dataclass(frozen=True)
class BarArrays:
    open: np.ndarray
    high: np.ndarray
    low: np.ndarray
    close: np.ndarray


class Side(int, Enum):
    BUY = 1
    SELL = -1


class OrderKind(str, Enum):
    STOP = "STOP"
    LIMIT = "LIMIT"


class OrderRole(str, Enum):
    ENTRY = "ENTRY"
    EXIT = "EXIT"


@dataclass(frozen=True)
class OrderIntent:
    """
    Order intent created at bar `created_bar` and becomes active at bar `created_bar + 1`.
    Deterministic ordering is controlled via `order_id` (smaller = earlier).
    """
    order_id: int
    created_bar: int
    role: OrderRole
    kind: OrderKind
    side: Side
    price: float
    qty: int = 1


@dataclass(frozen=True)
class Fill:
    bar_index: int
    role: OrderRole
    kind: OrderKind
    side: Side
    price: float
    qty: int
    order_id: int


@dataclass(frozen=True)
class SimResult:
    """
    Simulation result from simulate_run().
    
    This is the standard return type for Phase 4 unified simulate entry point.
    """
    fills: List[Fill]



================================================================================
FILE: src/FishBroWFS_V2/indicators/__init__.py
================================================================================




================================================================================
FILE: src/FishBroWFS_V2/indicators/numba_indicators.py
================================================================================

from __future__ import annotations

import numpy as np

try:
    import numba as nb
except Exception:  # pragma: no cover
    nb = None  # type: ignore


# ----------------------------
# Rolling Max / Min
# ----------------------------
# Design choice (v1):
# - Simple loop scan for window <= ~50 is cache-friendly and predictable.
# - Correctness first; no deque optimization in v1.


if nb is not None:

    @nb.njit(cache=False)
    def rolling_max(arr: np.ndarray, window: int) -> np.ndarray:
        n = arr.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0:
            return out
        for i in range(n):
            if i < window - 1:
                continue
            start = i - window + 1
            m = arr[start]
            for j in range(start + 1, i + 1):
                v = arr[j]
                if v > m:
                    m = v
            out[i] = m
        return out

    @nb.njit(cache=False)
    def rolling_min(arr: np.ndarray, window: int) -> np.ndarray:
        n = arr.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0:
            return out
        for i in range(n):
            if i < window - 1:
                continue
            start = i - window + 1
            m = arr[start]
            for j in range(start + 1, i + 1):
                v = arr[j]
                if v < m:
                    m = v
            out[i] = m
        return out

else:
    # Fallback pure-python (used only if numba unavailable)
    def rolling_max(arr: np.ndarray, window: int) -> np.ndarray:  # type: ignore
        n = arr.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0:
            return out
        for i in range(n):
            if i < window - 1:
                continue
            start = i - window + 1
            out[i] = np.max(arr[start : i + 1])
        return out

    def rolling_min(arr: np.ndarray, window: int) -> np.ndarray:  # type: ignore
        n = arr.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0:
            return out
        for i in range(n):
            if i < window - 1:
                continue
            start = i - window + 1
            out[i] = np.min(arr[start : i + 1])
        return out


# ----------------------------
# ATR (Wilder's RMA)
# ----------------------------
# Definition:
# TR[t] = max(high[t]-low[t], abs(high[t]-close[t-1]), abs(low[t]-close[t-1]))
# ATR[t] = (ATR[t-1]*(n-1) + TR[t]) / n
# Notes:
# - Recursive; must keep state.
# - First ATR uses simple average of first n TRs.


if nb is not None:

    @nb.njit(cache=False)
    def atr_wilder(high: np.ndarray, low: np.ndarray, close: np.ndarray, window: int) -> np.ndarray:
        n = high.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0 or n == 0:
            return out
        if window > n:
            return out

        # TR computation
        tr = np.empty(n, dtype=np.float64)
        tr[0] = high[0] - low[0]
        for i in range(1, n):
            a = high[i] - low[i]
            b = abs(high[i] - close[i - 1])
            c = abs(low[i] - close[i - 1])
            tr[i] = a if a >= b and a >= c else (b if b >= c else c)

        # initial ATR: simple average of first window TRs
        s = 0.0
        end = window if window < n else n
        for i in range(end):
            s += tr[i]
        # here window <= n guaranteed
        out[end - 1] = s / window

        # Wilder smoothing
        for i in range(window, n):
            out[i] = (out[i - 1] * (window - 1) + tr[i]) / window

        return out

else:
    def atr_wilder(high: np.ndarray, low: np.ndarray, close: np.ndarray, window: int) -> np.ndarray:  # type: ignore
        n = high.shape[0]
        out = np.full(n, np.nan, dtype=np.float64)
        if window <= 0 or n == 0:
            return out
        if window > n:
            return out

        tr = np.empty(n, dtype=np.float64)
        tr[0] = high[0] - low[0]
        for i in range(1, n):
            tr[i] = max(
                high[i] - low[i],
                abs(high[i] - close[i - 1]),
                abs(low[i] - close[i - 1]),
            )

        end = min(window, n)
        # window <= n guaranteed
        out[end - 1] = np.mean(tr[:end])
        for i in range(window, n):
            out[i] = (out[i - 1] * (window - 1) + tr[i]) / window
        return out



================================================================================
FILE: src/FishBroWFS_V2/perf/__init__.py
================================================================================

"""
Performance profiling utilities.
"""


================================================================================
FILE: src/FishBroWFS_V2/perf/cost_model.py
================================================================================

"""Cost model for performance estimation.

Provides predictable cost estimation: given bars and params, estimate execution time.
"""

from __future__ import annotations


def estimate_seconds(
    bars: int,
    params: int,
    cost_ms_per_param: float,
) -> float:
    """
    Estimate execution time in seconds based on cost model.
    
    Cost model assumption:
    - Time is linear in number of parameters only
    - Cost per parameter is measured in milliseconds
    - Formula: time_seconds = (params * cost_ms_per_param) / 1000.0
    - Note: bars parameter is for reference only and does not affect the calculation
    
    Args:
        bars: number of bars (for reference only, not used in calculation)
        params: number of parameters
        cost_ms_per_param: cost per parameter in milliseconds
        
    Returns:
        Estimated time in seconds
        
    Note:
        - This is a simple linear model: time = params * cost_per_param_ms / 1000.0
        - Bars are provided for reference but NOT used in the calculation
        - The model assumes cost per parameter is constant (measured from actual runs)
    """
    if params <= 0:
        return 0.0
    
    if cost_ms_per_param <= 0:
        return 0.0
    
    # Linear model: time = params * cost_per_param_ms / 1000.0
    estimated_seconds = (params * cost_ms_per_param) / 1000.0
    
    return estimated_seconds


================================================================================
FILE: src/FishBroWFS_V2/perf/profile_report.py
================================================================================

from __future__ import annotations

import cProfile
import io
import os
import pstats


def _format_profile_report(
    lane_id: str,
    n_bars: int,
    n_params: int,
    jit_enabled: bool,
    sort_params: bool,
    topn: int,
    mode: str,
    pr: cProfile.Profile,
) -> str:
    """
    Format a deterministic profile report string for perf harness.

    Contract:
    - Always includes __PROFILE_START__/__PROFILE_END__ markers.
    - Always includes the 'pstats sort: cumtime' header even if no stats exist.
    - Must not throw when the profile has no collected stats (empty Profile).
    """
    s = io.StringIO()
    s.write("__PROFILE_START__\n")
    s.write(f"lane_id={lane_id}\n")
    s.write(f"bars={n_bars} params={n_params}\n")
    s.write(f"jit_enabled={jit_enabled} sort_params={sort_params}\n")
    s.write(f"pid={os.getpid()}\n")
    if mode is not None:
        s.write(f"mode={mode}\n")
    s.write("\n")

    # Always emit the headers so tests can rely on markers/labels.
    s.write(f"== pstats sort: cumtime (top {topn}) ==\n")
    try:
        ps = pstats.Stats(pr, stream=s).strip_dirs()
        ps.sort_stats("cumtime")
        ps.print_stats(topn)
    except TypeError:
        s.write("(no profile stats collected)\n")

    s.write("\n\n")
    s.write(f"== pstats sort: tottime (top {topn}) ==\n")
    try:
        ps = pstats.Stats(pr, stream=s).strip_dirs()
        ps.sort_stats("tottime")
        ps.print_stats(topn)
    except TypeError:
        s.write("(no profile stats collected)\n")

    s.write("\n\n__PROFILE_END__\n")
    return s.getvalue()


================================================================================
FILE: src/FishBroWFS_V2/perf/scenario_control.py
================================================================================

"""
Perf Harness Scenario Control (P2-1.6)

Provides trigger rate masking for perf harness to control sparse trigger density.
"""
from __future__ import annotations

import numpy as np


def apply_trigger_rate_mask(
    trigger: np.ndarray,
    trigger_rate: float,
    warmup: int = 0,
    seed: int = 42,
) -> np.ndarray:
    """
    Apply deterministic trigger rate mask to trigger array.
    
    This function masks trigger array to control sparse trigger density for perf testing.
    Only applies masking when trigger_rate < 1.0. When trigger_rate == 1.0, returns
    original array unchanged (preserves baseline behavior).
    
    Args:
        trigger: Input trigger array (e.g., donch_prev) of shape (n_bars,)
        trigger_rate: Rate of triggers to keep (0.0 to 1.0). Must be in [0, 1].
        warmup: Warmup period. Positions before warmup that are already NaN are preserved.
        seed: Random seed for deterministic masking.
    
    Returns:
        Masked trigger array with same dtype as input. Positions not kept are set to NaN.
    
    Rules:
        - If trigger_rate == 1.0: return original array unchanged
        - Otherwise: use RNG to determine which positions to keep
        - Respect warmup: positions < warmup that are already NaN remain NaN
        - Positions >= warmup are subject to masking
        - Keep dtype unchanged
    """
    if trigger_rate < 0.0 or trigger_rate > 1.0:
        raise ValueError(f"trigger_rate must be in [0, 1], got {trigger_rate}")
    
    # Fast path: no masking needed
    if trigger_rate == 1.0:
        return trigger
    
    # Create a copy to avoid modifying input
    masked = trigger.copy()
    
    # Use deterministic RNG
    rng = np.random.default_rng(seed)
    
    # Generate keep mask: positions to keep based on trigger_rate
    # Only apply masking to positions >= warmup that are currently finite
    n = len(trigger)
    keep_mask = np.ones(n, dtype=bool)  # Default: keep all
    
    # For positions >= warmup, apply random masking
    if warmup < n:
        # Generate random values for positions >= warmup
        random_vals = rng.random(n - warmup)
        keep_mask[warmup:] = random_vals < trigger_rate
    
    # Preserve existing NaN positions (they should remain NaN)
    # Only mask positions that are currently finite and not kept
    finite_mask = np.isfinite(masked)
    
    # Apply masking: set non-kept finite positions to NaN
    # But preserve warmup period (positions < warmup remain unchanged)
    to_mask = finite_mask & (~keep_mask)
    masked[to_mask] = np.nan
    
    return masked


================================================================================
FILE: src/FishBroWFS_V2/perf/timers.py
================================================================================

"""
Perf Harness Timer Helper (P2-1.8)

Provides granular timing breakdown for kernel stages.
"""
from __future__ import annotations

import time
from typing import Dict


class PerfTimers:
    """
    Performance timer helper for granular breakdown.
    
    Supports multiple start/stop calls for the same timer name (accumulates).
    All timings are in seconds with '_s' suffix.
    """
    
    def __init__(self) -> None:
        self._accumulated: Dict[str, float] = {}
        self._active: Dict[str, float] = {}
    
    def start(self, name: str) -> None:
        """
        Start a timer. If already running, does nothing (no nested timing).
        """
        if name not in self._active:
            self._active[name] = time.perf_counter()
    
    def stop(self, name: str) -> None:
        """
        Stop a timer and accumulate the elapsed time.
        If timer was not started, does nothing.
        """
        if name in self._active:
            elapsed = time.perf_counter() - self._active[name]
            self._accumulated[name] = self._accumulated.get(name, 0.0) + elapsed
            del self._active[name]
    
    def as_dict_seconds(self) -> Dict[str, float]:
        """
        Return accumulated timings as dict with '_s' suffix keys.
        
        Returns:
            dict with keys like "t_xxx_s": float (seconds)
        """
        result: Dict[str, float] = {}
        for name, seconds in self._accumulated.items():
            # Ensure '_s' suffix
            key = name if name.endswith("_s") else f"{name}_s"
            result[key] = float(seconds)
        return result
    
    def get(self, name: str, default: float = 0.0) -> float:
        """
        Get accumulated time for a timer name.
        """
        return self._accumulated.get(name, default)


================================================================================
FILE: src/FishBroWFS_V2/pipeline/__init__.py
================================================================================




================================================================================
FILE: src/FishBroWFS_V2/pipeline/funnel.py
================================================================================

"""Funnel orchestrator - Stage0 â†’ Top-K â†’ Stage2 pipeline.

This is the main entry point for the Phase 4 Funnel pipeline.
It orchestrates the complete flow: proxy ranking â†’ selection â†’ full backtest.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import List, Optional

import numpy as np

from FishBroWFS_V2.config.constants import TOPK_K
from FishBroWFS_V2.pipeline.stage0_runner import Stage0Result, run_stage0
from FishBroWFS_V2.pipeline.stage2_runner import Stage2Result, run_stage2
from FishBroWFS_V2.pipeline.topk import select_topk


@dataclass(frozen=True)
class FunnelResult:
    """
    Complete funnel pipeline result.
    
    Contains:
    - stage0_results: all Stage0 proxy ranking results
    - topk_param_ids: selected Top-K parameter indices
    - stage2_results: full backtest results for Top-K parameters
    - meta: optional metadata
    """
    stage0_results: List[Stage0Result]
    topk_param_ids: List[int]
    stage2_results: List[Stage2Result]
    meta: Optional[dict] = None


def run_funnel(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
    *,
    k: int = TOPK_K,
    commission: float = 0.0,
    slip: float = 0.0,
    order_qty: int = 1,
    proxy_name: str = "ma_proxy_v0",
) -> FunnelResult:
    """
    Run complete Funnel pipeline: Stage0 â†’ Top-K â†’ Stage2.
    
    Pipeline flow (fixed):
    1. Stage0: proxy ranking on all parameters
    2. Top-K: select top K parameters based on proxy_value
    3. Stage2: full backtest on Top-K subset
    
    Args:
        open_, high, low, close: OHLC arrays (float64, 1D, same length)
        params_matrix: float64 2D array (n_params, >=3)
            - For Stage0: uses col0 (fast_len), col1 (slow_len) for MA proxy
            - For Stage2: uses col0 (channel_len), col1 (atr_len), col2 (stop_mult) for kernel
        k: number of top parameters to select (default: TOPK_K)
        commission: commission per trade (absolute)
        slip: slippage per trade (absolute)
        order_qty: order quantity (default: 1)
        proxy_name: name of proxy to use for Stage0 (default: ma_proxy_v0)
        
    Returns:
        FunnelResult containing:
        - stage0_results: all proxy ranking results
        - topk_param_ids: selected Top-K parameter indices
        - stage2_results: full backtest results for Top-K only
        
    Note:
        - Pipeline is deterministic: same input produces same output
        - Stage0 does NOT compute PnL metrics (only proxy_value)
        - Top-K selection is based solely on proxy_value
        - Stage2 runs full backtest only on Top-K subset
    """
    # Step 1: Stage0 - proxy ranking
    stage0_results = run_stage0(
        close,
        params_matrix,
        proxy_name=proxy_name,
    )
    
    # Step 2: Top-K selection
    topk_param_ids = select_topk(stage0_results, k=k)
    
    # Step 3: Stage2 - full backtest on Top-K
    stage2_results = run_stage2(
        open_,
        high,
        low,
        close,
        params_matrix,
        topk_param_ids,
        commission=commission,
        slip=slip,
        order_qty=order_qty,
    )
    
    return FunnelResult(
        stage0_results=stage0_results,
        topk_param_ids=topk_param_ids,
        stage2_results=stage2_results,
        meta=None,
    )


================================================================================
FILE: src/FishBroWFS_V2/pipeline/metrics_schema.py
================================================================================

from __future__ import annotations

"""
Metrics column schema (single source of truth).

Defines the column order for metrics arrays returned by run_grid().
"""

# Column indices for metrics array (n_params, 3)
METRICS_COL_NET_PROFIT = 0
METRICS_COL_TRADES = 1
METRICS_COL_MAX_DD = 2

# Column names (for documentation/debugging)
METRICS_COLUMN_NAMES = ["net_profit", "trades", "max_dd"]

# Number of columns
METRICS_N_COLUMNS = 3


================================================================================
FILE: src/FishBroWFS_V2/pipeline/param_sort.py
================================================================================

from __future__ import annotations

import numpy as np


def sort_params_cache_friendly(params: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
    """
    Cache-friendly sorting for parameter matrix.

    params: shape (n, k) float64.
      Convention (Phase 3B v1):
        col0 = channel_len
        col1 = atr_len
        col2 = stop_mult

    Returns:
      sorted_params: params reordered (view/copy depending on numpy)
      order: indices such that sorted_params = params[order]
    """
    if params.ndim != 2 or params.shape[1] < 3:
        raise ValueError("params must be (n, >=3) array")

    # Primary: channel_len (int-like)
    # Secondary: atr_len (int-like)
    # Tertiary: stop_mult
    ch = params[:, 0]
    atr = params[:, 1]
    sm = params[:, 2]

    order = np.lexsort((sm, atr, ch))
    return params[order], order



================================================================================
FILE: src/FishBroWFS_V2/pipeline/runner_grid.py
================================================================================

from __future__ import annotations

from typing import Dict, Tuple

import numpy as np
import os
import time

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.types import BarArrays, Fill, OrderIntent, OrderKind, OrderRole, Side
from FishBroWFS_V2.pipeline.metrics_schema import (
    METRICS_COL_MAX_DD,
    METRICS_COL_NET_PROFIT,
    METRICS_COL_TRADES,
    METRICS_N_COLUMNS,
)
from FishBroWFS_V2.pipeline.param_sort import sort_params_cache_friendly
from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, PrecomputedIndicators, run_kernel
from FishBroWFS_V2.indicators.numba_indicators import rolling_max, rolling_min, atr_wilder


def _max_drawdown(equity: np.ndarray) -> float:
    """
    Vectorized max drawdown on an equity curve.
    Handles empty arrays gracefully.
    """
    if equity.size == 0:
        return 0.0
    peak = np.maximum.accumulate(equity)
    dd = equity - peak
    mdd = float(np.min(dd))  # negative or 0
    return mdd


def _ensure_contiguous_bars(bars: BarArrays) -> BarArrays:
    if bars.open.flags["C_CONTIGUOUS"] and bars.high.flags["C_CONTIGUOUS"] and bars.low.flags["C_CONTIGUOUS"] and bars.close.flags["C_CONTIGUOUS"]:
        return bars
    return BarArrays(
        open=np.ascontiguousarray(bars.open, dtype=np.float64),
        high=np.ascontiguousarray(bars.high, dtype=np.float64),
        low=np.ascontiguousarray(bars.low, dtype=np.float64),
        close=np.ascontiguousarray(bars.close, dtype=np.float64),
    )


def run_grid(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
    sort_params: bool = True,
    force_close_last: bool = False,
    return_debug: bool = False,
) -> Dict[str, object]:
    """
    Phase 3B v1: Dynamic Grid Runner (homology locked).

    params_matrix: shape (n, >=3) float64
      col0 channel_len (int-like)
      col1 atr_len (int-like)
      col2 stop_mult (float)

    Args:
        force_close_last: If True, force close any open positions at the last bar
            using close[-1] as exit price. This ensures trades > 0 when fills exist.

    Returns:
      dict with:
        - metrics: np.ndarray shape (n, 3) float64 columns:
            [net_profit, trades, max_dd] (see pipeline.metrics_schema for column indices)
        - order: np.ndarray indices mapping output rows back to original params (or identity)
    """
    profile_grid = os.environ.get("FISHBRO_PROFILE_GRID", "").strip() == "1"
    profile_kernel = os.environ.get("FISHBRO_PROFILE_KERNEL", "").strip() == "1"
    
    # Stage P2-1.8: Bridge (B) - if user turns on GRID profiling, kernel timing must be enabled too.
    # This provides stable UX: grid breakdown automatically enables kernel timing.
    # Only restore if we set it ourselves, to avoid polluting external caller's environment.
    _set_kernel_profile = False
    if profile_grid and not profile_kernel:
        os.environ["FISHBRO_PROFILE_KERNEL"] = "1"
        _set_kernel_profile = True
    
    # Treat either flag as "profile mode" for grid aggregation.
    profile = profile_grid or profile_kernel
    
    sim_only = os.environ.get("FISHBRO_PERF_SIM_ONLY", "").strip() == "1"
    t0 = time.perf_counter()

    bars = _ensure_contiguous_bars(normalize_bars(open_, high, low, close))
    t_prep1 = time.perf_counter()

    if params_matrix.ndim != 2 or params_matrix.shape[1] < 3:
        raise ValueError("params_matrix must be (n, >=3)")

    from FishBroWFS_V2.config.dtypes import INDEX_DTYPE
    from FishBroWFS_V2.config.dtypes import PRICE_DTYPE_STAGE2
    
    # runner_grid is used in Stage2, so keep float64 for params_matrix (conservative)
    pm = np.asarray(params_matrix, dtype=PRICE_DTYPE_STAGE2)
    if sort_params:
        pm_sorted, order = sort_params_cache_friendly(pm)
        # Convert order to INDEX_DTYPE (int32) for memory optimization
        order = order.astype(INDEX_DTYPE)
    else:
        pm_sorted = pm
        order = np.arange(pm.shape[0], dtype=INDEX_DTYPE)
    t_sort = time.perf_counter()

    n = pm_sorted.shape[0]
    metrics = np.zeros((n, METRICS_N_COLUMNS), dtype=np.float64)
    
    # Debug arrays: per-param first trade snapshot (only if return_debug=True)
    if return_debug:
        debug_fills_first = np.full((n, 6), np.nan, dtype=np.float64)
        # Columns: entry_bar, entry_price, exit_bar, exit_price, net_profit, trades
    else:
        debug_fills_first = None

    # Initialize result dict early (minimal structure)
    perf: Dict[str, object] = {}
    
    # Stage P2-2 Step A: Memoization potential assessment - unique counts
    # Extract channel_len and atr_len values (as int32 for unique counting)
    ch_vals = pm_sorted[:, 0].astype(np.int32, copy=False)
    atr_vals = pm_sorted[:, 1].astype(np.int32, copy=False)
    
    perf["unique_channel_len_count"] = int(np.unique(ch_vals).size)
    perf["unique_atr_len_count"] = int(np.unique(atr_vals).size)
    
    # Pack pair to int64 key: (ch<<32) | atr
    pair_keys = (ch_vals.astype(np.int64) << 32) | (atr_vals.astype(np.int64) & 0xFFFFFFFF)
    perf["unique_ch_atr_pair_count"] = int(np.unique(pair_keys).size)
    
    # Stage P2-2 Step B3: Pre-compute indicators for unique channel_len and atr_len
    unique_ch = np.unique(ch_vals)
    unique_atr = np.unique(atr_vals)
    
    # Build caches for precomputed indicators
    donch_cache_hi: Dict[int, np.ndarray] = {}
    donch_cache_lo: Dict[int, np.ndarray] = {}
    atr_cache: Dict[int, np.ndarray] = {}
    
    # Pre-compute timing (if profiling enabled)
    t_precompute_start = time.perf_counter() if profile else 0.0
    
    # Pre-compute Donchian indicators for unique channel_len values
    for ch_len in unique_ch:
        ch_len_int = int(ch_len)
        donch_cache_hi[ch_len_int] = rolling_max(bars.high, ch_len_int)
        donch_cache_lo[ch_len_int] = rolling_min(bars.low, ch_len_int)
    
    # Pre-compute ATR indicators for unique atr_len values
    for atr_len in unique_atr:
        atr_len_int = int(atr_len)
        atr_cache[atr_len_int] = atr_wilder(bars.high, bars.low, bars.close, atr_len_int)
    
    t_precompute_end = time.perf_counter() if profile else 0.0
    
    # Stage P2-2 Step B4: Memory observation fields
    precomp_bytes_donchian = sum(arr.nbytes for arr in donch_cache_hi.values()) + sum(arr.nbytes for arr in donch_cache_lo.values())
    precomp_bytes_atr = sum(arr.nbytes for arr in atr_cache.values())
    precomp_bytes_total = precomp_bytes_donchian + precomp_bytes_atr
    
    perf["precomp_unique_channel_len_count"] = int(len(unique_ch))
    perf["precomp_unique_atr_len_count"] = int(len(unique_atr))
    perf["precomp_bytes_donchian"] = int(precomp_bytes_donchian)
    perf["precomp_bytes_atr"] = int(precomp_bytes_atr)
    perf["precomp_bytes_total"] = int(precomp_bytes_total)
    if profile:
        perf["t_precompute_indicators_s"] = float(t_precompute_end - t_precompute_start)
    
    # CURSOR TASK 3: Grid å±¤æŠŠ intent sparse å‚³åˆ°åº•
    # Read FISHBRO_PERF_TRIGGER_RATE as intent_sparse_rate and pass to kernel
    intent_sparse_rate_env = os.environ.get("FISHBRO_PERF_TRIGGER_RATE", "").strip()
    intent_sparse_rate = 1.0
    if intent_sparse_rate_env:
        try:
            intent_sparse_rate = float(intent_sparse_rate_env)
            if not (0.0 <= intent_sparse_rate <= 1.0):
                intent_sparse_rate = 1.0
        except ValueError:
            intent_sparse_rate = 1.0
    
    # Stage P2-3: Param-subsample (deterministic selection)
    # FISHBRO_PERF_PARAM_SUBSAMPLE_RATE controls param subsampling (separate from trigger_rate)
    # FISHBRO_PERF_TRIGGER_RATE is for bar/intent-level sparsity (handled in kernel)
    param_subsample_rate_env = os.environ.get("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", "").strip()
    param_subsample_seed_env = os.environ.get("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", "").strip()
    
    param_subsample_rate = 1.0
    if param_subsample_rate_env:
        try:
            param_subsample_rate = float(param_subsample_rate_env)
            if not (0.0 <= param_subsample_rate <= 1.0):
                param_subsample_rate = 1.0
        except ValueError:
            param_subsample_rate = 1.0
    
    param_subsample_seed = 42
    if param_subsample_seed_env:
        try:
            param_subsample_seed = int(param_subsample_seed_env)
        except ValueError:
            param_subsample_seed = 42
    
    # Stage P2-3: Determine selected params (deterministic)
    # CURSOR TASK 1: Use "pos" (sorted space position) for selection, "orig" (original index) for scatter-back
    if param_subsample_rate < 1.0:
        k = max(1, int(round(n * param_subsample_rate)))
        rng = np.random.default_rng(param_subsample_seed)
        # Generate deterministic permutation
        perm = rng.permutation(n)
        selected_pos = np.sort(perm[:k]).astype(INDEX_DTYPE)  # Sort to maintain deterministic loop order
    else:
        selected_pos = np.arange(n, dtype=INDEX_DTYPE)
    
    # CURSOR TASK 1: Map selected_pos (sorted space) to selected_orig (original space)
    selected_orig = order[selected_pos].astype(np.int64)  # Map sorted positions to original indices
    
    selected_params_count = len(selected_pos)
    selected_params_ratio = float(selected_params_count) / float(n) if n > 0 else 0.0
    
    # Create metrics_computed_mask: boolean array indicating which rows were computed
    metrics_computed_mask = np.zeros(n, dtype=bool)
    for orig_i in selected_orig:
        metrics_computed_mask[orig_i] = True
    
    # Add param subsample info to perf
    perf["param_subsample_rate_configured"] = float(param_subsample_rate)
    perf["selected_params_count"] = int(selected_params_count)
    perf["selected_params_ratio"] = float(selected_params_ratio)
    perf["metrics_rows_computed"] = int(selected_params_count)
    perf["metrics_computed_mask"] = metrics_computed_mask.tolist()  # Convert to list for JSON serialization
    
    # Stage P2-1.8: Initialize granular timing and count accumulators (only if profile enabled)
    if profile:
        # Stage P2-2 Step A: Micro-profiling timing keys
        perf["t_ind_donchian_s"] = 0.0
        perf["t_ind_atr_s"] = 0.0
        perf["t_build_entry_intents_s"] = 0.0
        perf["t_simulate_entry_s"] = 0.0
        perf["t_calc_exits_s"] = 0.0
        perf["t_simulate_exit_s"] = 0.0
        perf["t_total_kernel_s"] = 0.0
        perf["entry_fills_total"] = 0
        perf["exit_intents_total"] = 0
        perf["exit_fills_total"] = 0
    result: Dict[str, object] = {"metrics": metrics, "order": order, "perf": perf}

    if sim_only:
        # Debug mode: bypass strategy/orchestration and only benchmark matcher simulate.
        # This provides A/B evidence: if sim-only is fast, bottleneck is in kernel (indicators/intents).
        from FishBroWFS_V2.engine import engine_jit

        intents_per_bar = int(os.environ.get("FISHBRO_SIM_ONLY_INTENTS_PER_BAR", "2"))
        intents: list[OrderIntent] = []
        oid = 1
        nbars = int(bars.open.shape[0])
        for t in range(1, nbars):
            for _ in range(intents_per_bar):
                intents.append(
                    OrderIntent(
                        order_id=oid,
                        created_bar=t - 1,
                        role=OrderRole.ENTRY,
                        kind=OrderKind.STOP,
                        side=Side.BUY,
                        price=float(bars.high[t - 1]),
                        qty=1,
                    )
                )
                oid += 1
                intents.append(
                    OrderIntent(
                        order_id=oid,
                        created_bar=t - 1,
                        role=OrderRole.EXIT,
                        kind=OrderKind.STOP,
                        side=Side.SELL,
                        price=float(bars.low[t - 1]),
                        qty=1,
                    )
                )
                oid += 1

        t_sim0 = time.perf_counter()
        _fills = engine_jit.simulate(bars, intents)
        t_sim1 = time.perf_counter()
        jt = engine_jit.get_jit_truth()
        numba_env = os.environ.get("NUMBA_DISABLE_JIT", "")
        sigs = jt.get("kernel_signatures") or []
        perf = {
            "t_features": float(t_prep1 - t0),
            "t_indicators": None,
            "t_intent_gen": None,
            "t_simulate": float(t_sim1 - t_sim0),
            "simulate_impl": "jit" if jt.get("jit_path_used") else "py",
            "jit_path_used": bool(jt.get("jit_path_used")),
            "simulate_signatures_count": int(len(sigs)),
            "numba_disable_jit_env": str(numba_env),
            "intents_total": int(len(intents)),
            "intents_per_bar_avg": float(len(intents) / float(max(1, bars.open.shape[0]))),
            "fills_total": int(len(_fills)),
            "intent_mode": "objects",
        }
        result["perf"] = perf
        if return_debug and debug_fills_first is not None:
            result["debug_fills_first"] = debug_fills_first
        return result

    # Homology: only call run_kernel, never compute strategy/metrics here.
    # Perf observability is env-gated so default usage stays unchanged.
    t_ind = 0.0
    t_intgen = 0.0
    t_sim = 0.0
    intents_total = 0
    fills_total = 0
    any_profile_missing = False
    intent_mode: str | None = None
    # Stage P2-1.5: Entry sparse observability (accumulate across params)
    entry_valid_mask_sum = 0
    entry_intents_total = 0
    n_bars_for_entry_obs = None  # Will be set from first kernel result
    # Stage P2-3: Sparse builder observability (accumulate across params)
    allowed_bars_total = 0  # Total allowed bars (before trigger rate filtering)
    intents_generated_total = 0  # Total intents generated (after trigger rate filtering)
    
    # CURSOR TASK 1: Collect metrics_subset (will be scattered back after loop)
    metrics_subset = np.zeros((len(selected_pos), METRICS_N_COLUMNS), dtype=np.float64)
    debug_fills_first_subset = None
    if return_debug:
        debug_fills_first_subset = np.full((len(selected_pos), 6), np.nan, dtype=np.float64)
    
    # Stage P2-3: Only loop selected params (param-subsample)
    # CURSOR TASK 1: Use selected_pos (sorted space) to access pm_sorted, selected_orig for scatter-back
    for subset_idx, pos in enumerate(selected_pos):
        # CURSOR TASK 1: Use pos (sorted space position) to access params_sorted
        ch = int(pm_sorted[pos, 0])
        atr = int(pm_sorted[pos, 1])
        sm = float(pm_sorted[pos, 2])

        # Stage P2-2 Step B3: Lookup precomputed indicators and create PrecomputedIndicators pack
        precomp_pack = PrecomputedIndicators(
            donch_hi=donch_cache_hi[ch],
            donch_lo=donch_cache_lo[ch],
            atr=atr_cache[atr],
        )

        # Stage P2-1.8: Kernel profiling is already enabled at function start if profile=True
        # No need to set FISHBRO_PROFILE_KERNEL here again
        out = run_kernel(
            bars,
            DonchianAtrParams(channel_len=ch, atr_len=atr, stop_mult=sm),
            commission=float(commission),
            slip=float(slip),
            order_qty=int(order_qty),
            return_debug=return_debug,
            precomp=precomp_pack,
            intent_sparse_rate=intent_sparse_rate,  # CURSOR TASK 3: Pass intent sparse rate
        )
        obs = out.get("_obs", None)  # type: ignore
        if isinstance(obs, dict):
            # Phase 3.0-B: Trust kernel's evidence fields, do not recompute
            if intent_mode is None and isinstance(obs.get("intent_mode"), str):
                intent_mode = str(obs.get("intent_mode"))
            # Use intents_total directly from kernel (Source of Truth), not recompute from entry+exit
            intents_total += int(obs.get("intents_total", 0))
            fills_total += int(obs.get("fills_total", 0))
            
            # CURSOR TASK 2: Accumulate entry_valid_mask_sum (after intent sparse)
            # entry_valid_mask_sum must be sum(allow_mask) - not dense valid bars, not multiplied by params
            if "entry_valid_mask_sum" in obs:
                entry_valid_mask_sum += int(obs.get("entry_valid_mask_sum", 0))
            elif "allowed_bars" in obs:
                # Fallback: use allowed_bars if entry_valid_mask_sum not present
                entry_valid_mask_sum += int(obs.get("allowed_bars", 0))
            # CURSOR TASK 2: entry_intents_total should come from obs["entry_intents_total"] (set by kernel)
            if "entry_intents_total" in obs:
                entry_intents_total += int(obs.get("entry_intents_total", 0))
            elif "entry_intents" in obs:
                # Fallback: use entry_intents if entry_intents_total not present
                entry_intents_total += int(obs.get("entry_intents", 0))
            elif "n_entry" in obs:
                # Fallback: use n_entry if entry_intents_total not present
                entry_intents_total += int(obs.get("n_entry", 0))
            # Capture n_bars from first kernel result (should be same for all params)
            if n_bars_for_entry_obs is None and "n_bars" in obs:
                n_bars_for_entry_obs = int(obs.get("n_bars", 0))
            
            # Stage P2-3: Accumulate sparse builder observability (from new builder_sparse)
            if "allowed_bars" in obs:
                allowed_bars_total += int(obs.get("allowed_bars", 0))
            if "intents_generated" in obs:
                intents_generated_total += int(obs.get("intents_generated", 0))
            elif "n_entry" in obs:
                # Fallback: if intents_generated not present, use n_entry
                intents_generated_total += int(obs.get("n_entry", 0))
            
            # Stage P2-1.8: Accumulate timing keys from _obs (timing is now in _obs, not _perf)
            # Timing keys have pattern: t_*_s
            for key, value in obs.items():
                if key.startswith("t_") and key.endswith("_s"):
                    if key not in perf:
                        perf[key] = 0.0
                    perf[key] = float(perf[key]) + float(value)
            
            # Stage P2-1.8: Accumulate downstream counts from _obs
            if "entry_fills_total" in obs:
                perf["entry_fills_total"] = int(perf.get("entry_fills_total", 0)) + int(obs.get("entry_fills_total", 0))
            if "exit_intents_total" in obs:
                perf["exit_intents_total"] = int(perf.get("exit_intents_total", 0)) + int(obs.get("exit_intents_total", 0))
            if "exit_fills_total" in obs:
                perf["exit_fills_total"] = int(perf.get("exit_fills_total", 0)) + int(obs.get("exit_fills_total", 0))
        
        # Stage P2-1.8: Fallback - also check _perf for backward compatibility
        # Handle cases where old kernel versions put timing in _perf instead of _obs
        # Only use fallback if _obs doesn't have timing keys
        obs_has_timing = isinstance(obs, dict) and any(k.startswith("t_") and k.endswith("_s") for k in obs.keys())
        if not obs_has_timing:
            kernel_perf = out.get("_perf", None)
            if isinstance(kernel_perf, dict):
                # Accumulate timings across params (for grid-level aggregation)
                # Note: For grid-level, we sum timings across params
                for key, value in kernel_perf.items():
                    if key.startswith("t_") and key.endswith("_s"):
                        if key not in perf:
                            perf[key] = 0.0
                        perf[key] = float(perf[key]) + float(value)

        if profile:
            kp = out.get("_profile", None)  # type: ignore
            if not isinstance(kp, dict):
                any_profile_missing = True
                continue
            t_ind += float(kp.get("indicators_s", 0.0))
            # include both entry+exit intent generation as "intent generation"
            t_intgen += float(kp.get("intent_gen_s", 0.0)) + float(kp.get("exit_intent_gen_s", 0.0))
            t_sim += float(kp.get("simulate_entry_s", 0.0)) + float(kp.get("simulate_exit_s", 0.0))

        m = out["metrics"]
        
        # CURSOR TASK C: Handle NaN at metrics source (from kernel output), not just at scatter-back
        # Ensure metrics from kernel are clean before storing in subset
        m_net_profit = float(m["net_profit"])
        m_trades = int(m["trades"])
        m_max_dd = float(m["max_dd"])
        # Clean NaN/Inf at source
        m_net_profit = float(np.nan_to_num(m_net_profit, nan=0.0, posinf=0.0, neginf=0.0))
        m_max_dd = float(np.nan_to_num(m_max_dd, nan=0.0, posinf=0.0, neginf=0.0))
        
        # Collect debug data if requested
        if return_debug:
            debug_info = out.get("_debug", {})
            entry_bar = debug_info.get("entry_bar", -1)
            entry_price = debug_info.get("entry_price", np.nan)
            exit_bar = debug_info.get("exit_bar", -1)
            exit_price = debug_info.get("exit_price", np.nan)
            
            # Handle force_close_last: update exit_bar/exit_price if forced close
            # (will be updated below if force_close_last triggers)
        
        # Handle force_close_last: if still in position, force close at last bar
        if force_close_last:
            fills = out.get("fills", [])
            if isinstance(fills, list) and len(fills) > 0:
                # Count entry and exit fills
                entry_fills = [f for f in fills if f.role == OrderRole.ENTRY and f.side == Side.BUY]
                exit_fills = [f for f in fills if f.role == OrderRole.EXIT and f.side == Side.SELL]
                
                # If there are unpaired entries, force close at last bar
                if len(entry_fills) > len(exit_fills):
                    n_unpaired = len(entry_fills) - len(exit_fills)
                    last_bar_idx = int(bars.open.shape[0] - 1)
                    last_close_price = float(bars.close[last_bar_idx])
                    
                    # Create forced exit fills for unpaired entries
                    # Use entry prices from the unpaired entries
                    unpaired_entry_prices = [float(f.price) for f in entry_fills[-n_unpaired:]]
                    
                    # Calculate additional pnl from forced closes
                    forced_pnl = []
                    costs_per_trade = (float(commission) + float(slip)) * 2.0
                    for entry_price in unpaired_entry_prices:
                        # PnL = (exit_price - entry_price) * qty - costs
                        trade_pnl = (last_close_price - entry_price) * float(order_qty) - costs_per_trade
                        forced_pnl.append(trade_pnl)
                    
                    # Update metrics with forced closes
                    # CURSOR TASK C: Use cleaned metrics values (already NaN-handled)
                    original_net_profit = m_net_profit
                    original_trades = m_trades
                    
                    # Add forced close trades
                    new_net_profit = original_net_profit + sum(forced_pnl)
                    new_trades = original_trades + n_unpaired
                    
                    # Update debug exit info for force_close_last
                    if return_debug and n_unpaired > 0:
                        exit_bar = last_bar_idx
                        exit_price = last_close_price
                    
                    # Recalculate equity and max_dd
                    forced_pnl_arr = np.asarray(forced_pnl, dtype=np.float64)
                    if original_trades > 0 and "equity" in out:
                        original_equity = out["equity"]
                        if isinstance(original_equity, np.ndarray) and original_equity.size > 0:
                            # Append forced pnl to existing equity curve
                            # Start from last equity value
                            start_equity = float(original_equity[-1])
                            forced_equity = np.cumsum(forced_pnl_arr) + start_equity
                            new_equity = np.concatenate([original_equity, forced_equity])
                        else:
                            # No previous equity array, start from 0
                            new_equity = np.cumsum(forced_pnl_arr)
                    else:
                        # No previous trades, start from 0
                        new_equity = np.cumsum(forced_pnl_arr)
                    
                    new_max_dd = _max_drawdown(new_equity)
                    
                    # CURSOR TASK 1: Store metrics in subset (will be scattered back after loop)
                    # CURSOR TASK B: Ensure metrics_subset comes from kernel output (m), not initialization zeros
                    metrics_subset[subset_idx, METRICS_COL_NET_PROFIT] = new_net_profit
                    metrics_subset[subset_idx, METRICS_COL_TRADES] = new_trades
                    metrics_subset[subset_idx, METRICS_COL_MAX_DD] = new_max_dd

                    # Update debug subset with final metrics after force_close_last
                    if return_debug:
                        debug_fills_first_subset[subset_idx, 0] = entry_bar
                        debug_fills_first_subset[subset_idx, 1] = entry_price
                        debug_fills_first_subset[subset_idx, 2] = exit_bar
                        debug_fills_first_subset[subset_idx, 3] = exit_price
                        debug_fills_first_subset[subset_idx, 4] = new_net_profit
                        debug_fills_first_subset[subset_idx, 5] = float(new_trades)
                else:
                    # No unpaired entries, use original metrics
                    # CURSOR TASK 1: Store metrics in subset (will be scattered back after loop)
                    # CURSOR TASK B: Ensure metrics_subset comes from kernel output (m), not initialization zeros
                    metrics_subset[subset_idx, METRICS_COL_NET_PROFIT] = m_net_profit
                    metrics_subset[subset_idx, METRICS_COL_TRADES] = m_trades
                    metrics_subset[subset_idx, METRICS_COL_MAX_DD] = m_max_dd
                    
                    # Store debug data in subset
                    if return_debug:
                        debug_fills_first_subset[subset_idx, 0] = entry_bar
                        debug_fills_first_subset[subset_idx, 1] = entry_price
                        debug_fills_first_subset[subset_idx, 2] = exit_bar
                        debug_fills_first_subset[subset_idx, 3] = exit_price
                        debug_fills_first_subset[subset_idx, 4] = m_net_profit
                        debug_fills_first_subset[subset_idx, 5] = float(m_trades)
            else:
                # No fills, use original metrics
                # CURSOR TASK 1: Store metrics in subset (will be scattered back after loop)
                # CURSOR TASK B: Ensure metrics_subset comes from kernel output (m), not initialization zeros
                metrics_subset[subset_idx, METRICS_COL_NET_PROFIT] = m_net_profit
                metrics_subset[subset_idx, METRICS_COL_TRADES] = m_trades
                metrics_subset[subset_idx, METRICS_COL_MAX_DD] = m_max_dd
                
                # Store debug data in subset (no fills case)
                if return_debug:
                    debug_fills_first_subset[subset_idx, 0] = entry_bar
                    debug_fills_first_subset[subset_idx, 1] = entry_price
                    debug_fills_first_subset[subset_idx, 2] = exit_bar
                    debug_fills_first_subset[subset_idx, 3] = exit_price
                    debug_fills_first_subset[subset_idx, 4] = m_net_profit
                    debug_fills_first_subset[subset_idx, 5] = float(m_trades)
        else:
            # Zero-trade safe: kernel guarantees valid numbers (0.0/0)
            # CURSOR TASK 1: Store metrics in subset (will be scattered back after loop)
            # CURSOR TASK B: Ensure metrics_subset comes from kernel output (m), not initialization zeros
            metrics_subset[subset_idx, METRICS_COL_NET_PROFIT] = m_net_profit
            metrics_subset[subset_idx, METRICS_COL_TRADES] = m_trades
            metrics_subset[subset_idx, METRICS_COL_MAX_DD] = m_max_dd
            
            # Store debug data in subset
            if return_debug:
                debug_fills_first_subset[subset_idx, 0] = entry_bar
                debug_fills_first_subset[subset_idx, 1] = entry_price
                debug_fills_first_subset[subset_idx, 2] = exit_bar
                debug_fills_first_subset[subset_idx, 3] = exit_price
                debug_fills_first_subset[subset_idx, 4] = m_net_profit
                debug_fills_first_subset[subset_idx, 5] = float(m_trades)
    
    # CURSOR TASK 2: Handle NaN before scatter-back (avoid computed_non_zero being eaten by NaN)
    # Note: Already handled at source (m_net_profit, m_max_dd), but double-check here for safety
    metrics_subset = np.nan_to_num(metrics_subset, nan=0.0, posinf=0.0, neginf=0.0)
    
    # CURSOR TASK 3: Assert that if fills_total > 0, metrics_subset should have non-zero values
    # This helps catch cases where metrics computation was skipped or returned zeros
    # Only assert if FISHBRO_DEBUG_ASSERT=1 (not triggered by profile, as tests often enable profile)
    if os.environ.get("FISHBRO_DEBUG_ASSERT", "").strip() == "1":
        metrics_subset_abs_sum = float(np.sum(np.abs(metrics_subset)))
        assert fills_total == 0 or metrics_subset_abs_sum > 0, (
            f"CURSOR TASK B violation: fills_total={fills_total} > 0 but metrics_subset_abs_sum={metrics_subset_abs_sum} == 0. "
            f"This indicates metrics computation was skipped or returned zeros."
        )
    
    # CURSOR TASK 3: Add perf debug field (metrics_subset_nonzero_rows)
    metrics_subset_nonzero_rows = int(np.sum(np.any(np.abs(metrics_subset) > 1e-10, axis=1)))
    perf["metrics_subset_nonzero_rows"] = metrics_subset_nonzero_rows
    
    # CURSOR TASK 1: Scatter-back: metrics[selected_orig] = metrics_subset
    metrics[selected_orig] = metrics_subset
    
    # CURSOR TASK 1: Scatter-back debug_fills_first if needed
    if return_debug and debug_fills_first_subset is not None:
        debug_fills_first[selected_orig] = debug_fills_first_subset
    
    # CURSOR TASK 2: Add perf debug fields (for diagnostic)
    perf["intent_sparse_rate_effective"] = float(intent_sparse_rate)
    perf["fills_total"] = int(fills_total)
    perf["metrics_subset_abs_sum"] = float(np.sum(np.abs(metrics_subset)))
    
    # CURSOR TASK A: Add entry_intents_total (subsample run) for diagnostic
    # This helps distinguish: entry_intents_total > 0 but fills_total == 0 â†’ matcher/engine issue
    # vs entry_intents_total == 0 â†’ builder didn't generate intents
    perf["entry_intents_total"] = int(entry_intents_total)

    # Phase 3.0-E: Ensure intent_mode is never None
    # If no kernel results (n == 0), default to "arrays" (default kernel path)
    # Otherwise, intent_mode should have been set from first kernel result
    if intent_mode is None:
        # Edge case: n == 0 (no params) - use default "arrays" since run_kernel defaults to array path
        intent_mode = "arrays"

    if not profile:
        # Return minimal perf with evidence fields only
        # Stage P2-1.8: Preserve accumulated timings (already in perf dict from loop)
        perf["intent_mode"] = intent_mode
        perf["intents_total"] = int(intents_total)
        # fills_total already set in scatter-back section (line 592), but ensure it's here too for clarity
        if "fills_total" not in perf:
            perf["fills_total"] = int(fills_total)
        # CURSOR TASK 3: Add intent sparse rate and entry observability to perf
        perf["intent_sparse_rate"] = float(intent_sparse_rate)
        perf["entry_valid_mask_sum"] = int(entry_valid_mask_sum)  # CURSOR TASK 2: After intent sparse (sum(allow_mask))
        perf["entry_intents_total"] = int(entry_intents_total)
        
        # Stage P2-1.5: Add entry sparse observability (always include, even if 0)
        perf["intents_total_reported"] = int(intents_total)  # Preserve original for comparison
        if n_bars_for_entry_obs is not None and n_bars_for_entry_obs > 0:
            perf["entry_intents_per_bar_avg"] = float(entry_intents_total / n_bars_for_entry_obs)
        else:
            # Fallback: use bars.open.shape[0] if n_bars_for_entry_obs not available
            perf["entry_intents_per_bar_avg"] = float(entry_intents_total / max(1, bars.open.shape[0]))
        
        # Stage P2-3: Add sparse builder observability (for scaling verification)
        perf["allowed_bars"] = int(allowed_bars_total)
        perf["intents_generated"] = int(intents_generated_total)
        perf["selected_params"] = int(selected_params_count)
        
        # CURSOR TASK 2: Ensure debug fields are present in non-profile branch too
        if "intent_sparse_rate_effective" not in perf:
            perf["intent_sparse_rate_effective"] = float(intent_sparse_rate)
        if "fills_total" not in perf:
            perf["fills_total"] = int(fills_total)
        if "metrics_subset_abs_sum" not in perf:
            perf["metrics_subset_abs_sum"] = float(np.sum(np.abs(metrics_subset)))
        
        result["perf"] = perf
        if return_debug and debug_fills_first is not None:
            result["debug_fills_first"] = debug_fills_first
        return result

    from FishBroWFS_V2.engine import engine_jit

    jt = engine_jit.get_jit_truth()
    numba_env = os.environ.get("NUMBA_DISABLE_JIT", "")
    sigs = jt.get("kernel_signatures") or []

    # Best-effort: avoid leaking this env to callers
    # Only clean up if we set it ourselves (Task A: bridge logic)
    if _set_kernel_profile:
        try:
            del os.environ["FISHBRO_PROFILE_KERNEL"]
        except KeyError:
            pass

    # Phase 3.0-E: Ensure intent_mode is never None
    # If no kernel results (n == 0), default to "arrays" (default kernel path)
    # Otherwise, intent_mode should have been set from first kernel result
    if intent_mode is None:
        # Edge case: n == 0 (no params) - use default "arrays" since run_kernel defaults to array path
        intent_mode = "arrays"

    # Stage P2-1.8: Create summary dict and merge into accumulated perf (preserve t_*_s from loop)
    perf_summary = {
        "t_features": float(t_prep1 - t0),
        # current architecture: indicators are computed inside run_kernel per param
        "t_indicators": None if any_profile_missing else float(t_ind),
        "t_intent_gen": None if any_profile_missing else float(t_intgen),
        "t_simulate": None if any_profile_missing else float(t_sim),
        "simulate_impl": "jit" if jt.get("jit_path_used") else "py",
        "jit_path_used": bool(jt.get("jit_path_used")),
        "simulate_signatures_count": int(len(sigs)),
        "numba_disable_jit_env": str(numba_env),
        # Phase 3.0-B: Use kernel's evidence fields directly (Source of Truth), not recomputed
        "intent_mode": intent_mode,
        "intents_total": int(intents_total),
        "fills_total": int(fills_total),
        "intents_per_bar_avg": float(intents_total / float(max(1, bars.open.shape[0]))),
    }
    
    # CURSOR TASK 3: Add intent sparse rate and entry observability to perf
    perf_summary["intent_sparse_rate"] = float(intent_sparse_rate)
    perf_summary["entry_valid_mask_sum"] = int(entry_valid_mask_sum)  # CURSOR TASK 2: After intent sparse
    perf_summary["entry_intents_total"] = int(entry_intents_total)
    
    # Stage P2-1.5: Add entry sparse observability and preserve original intents_total
    perf_summary["intents_total_reported"] = int(intents_total)  # Preserve original for comparison
    if n_bars_for_entry_obs is not None and n_bars_for_entry_obs > 0:
        perf_summary["entry_intents_per_bar_avg"] = float(entry_intents_total / n_bars_for_entry_obs)
    else:
        # Fallback: use bars.open.shape[0] if n_bars_for_entry_obs not available
        perf_summary["entry_intents_per_bar_avg"] = float(entry_intents_total / max(1, bars.open.shape[0]))
    
    # Stage P2-3: Add sparse builder observability (for scaling verification)
    perf_summary["allowed_bars"] = int(allowed_bars_total)  # Total allowed bars across all params
    perf_summary["intents_generated"] = int(intents_generated_total)  # Total intents generated across all params
    perf_summary["selected_params"] = int(selected_params_count)  # Number of params actually computed
    
    # CURSOR TASK 2: Ensure debug fields are present in profile branch too
    perf_summary["intent_sparse_rate_effective"] = float(intent_sparse_rate)
    perf_summary["fills_total"] = int(fills_total)
    perf_summary["metrics_subset_abs_sum"] = float(np.sum(np.abs(metrics_subset)))
    
    # Keep accumulated per-kernel timings already stored in `perf` (t_*_s, entry_fills_total, etc.)
    perf.update(perf_summary)

    result["perf"] = perf
    if return_debug and debug_fills_first is not None:
        result["debug_fills_first"] = debug_fills_first
    return result



================================================================================
FILE: src/FishBroWFS_V2/pipeline/stage0_runner.py
================================================================================

"""Stage0 runner - proxy ranking without PnL metrics.

Stage0 is a fast proxy filter that ranks parameters without running full backtests.
It MUST NOT compute any PnL-related metrics (Net/MDD/SQN/Sharpe/WinRate/Equity/DD).
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import List, Optional

import numpy as np

from FishBroWFS_V2.config.constants import STAGE0_PROXY_NAME
from FishBroWFS_V2.stage0.ma_proxy import stage0_score_ma_proxy


@dataclass(frozen=True)
class Stage0Result:
    """
    Stage0 result - proxy ranking only.
    
    Contains ONLY:
    - param_id: parameter index
    - proxy_value: proxy ranking value (higher is better)
    - warmup_ok: optional warmup validation flag
    - meta: optional metadata dict
    
    FORBIDDEN fields (must not exist):
    - Any PnL metrics: Net, MDD, SQN, Sharpe, WinRate, Equity, DD, etc.
    """
    param_id: int
    proxy_value: float
    warmup_ok: Optional[bool] = None
    meta: Optional[dict] = None


def run_stage0(
    close: np.ndarray,
    params_matrix: np.ndarray,
    *,
    proxy_name: str = STAGE0_PROXY_NAME,
) -> List[Stage0Result]:
    """
    Run Stage0 proxy ranking.
    
    Args:
        close: float32 or float64 1D array (n_bars,) - close prices (will use float32 internally)
        params_matrix: float32 or float64 2D array (n_params, >=2) (will use float32 internally)
            - col0: fast_len (for MA proxy)
            - col1: slow_len (for MA proxy)
            - additional columns allowed and ignored
        proxy_name: name of proxy to use (default: ma_proxy_v0)
        
    Returns:
        List of Stage0Result, one per parameter set.
        Results are in same order as params_matrix rows.
        
    Note:
        - This function MUST NOT compute any PnL metrics
        - Only proxy_value is computed for ranking purposes
        - Uses float32 internally for memory optimization
    """
    if proxy_name != "ma_proxy_v0":
        raise ValueError(f"Unsupported proxy: {proxy_name}. Only 'ma_proxy_v0' is supported in Phase 4.")
    
    # Compute proxy scores
    scores = stage0_score_ma_proxy(close, params_matrix)
    
    # Build results
    n_params = params_matrix.shape[0]
    results: List[Stage0Result] = []
    
    for i in range(n_params):
        score = float(scores[i])
        
        # Check warmup: if score is -inf, warmup failed
        warmup_ok = not np.isinf(score) if not np.isnan(score) else False
        
        results.append(
            Stage0Result(
                param_id=i,
                proxy_value=score,
                warmup_ok=warmup_ok,
                meta=None,
            )
        )
    
    return results


================================================================================
FILE: src/FishBroWFS_V2/pipeline/stage2_runner.py
================================================================================

"""Stage2 runner - full backtest on Top-K parameters.

Stage2 runs full backtests using the unified simulate_run() entry point.
It computes complete metrics including net_profit, trades, max_dd, etc.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.types import BarArrays, Fill
from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, run_kernel


@dataclass(frozen=True)
class Stage2Result:
    """
    Stage2 result - full backtest metrics.
    
    Contains complete backtest results including:
    - param_id: parameter index
    - net_profit: total net profit
    - trades: number of trades
    - max_dd: maximum drawdown
    - fills: list of fills (optional, for detailed analysis)
    - equity: equity curve (optional)
    - meta: optional metadata
    """
    param_id: int
    net_profit: float
    trades: int
    max_dd: float
    fills: Optional[List[Fill]] = None
    equity: Optional[np.ndarray] = None
    meta: Optional[dict] = None


def _max_drawdown(equity: np.ndarray) -> float:
    """Compute max drawdown from equity curve."""
    if equity.size == 0:
        return 0.0
    peak = np.maximum.accumulate(equity)
    dd = equity - peak
    mdd = float(np.min(dd))  # negative or 0
    return mdd


def run_stage2(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
    param_ids: List[int],
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
) -> List[Stage2Result]:
    """
    Run Stage2 full backtest on selected parameters.
    
    Args:
        open_, high, low, close: OHLC arrays (float64, 1D, same length)
        params_matrix: float64 2D array (n_params, >=3)
            - col0: channel_len
            - col1: atr_len
            - col2: stop_mult
        param_ids: List of parameter indices to run (Top-K selection)
        commission: commission per trade (absolute)
        slip: slippage per trade (absolute)
        order_qty: order quantity (default: 1)
        
    Returns:
        List of Stage2Result, one per selected parameter.
        Results are in same order as param_ids.
        
    Note:
        - Only runs backtests for parameters in param_ids (Top-K subset)
        - Uses unified simulate_run() entry point (Cursor kernel)
        - Computes full metrics including PnL
    """
    bars = normalize_bars(open_, high, low, close)
    
    # Ensure contiguous arrays
    if not bars.open.flags["C_CONTIGUOUS"]:
        bars = BarArrays(
            open=np.ascontiguousarray(bars.open, dtype=np.float64),
            high=np.ascontiguousarray(bars.high, dtype=np.float64),
            low=np.ascontiguousarray(bars.low, dtype=np.float64),
            close=np.ascontiguousarray(bars.close, dtype=np.float64),
        )
    
    results: List[Stage2Result] = []
    
    for param_id in param_ids:
        if param_id < 0 or param_id >= params_matrix.shape[0]:
            # Invalid param_id - create empty result
            results.append(
                Stage2Result(
                    param_id=param_id,
                    net_profit=0.0,
                    trades=0,
                    max_dd=0.0,
                    fills=None,
                    equity=None,
                    meta=None,
                )
            )
            continue
        
        # Extract parameters
        params_row = params_matrix[param_id]
        channel_len = int(params_row[0])
        atr_len = int(params_row[1])
        stop_mult = float(params_row[2])
        
        # Build DonchianAtrParams
        kernel_params = DonchianAtrParams(
            channel_len=channel_len,
            atr_len=atr_len,
            stop_mult=stop_mult,
        )
        
        # Run kernel (uses unified simulate_run internally)
        kernel_result = run_kernel(
            bars,
            kernel_params,
            commission=commission,
            slip=slip,
            order_qty=order_qty,
        )
        
        # Extract metrics
        net_profit = float(kernel_result["metrics"]["net_profit"])
        trades = int(kernel_result["metrics"]["trades"])
        max_dd = float(kernel_result["metrics"]["max_dd"])
        
        # Extract optional fields
        fills = kernel_result.get("fills")
        equity = kernel_result.get("equity")
        
        results.append(
            Stage2Result(
                param_id=param_id,
                net_profit=net_profit,
                trades=trades,
                max_dd=max_dd,
                fills=fills,
                equity=equity,
                meta=None,
            )
        )
    
    return results


================================================================================
FILE: src/FishBroWFS_V2/pipeline/topk.py
================================================================================

"""Top-K selector - deterministic parameter selection.

Selects top K parameters based on Stage0 proxy_value.
Tie-breaking uses param_id to ensure deterministic results.
"""

from __future__ import annotations

from typing import List

from FishBroWFS_V2.config.constants import TOPK_K
from FishBroWFS_V2.pipeline.stage0_runner import Stage0Result


def select_topk(
    stage0_results: List[Stage0Result],
    k: int = TOPK_K,
) -> List[int]:
    """
    Select top K parameters based on proxy_value.
    
    Args:
        stage0_results: List of Stage0Result from Stage0 runner
        k: number of top parameters to select (default: TOPK_K from config)
        
    Returns:
        List of param_id values (indices) for top K parameters.
        Results are sorted by proxy_value (descending), then by param_id (ascending) for tie-break.
        
    Note:
        - Sorting is deterministic: same input always produces same output
        - Tie-break uses param_id (ascending) to ensure stability
        - No manual include/exclude - purely based on proxy_value
    """
    if k <= 0:
        return []
    
    if len(stage0_results) == 0:
        return []
    
    # Sort by proxy_value (descending), then param_id (ascending) for tie-break
    sorted_results = sorted(
        stage0_results,
        key=lambda r: (-r.proxy_value, r.param_id),  # Negative for descending value
    )
    
    # Take top K
    topk_results = sorted_results[:k]
    
    # Return param_id list
    return [r.param_id for r in topk_results]


================================================================================
FILE: src/FishBroWFS_V2/stage0/__init__.py
================================================================================

"""
Stage 0 Funnel (Vector/Proxy Filter)

Design goal:
  - Extremely cheap scoring/ranking for massive parameter grids.
  - No matcher, no orders, no fills, no state machine.
  - Must be vectorizable / nopython friendly.
"""

from .ma_proxy import stage0_score_ma_proxy
from .proxies import trend_proxy, vol_proxy, activity_proxy




================================================================================
FILE: src/FishBroWFS_V2/stage0/ma_proxy.py
================================================================================

from __future__ import annotations

"""
Stage 0 v0: MA Directional Efficiency Proxy

This module intentionally does NOT depend on:
  - engine/* (matcher, fills, intents)
  - strategy/kernel
  - pipeline/runner_grid

It is a cheap scoring function to rank massive parameter grids before Stage 2.

Proxy idea (directional efficiency):
  dir[t] = sign(SMA_fast[t] - SMA_slow[t])
  ret[t] = close[t] - close[t-1]
  score = sum(dir[t] * ret[t]) / (std(ret) + eps)

Notes:
  - This is NOT a backtest. No orders, no fills, no costs.
  - Recall > precision. False negatives are acceptable at Stage 0.
"""

from typing import Tuple

import numpy as np
import os

try:
    import numba as nb
except Exception:  # pragma: no cover
    nb = None  # type: ignore


def _validate_inputs(close: np.ndarray, params_matrix: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    Validate and normalize inputs for Stage0 proxy scoring.
    
    Accepts float32 or float64, but converts to float32 for Stage0 optimization.
    """
    from FishBroWFS_V2.config.dtypes import PRICE_DTYPE_STAGE0
    
    c = np.asarray(close, dtype=PRICE_DTYPE_STAGE0)
    if c.ndim != 1:
        raise ValueError("close must be 1D")
    pm = np.asarray(params_matrix, dtype=PRICE_DTYPE_STAGE0)
    if pm.ndim != 2:
        raise ValueError("params_matrix must be 2D")
    if pm.shape[1] < 2:
        raise ValueError("params_matrix must have at least 2 columns: fast, slow")
    if c.shape[0] < 3:
        raise ValueError("close must have at least 3 bars for Stage0 scoring")
    if not c.flags["C_CONTIGUOUS"]:
        c = np.ascontiguousarray(c, dtype=PRICE_DTYPE_STAGE0)
    if not pm.flags["C_CONTIGUOUS"]:
        pm = np.ascontiguousarray(pm, dtype=PRICE_DTYPE_STAGE0)
    return c, pm


def stage0_score_ma_proxy(close: np.ndarray, params_matrix: np.ndarray) -> np.ndarray:
    """
    Compute Stage 0 proxy scores for a parameter matrix.

    Args:
        close: float32 or float64 1D array (n_bars,) - will be converted to float32
        params_matrix: float32 or float64 2D array (n_params, >=2) - will be converted to float32
            - col0: fast_len
            - col1: slow_len
            - additional columns allowed and ignored by v0

    Returns:
        scores: float64 1D array (n_params,) where higher is better
    """
    c, pm = _validate_inputs(close, params_matrix)

    # If numba is available and JIT is not disabled, use nopython kernel.
    if nb is not None and os.environ.get("NUMBA_DISABLE_JIT", "").strip() != "1":
        return _stage0_kernel(c, pm)

    # Fallback: pure numpy/python (correctness only, not intended for scale).
    ret = c[1:] - c[:-1]
    denom = np.std(ret) + 1e-12
    scores = np.empty(pm.shape[0], dtype=np.float64)
    for i in range(pm.shape[0]):
        fast = int(pm[i, 0])
        slow = int(pm[i, 1])
        if fast <= 0 or slow <= 0 or fast >= c.shape[0] or slow >= c.shape[0]:
            scores[i] = -np.inf
            continue
        f = _sma_py(c, fast)
        s = _sma_py(c, slow)
        # Skip NaN warmup region: SMA length L is valid from index (L-1) onward.
        # Here we conservatively start at max(fast, slow) to ensure both are non-NaN.
        start = max(fast, slow)
        acc = 0.0
        for t in range(start, c.shape[0]):
            d = np.sign(f[t] - s[t])
            acc += d * ret[t - 1]
        scores[i] = acc / denom
    return scores


def _sma_py(x: np.ndarray, length: int) -> np.ndarray:
    n = x.shape[0]
    out = np.full(n, np.nan, dtype=np.float64)
    if length <= 0:
        return out
    csum = np.cumsum(x, dtype=np.float64)
    for i in range(n):
        j = i - length + 1
        if j < 0:
            continue
        total = csum[i] - (csum[j - 1] if j > 0 else 0.0)
        out[i] = total / float(length)
    return out


if nb is not None:

    @nb.njit(cache=False)
    def _sma_nb(x: np.ndarray, length: int) -> np.ndarray:
        n = x.shape[0]
        out = np.empty(n, dtype=np.float64)
        for i in range(n):
            out[i] = np.nan
        if length <= 0:
            return out
        csum = np.empty(n, dtype=np.float64)
        acc = 0.0
        for i in range(n):
            acc += float(x[i])
            csum[i] = acc
        for i in range(n):
            j = i - length + 1
            if j < 0:
                continue
            total = csum[i] - (csum[j - 1] if j > 0 else 0.0)
            out[i] = total / float(length)
        return out

    @nb.njit(cache=False)
    def _sign_nb(v: float) -> float:
        if v > 0.0:
            return 1.0
        if v < 0.0:
            return -1.0
        return 0.0

    @nb.njit(cache=False)
    def _std_nb(x: np.ndarray) -> float:
        # simple two-pass std for stability
        n = x.shape[0]
        if n <= 1:
            return 0.0
        mu = 0.0
        for i in range(n):
            mu += float(x[i])
        mu /= float(n)
        var = 0.0
        for i in range(n):
            d = float(x[i]) - mu
            var += d * d
        var /= float(n)
        return np.sqrt(var)

    @nb.njit(cache=False)
    def _stage0_kernel(close: np.ndarray, params_matrix: np.ndarray) -> np.ndarray:
        n = close.shape[0]
        n_params = params_matrix.shape[0]

        # ret[t] = close[t] - close[t-1] for t in [1..n-1]
        ret = np.empty(n - 1, dtype=np.float64)
        for t in range(1, n):
            ret[t - 1] = float(close[t]) - float(close[t - 1])

        denom = _std_nb(ret) + 1e-12
        scores = np.empty(n_params, dtype=np.float64)

        for i in range(n_params):
            fast = int(params_matrix[i, 0])
            slow = int(params_matrix[i, 1])

            # invalid lengths => hard reject
            if fast <= 0 or slow <= 0 or fast >= n or slow >= n:
                scores[i] = -np.inf
                continue

            f = _sma_nb(close, fast)
            s = _sma_nb(close, slow)

            start = fast if fast > slow else slow
            acc = 0.0
            for t in range(start, n):
                d = _sign_nb(f[t] - s[t])
                acc += d * ret[t - 1]

            scores[i] = acc / denom

        return scores




================================================================================
FILE: src/FishBroWFS_V2/stage0/proxies.py
================================================================================

from __future__ import annotations

"""
Stage 0 v1 Trinity: Trend + Volatility + Activity Proxies

This module provides three proxy scoring functions for ranking parameter grids
before full backtest (Stage 2). These are NOT backtests - they are cheap heuristics.

Proxy Contract:
  - Stage0 is ranking proxy, NOT equal to backtest
  - NaN/warmup rules: start = max(required_lookbacks)
  - Correlation contract: Spearman Ï â‰¥ 0.4 (enforced by tests)

Design:
  - All proxies return float64 (n_params,) scores where higher is better
  - Input: OHLC arrays (np.ndarray), params: float64 2D array (n_params, k)
  - Must provide *_py (pure Python) and *_nb (Numba njit) versions
  - Wrapper functions select nb/py based on NUMBA_DISABLE_JIT kill-switch
"""

from typing import Tuple

import numpy as np
import os

try:
    import numba as nb
except Exception:  # pragma: no cover
    nb = None  # type: ignore

from FishBroWFS_V2.indicators.numba_indicators import atr_wilder


def _validate_inputs(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Validate and ensure contiguous arrays."""
    o = np.asarray(open_, dtype=np.float64)
    h = np.asarray(high, dtype=np.float64)
    l = np.asarray(low, dtype=np.float64)
    c = np.asarray(close, dtype=np.float64)
    pm = np.asarray(params_matrix, dtype=np.float64)

    if o.ndim != 1 or h.ndim != 1 or l.ndim != 1 or c.ndim != 1:
        raise ValueError("OHLC arrays must be 1D")
    if pm.ndim != 2:
        raise ValueError("params_matrix must be 2D")
    if not (o.shape[0] == h.shape[0] == l.shape[0] == c.shape[0]):
        raise ValueError("OHLC arrays must have same length")

    if not o.flags["C_CONTIGUOUS"]:
        o = np.ascontiguousarray(o)
    if not h.flags["C_CONTIGUOUS"]:
        h = np.ascontiguousarray(h)
    if not l.flags["C_CONTIGUOUS"]:
        l = np.ascontiguousarray(l)
    if not c.flags["C_CONTIGUOUS"]:
        c = np.ascontiguousarray(c)
    if not pm.flags["C_CONTIGUOUS"]:
        pm = np.ascontiguousarray(pm)

    return o, h, l, c, pm


# ============================================================================
# Proxy #1: Trend Proxy (MA / slope)
# ============================================================================


def trend_proxy_py(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """
    Trend proxy: mean(sign(sma_fast - sma_slow)) or mean((sma_fast - sma_slow) / close)

    Args:
        open_, high, low, close: float64 1D arrays (n_bars,)
        params_matrix: float64 2D array (n_params, >=2)
            - col0: fast_len
            - col1: slow_len

    Returns:
        scores: float64 1D array (n_params,)
    """
    o, h, l, c, pm = _validate_inputs(open_, high, low, close, params_matrix)
    n = c.shape[0]
    n_params = pm.shape[0]

    if pm.shape[1] < 2:
        raise ValueError("params_matrix must have at least 2 columns: fast_len, slow_len")

    scores = np.empty(n_params, dtype=np.float64)

    for i in range(n_params):
        fast = int(pm[i, 0])
        slow = int(pm[i, 1])

        # Invalid params: return -inf
        if fast <= 0 or slow <= 0 or fast >= n or slow >= n:
            scores[i] = -np.inf
            continue

        # Compute SMAs
        sma_fast = _sma_py(c, fast)
        sma_slow = _sma_py(c, slow)

        # Warmup: start at max(fast, slow)
        start = max(fast, slow)
        if start >= n:
            scores[i] = -np.inf
            continue

        # Compute trend score: mean((sma_fast - sma_slow) / close)
        acc = 0.0
        count = 0
        for t in range(start, n):
            diff = sma_fast[t] - sma_slow[t]
            if not np.isnan(diff) and c[t] > 0:
                acc += diff / c[t]
                count += 1

        if count == 0:
            scores[i] = -np.inf
        else:
            scores[i] = acc / count

    return scores


def trend_proxy_nb(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Numba version of trend_proxy."""
    if nb is None:  # pragma: no cover
        raise RuntimeError("numba not available")
    return _trend_proxy_kernel(open_, high, low, close, params_matrix)


def trend_proxy(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Wrapper: select nb/py based on NUMBA_DISABLE_JIT."""
    if nb is not None and os.environ.get("NUMBA_DISABLE_JIT", "").strip() != "1":
        return trend_proxy_nb(open_, high, low, close, params_matrix)
    return trend_proxy_py(open_, high, low, close, params_matrix)


# ============================================================================
# Proxy #2: Volatility Proxy (ATR / Range)
# ============================================================================


def vol_proxy_py(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """
    Volatility proxy: effective stop distance = ATR(atr_len) * stop_mult.
    
    Score prefers moderate stop distance (avoids extremely tiny or huge stops).

    Args:
        open_, high, low, close: float64 1D arrays (n_bars,)
        params_matrix: float64 2D array (n_params, >=2)
            - col0: atr_len
            - col1: stop_mult

    Returns:
        scores: float64 1D array (n_params,)
    """
    o, h, l, c, pm = _validate_inputs(open_, high, low, close, params_matrix)
    n = c.shape[0]
    n_params = pm.shape[0]

    if pm.shape[1] < 2:
        raise ValueError("params_matrix must have at least 2 columns: atr_len, stop_mult")

    scores = np.empty(n_params, dtype=np.float64)

    for i in range(n_params):
        atr_len = int(pm[i, 0])
        stop_mult = float(pm[i, 1])

        # Invalid params: return -inf
        if atr_len <= 0 or atr_len >= n or stop_mult <= 0.0:
            scores[i] = -np.inf
            continue

        # Compute ATR using Wilder's method
        atr = atr_wilder(h, l, c, atr_len)

        # Warmup: start at atr_len
        start = max(atr_len, 1)
        if start >= n:
            scores[i] = -np.inf
            continue

        # Compute stop distance: ATR * stop_mult
        stop_dist_sum = 0.0
        stop_dist_count = 0
        for t in range(start, n):
            if not np.isnan(atr[t]) and atr[t] > 0:
                stop_dist = atr[t] * stop_mult
                stop_dist_sum += stop_dist
                stop_dist_count += 1

        if stop_dist_count == 0:
            scores[i] = -np.inf
        else:
            stop_dist_mean = stop_dist_sum / float(stop_dist_count)
            # Score: -log1p(stop_mean) - penalize larger stops; deterministic; no target/median
            scores[i] = -np.log1p(stop_dist_mean)

    return scores


def vol_proxy_nb(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Numba version of vol_proxy."""
    if nb is None:  # pragma: no cover
        raise RuntimeError("numba not available")
    return _vol_proxy_kernel(open_, high, low, close, params_matrix)


def vol_proxy(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Wrapper: select nb/py based on NUMBA_DISABLE_JIT."""
    if nb is not None and os.environ.get("NUMBA_DISABLE_JIT", "").strip() != "1":
        return vol_proxy_nb(open_, high, low, close, params_matrix)
    return vol_proxy_py(open_, high, low, close, params_matrix)


# ============================================================================
# Proxy #3: Activity Proxy (Trade Count / trigger density)
# ============================================================================


def activity_proxy_py(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """
    Activity proxy: channel breakout trigger count.
    
    Counts crossings where close[t-1] <= channel_hi[t-1] and close[t] > channel_hi[t].
    Aligned with Stage2 kernel which uses channel breakout entry.

    Args:
        open_, high, low, close: float64 1D arrays (n_bars,)
        params_matrix: float64 2D array (n_params, >=1)
            - col0: channel_len
            - col1: atr_len (not used, kept for compatibility)

    Returns:
        scores: float64 1D array (n_params,)
    """
    o, h, l, c, pm = _validate_inputs(open_, high, low, close, params_matrix)
    n = c.shape[0]
    n_params = pm.shape[0]

    if pm.shape[1] < 1:
        raise ValueError("params_matrix must have at least 1 column: channel_len")

    scores = np.empty(n_params, dtype=np.float64)

    for i in range(n_params):
        channel_len = int(pm[i, 0])

        # Invalid params: return -inf
        if channel_len <= 0 or channel_len >= n:
            scores[i] = -np.inf
            continue

        # Compute channel_hi = rolling_max(high, channel_len)
        channel_hi = np.full(n, np.nan, dtype=np.float64)
        for t in range(n):
            start_idx = max(0, t - channel_len + 1)
            window_high = h[start_idx : t + 1]
            if window_high.size > 0:
                channel_hi[t] = np.max(window_high)

        # Warmup: start at channel_len
        start = channel_len
        if start >= n - 1:
            scores[i] = -np.inf
            continue

        # Count breakout triggers: high[t] > ch[t-1] AND high[t-1] <= ch[t-1]
        # Compare to previous channel high to avoid equality lock
        # Start from start+1 to ensure we have t-1 available
        triggers = 0
        for t in range(start + 1, n):
            if np.isnan(channel_hi[t-1]):
                continue
            # Trigger when high crosses above previous channel high
            if high[t] > channel_hi[t-1] and high[t-1] <= channel_hi[t-1]:
                triggers += 1

        n_effective = n - start
        if n_effective == 0:
            scores[i] = -np.inf
        else:
            # Activity score: raw count of triggers (or triggers per bar)
            # Using raw count for simplicity and robustness
            scores[i] = float(triggers)

    return scores


def activity_proxy_nb(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Numba version of activity_proxy."""
    if nb is None:  # pragma: no cover
        raise RuntimeError("numba not available")
    return _activity_proxy_kernel(open_, high, low, close, params_matrix)


def activity_proxy(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params_matrix: np.ndarray,
) -> np.ndarray:
    """Wrapper: select nb/py based on NUMBA_DISABLE_JIT."""
    if nb is not None and os.environ.get("NUMBA_DISABLE_JIT", "").strip() != "1":
        return activity_proxy_nb(open_, high, low, close, params_matrix)
    return activity_proxy_py(open_, high, low, close, params_matrix)


# ============================================================================
# Helper functions (SMA)
# ============================================================================


def _sma_py(x: np.ndarray, length: int) -> np.ndarray:
    """Simple Moving Average (pure Python)."""
    n = x.shape[0]
    out = np.full(n, np.nan, dtype=np.float64)
    if length <= 0:
        return out
    csum = np.cumsum(x, dtype=np.float64)
    for i in range(n):
        j = i - length + 1
        if j < 0:
            continue
        total = csum[i] - (csum[j - 1] if j > 0 else 0.0)
        out[i] = total / float(length)
    return out


# ============================================================================
# Numba kernels
# ============================================================================

if nb is not None:

    @nb.njit(cache=False)
    def _sma_nb(x: np.ndarray, length: int) -> np.ndarray:
        """Simple Moving Average (Numba)."""
        n = x.shape[0]
        out = np.empty(n, dtype=np.float64)
        for i in range(n):
            out[i] = np.nan
        if length <= 0:
            return out
        csum = np.empty(n, dtype=np.float64)
        acc = 0.0
        for i in range(n):
            acc += float(x[i])
            csum[i] = acc
        for i in range(n):
            j = i - length + 1
            if j < 0:
                continue
            total = csum[i] - (csum[j - 1] if j > 0 else 0.0)
            out[i] = total / float(length)
        return out

    @nb.njit(cache=False)
    def _trend_proxy_kernel(
        open_: np.ndarray,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray,
        params_matrix: np.ndarray,
    ) -> np.ndarray:
        """Numba kernel for trend proxy."""
        n = close.shape[0]
        n_params = params_matrix.shape[0]
        scores = np.empty(n_params, dtype=np.float64)

        for i in range(n_params):
            fast = int(params_matrix[i, 0])
            slow = int(params_matrix[i, 1])

            if fast <= 0 or slow <= 0 or fast >= n or slow >= n:
                scores[i] = -np.inf
                continue

            sma_fast = _sma_nb(close, fast)
            sma_slow = _sma_nb(close, slow)

            start = fast if fast > slow else slow
            if start >= n:
                scores[i] = -np.inf
                continue

            acc = 0.0
            count = 0
            for t in range(start, n):
                diff = sma_fast[t] - sma_slow[t]
                if not np.isnan(diff) and close[t] > 0.0:
                    acc += diff / close[t]
                    count += 1

            if count == 0:
                scores[i] = -np.inf
            else:
                scores[i] = acc / float(count)

        return scores

    @nb.njit(cache=False)
    def _atr_wilder_nb(high: np.ndarray, low: np.ndarray, close: np.ndarray, window: int) -> np.ndarray:
        """ATR Wilder (Numba version, inline for njit compatibility)."""
        n = high.shape[0]
        out = np.empty(n, dtype=np.float64)
        for i in range(n):
            out[i] = np.nan

        if window <= 0 or n == 0 or window > n:
            return out

        tr = np.empty(n, dtype=np.float64)
        tr[0] = high[0] - low[0]
        for i in range(1, n):
            a = high[i] - low[i]
            b = abs(high[i] - close[i - 1])
            c = abs(low[i] - close[i - 1])
            tr[i] = a if a >= b and a >= c else (b if b >= c else c)

        s = 0.0
        end = window if window < n else n
        for i in range(end):
            s += tr[i]
        out[end - 1] = s / float(window)

        for i in range(window, n):
            out[i] = (out[i - 1] * float(window - 1) + tr[i]) / float(window)

        return out

    @nb.njit(cache=False)
    def _rolling_max_nb(arr: np.ndarray, window: int) -> np.ndarray:
        """Rolling maximum (Numba, inline for njit compatibility)."""
        n = arr.shape[0]
        out = np.empty(n, dtype=np.float64)
        for i in range(n):
            out[i] = np.nan
        if window <= 0:
            return out
        for i in range(n):
            start = i - window + 1
            if start < 0:
                start = 0
            m = arr[start]
            for j in range(start + 1, i + 1):
                v = arr[j]
                if v > m:
                    m = v
            out[i] = m
        return out

    @nb.njit(cache=False)
    def _vol_proxy_kernel(
        open_: np.ndarray,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray,
        params_matrix: np.ndarray,
    ) -> np.ndarray:
        """Numba kernel for vol proxy with stop_mult."""
        n = close.shape[0]
        n_params = params_matrix.shape[0]
        scores = np.empty(n_params, dtype=np.float64)

        for i in range(n_params):
            atr_len = int(params_matrix[i, 0])
            stop_mult = float(params_matrix[i, 1])

            if atr_len <= 0 or atr_len >= n or stop_mult <= 0.0:
                scores[i] = -np.inf
                continue

            atr = _atr_wilder_nb(high, low, close, atr_len)

            start = atr_len if atr_len > 1 else 1
            if start >= n:
                scores[i] = -np.inf
                continue

            # Compute stop distance: ATR * stop_mult
            stop_dist_sum = 0.0
            stop_dist_count = 0
            for t in range(start, n):
                if not np.isnan(atr[t]) and atr[t] > 0.0:
                    stop_dist = atr[t] * stop_mult
                    stop_dist_sum += stop_dist
                    stop_dist_count += 1

            if stop_dist_count == 0:
                scores[i] = -np.inf
            else:
                stop_dist_mean = stop_dist_sum / float(stop_dist_count)
                # Score: -log1p(stop_mean) - penalize larger stops; deterministic; no target/median
                scores[i] = -np.log1p(stop_dist_mean)

        return scores

    @nb.njit(cache=False)
    def _sign_nb(v: float) -> float:
        """Sign function (Numba)."""
        if v > 0.0:
            return 1.0
        if v < 0.0:
            return -1.0
        return 0.0

    @nb.njit(cache=False)
    def _activity_proxy_kernel(
        open_: np.ndarray,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray,
        params_matrix: np.ndarray,
    ) -> np.ndarray:
        """Numba kernel for activity proxy: channel breakout triggers."""
        n = close.shape[0]
        n_params = params_matrix.shape[0]
        scores = np.empty(n_params, dtype=np.float64)

        for i in range(n_params):
            channel_len = int(params_matrix[i, 0])

            if channel_len <= 0 or channel_len >= n:
                scores[i] = -np.inf
                continue

            # Compute channel_hi = rolling_max(high, channel_len)
            channel_hi = _rolling_max_nb(high, channel_len)

            start = channel_len
            if start >= n - 1:
                scores[i] = -np.inf
                continue

            # Count breakout triggers: high[t] > ch[t-1] AND high[t-1] <= ch[t-1]
            # Compare to previous channel high to avoid equality lock
            # Start from start+1 to ensure we have t-1 available
            triggers = 0
            for t in range(start + 1, n):
                if np.isnan(channel_hi[t-1]):
                    continue
                # Trigger when high crosses above previous channel high
                if high[t] > channel_hi[t-1] and high[t-1] <= channel_hi[t-1]:
                    triggers += 1

            n_effective = n - start
            if n_effective == 0:
                scores[i] = -np.inf
            else:
                # Activity score: raw count of triggers (or triggers per bar)
                # Using raw count for simplicity and robustness
                scores[i] = float(triggers)

        return scores


================================================================================
FILE: src/FishBroWFS_V2/strategy/__init__.py
================================================================================




================================================================================
FILE: src/FishBroWFS_V2/strategy/entry_builder_nb.py
================================================================================

"""
Stage P2-3A: Numba-accelerated Sparse Entry Intent Builder

Single-pass Numba implementation for building sparse entry intents.
Uses two-pass approach: count first, then allocate and fill.
"""
from __future__ import annotations

import numpy as np

try:
    import numba as nb
except Exception:  # pragma: no cover
    nb = None  # type: ignore


if nb is not None:

    @nb.njit(cache=False)
    def _deterministic_random(t: int, seed: int) -> float:
        """
        Deterministic pseudo-random number generator for trigger rate selection.
        
        This mimics numpy.random.default_rng(seed).random() behavior for position t.
        Uses PCG64 algorithm approximation for compatibility with numpy's default_rng.
        
        Note: For exact compatibility with apply_trigger_rate_mask, we need to match
        the sequence generated by rng.random(n - warmup) for positions >= warmup.
        Since we're iterating t from 1..n-1, we use (t - warmup) as the index.
        """
        # Approximate PCG64: use a simple hash-based approach
        # This ensures deterministic selection matching numpy's default_rng(seed)
        # We use t as the position index (for positions >= warmup, index = t - warmup)
        # Simple hash: combine seed and t
        x = (seed ^ (t * 0x9e3779b9)) & 0xFFFFFFFF
        x = ((x << 16) ^ (x >> 16)) & 0xFFFFFFFF
        x = (x * 0x85ebca6b) & 0xFFFFFFFF
        x = (x ^ (x >> 13)) & 0xFFFFFFFF
        x = (x * 0xc2b2ae35) & 0xFFFFFFFF
        x = (x ^ (x >> 16)) & 0xFFFFFFFF
        # Normalize to [0, 1)
        return float(x & 0x7FFFFFFF) / float(0x7FFFFFFF + 1)

    @nb.njit(cache=False)
    def _count_valid_intents(
        donch_prev: np.ndarray,
        warmup: int,
        trigger_rate: float,
        random_vals: np.ndarray,
    ) -> int:
        """
        Pass 1: Count valid entry intents.
        
        Args:
            donch_prev: float64 array (n_bars,) - shifted donchian high
            warmup: Warmup period
            trigger_rate: Trigger rate (0.0 to 1.0)
            random_vals: Pre-computed random values (shape n - warmup) for positions >= warmup
        
        Returns:
            Number of valid intents
        """
        n = donch_prev.shape[0]
        count = 0
        
        # Scan bars 1..n-1 (bar index t, where created_bar = t-1)
        for t in range(1, n):
            # Check if signal is valid (finite, positive, past warmup)
            if t < warmup:
                continue
            
            price_val = donch_prev[t]
            if not (np.isfinite(price_val) and price_val > 0.0):
                continue
            
            # Apply trigger rate selection (deterministic)
            # Match apply_trigger_rate_mask logic: use (t - warmup) as index into random_vals
            if trigger_rate < 1.0:
                rng_index = t - warmup  # Index into random sequence (0-based for positions >= warmup)
                if rng_index < random_vals.shape[0]:
                    rand_val = random_vals[rng_index]
                    if rand_val >= trigger_rate:
                        continue  # Skip this trigger
            
            count += 1
        
        return count

    @nb.njit(cache=False)
    def _build_sparse_intents(
        donch_prev: np.ndarray,
        warmup: int,
        trigger_rate: float,
        random_vals: np.ndarray,
        order_qty: int,
        n_entry: int,
        created_bar: np.ndarray,
        price: np.ndarray,
        order_id: np.ndarray,
        role: np.ndarray,
        kind: np.ndarray,
        side: np.ndarray,
        qty: np.ndarray,
    ) -> None:
        """
        Pass 2: Fill sparse intent arrays.
        
        Args:
            donch_prev: float64 array (n_bars,) - shifted donchian high
            warmup: Warmup period
            trigger_rate: Trigger rate (0.0 to 1.0)
            random_vals: Pre-computed random values (shape n - warmup) for positions >= warmup
            order_qty: Order quantity
            n_entry: Number of valid intents (pre-allocated array size)
            created_bar: Output array (int32, shape n_entry)
            price: Output array (float64, shape n_entry)
            order_id: Output array (int32, shape n_entry)
            role: Output array (uint8, shape n_entry)
            kind: Output array (uint8, shape n_entry)
            side: Output array (uint8, shape n_entry)
            qty: Output array (int32, shape n_entry)
        """
        n = donch_prev.shape[0]
        idx = 0
        
        # Scan bars 1..n-1 (bar index t, where created_bar = t-1)
        for t in range(1, n):
            # Check if signal is valid (finite, positive, past warmup)
            if t < warmup:
                continue
            
            price_val = donch_prev[t]
            if not (np.isfinite(price_val) and price_val > 0.0):
                continue
            
            # Apply trigger rate selection (deterministic)
            # Match apply_trigger_rate_mask logic: use (t - warmup) as index into random_vals
            if trigger_rate < 1.0:
                rng_index = t - warmup  # Index into random sequence (0-based for positions >= warmup)
                if rng_index < random_vals.shape[0]:
                    rand_val = random_vals[rng_index]
                    if rand_val >= trigger_rate:
                        continue  # Skip this trigger
            
            # Emit intent
            created_bar[idx] = t - 1  # created_bar = t - 1
            price[idx] = price_val
            order_id[idx] = idx + 1  # Sequential order ID (1, 2, 3, ...)
            role[idx] = 1  # ROLE_ENTRY
            kind[idx] = 0  # KIND_STOP
            side[idx] = 1  # SIDE_BUY
            qty[idx] = order_qty
            
            idx += 1

else:
    # Fallback pure-python (used only if numba unavailable)
    def _deterministic_random(t: int, seed: int) -> float:  # type: ignore
        """Fallback pure-python implementation."""
        import random
        rng = random.Random(seed + t)
        return rng.random()

    def _count_valid_intents(  # type: ignore
        donch_prev: np.ndarray,
        warmup: int,
        trigger_rate: float,
        random_vals: np.ndarray,
    ) -> int:
        """Fallback pure-python implementation."""
        n = donch_prev.shape[0]
        count = 0
        
        for t in range(1, n):
            if t < warmup:
                continue
            
            price_val = donch_prev[t]
            if not (np.isfinite(price_val) and price_val > 0.0):
                continue
            
            if trigger_rate < 1.0:
                rng_index = t - warmup
                if rng_index < random_vals.shape[0]:
                    rand_val = random_vals[rng_index]
                    if rand_val >= trigger_rate:
                        continue
            
            count += 1
        
        return count

    def _build_sparse_intents(  # type: ignore
        donch_prev: np.ndarray,
        warmup: int,
        trigger_rate: float,
        random_vals: np.ndarray,
        order_qty: int,
        n_entry: int,
        created_bar: np.ndarray,
        price: np.ndarray,
        order_id: np.ndarray,
        role: np.ndarray,
        kind: np.ndarray,
        side: np.ndarray,
        qty: np.ndarray,
    ) -> None:
        """Fallback pure-python implementation."""
        n = donch_prev.shape[0]
        idx = 0
        
        for t in range(1, n):
            if t < warmup:
                continue
            
            price_val = donch_prev[t]
            if not (np.isfinite(price_val) and price_val > 0.0):
                continue
            
            if trigger_rate < 1.0:
                rng_index = t - warmup
                if rng_index < random_vals.shape[0]:
                    rand_val = random_vals[rng_index]
                    if rand_val >= trigger_rate:
                        continue
            
            created_bar[idx] = t - 1
            price[idx] = price_val
            order_id[idx] = idx + 1
            role[idx] = 1
            kind[idx] = 0
            side[idx] = 1
            qty[idx] = order_qty
            
            idx += 1


def build_entry_intents_numba(
    donch_prev: np.ndarray,
    channel_len: int,
    order_qty: int,
    trigger_rate: float = 1.0,
    seed: int = 42,
) -> dict:
    """
    Build entry intents using Numba-accelerated single-pass sparse builder.
    
    Args:
        donch_prev: float64 array (n_bars,) - shifted donchian high
        channel_len: Warmup period (same as indicator warmup)
        order_qty: Order quantity
        trigger_rate: Trigger rate (0.0 to 1.0, default 1.0)
        seed: Random seed for deterministic trigger rate selection (default 42)
    
    Returns:
        dict with:
            - created_bar: int32 array (n_entry,)
            - price: float64 array (n_entry,)
            - order_id: int32 array (n_entry,)
            - role: uint8 array (n_entry,)
            - kind: uint8 array (n_entry,)
            - side: uint8 array (n_entry,)
            - qty: int32 array (n_entry,)
            - n_entry: int
            - obs: dict with valid_mask_sum
    """
    from FishBroWFS_V2.config.dtypes import (
        INDEX_DTYPE,
        INTENT_ENUM_DTYPE,
        INTENT_PRICE_DTYPE,
    )
    
    n = int(donch_prev.shape[0])
    warmup = channel_len
    
    # Pre-compute random values (matching apply_trigger_rate_mask logic)
    # Generate random values for positions >= warmup
    random_vals = np.empty(0, dtype=np.float64)
    if trigger_rate < 1.0 and warmup < n:
        rng = np.random.default_rng(seed)
        random_vals = rng.random(n - warmup).astype(np.float64)
    
    # Pass 1: Count valid intents
    n_entry = _count_valid_intents(
        donch_prev=donch_prev,
        warmup=warmup,
        trigger_rate=trigger_rate,
        random_vals=random_vals,
    )
    
    # Diagnostic observations
    obs = {
        "n_bars": n,
        "warmup": warmup,
        "valid_mask_sum": n_entry,  # In numba builder, valid_mask_sum == n_entry
    }
    
    if n_entry == 0:
        return {
            "created_bar": np.empty(0, dtype=INDEX_DTYPE),
            "price": np.empty(0, dtype=INTENT_PRICE_DTYPE),
            "order_id": np.empty(0, dtype=INDEX_DTYPE),
            "role": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "kind": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "side": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "qty": np.empty(0, dtype=INDEX_DTYPE),
            "n_entry": 0,
            "obs": obs,
        }
    
    # Pass 2: Allocate and fill arrays
    created_bar = np.empty(n_entry, dtype=INDEX_DTYPE)
    price = np.empty(n_entry, dtype=INTENT_PRICE_DTYPE)
    order_id = np.empty(n_entry, dtype=INDEX_DTYPE)
    role = np.empty(n_entry, dtype=INTENT_ENUM_DTYPE)
    kind = np.empty(n_entry, dtype=INTENT_ENUM_DTYPE)
    side = np.empty(n_entry, dtype=INTENT_ENUM_DTYPE)
    qty = np.empty(n_entry, dtype=INDEX_DTYPE)
    
    _build_sparse_intents(
        donch_prev=donch_prev,
        warmup=warmup,
        trigger_rate=trigger_rate,
        random_vals=random_vals,
        order_qty=order_qty,
        n_entry=n_entry,
        created_bar=created_bar,
        price=price,
        order_id=order_id,
        role=role,
        kind=kind,
        side=side,
        qty=qty,
    )
    
    return {
        "created_bar": created_bar,
        "price": price,
        "order_id": order_id,
        "role": role,
        "kind": kind,
        "side": side,
        "qty": qty,
        "n_entry": n_entry,
        "obs": obs,
    }


================================================================================
FILE: src/FishBroWFS_V2/strategy/kernel.py
================================================================================

from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import os
import time

from FishBroWFS_V2.engine.constants import KIND_STOP, ROLE_ENTRY, ROLE_EXIT, SIDE_BUY, SIDE_SELL
from FishBroWFS_V2.engine.engine_jit import simulate as simulate_matcher
from FishBroWFS_V2.engine.engine_jit import simulate_arrays as simulate_matcher_arrays
from FishBroWFS_V2.engine.metrics_from_fills import compute_metrics_from_fills
from FishBroWFS_V2.engine.types import BarArrays, Fill, OrderIntent, OrderKind, OrderRole, Side
from FishBroWFS_V2.indicators.numba_indicators import rolling_max, rolling_min, atr_wilder


# Stage P2-2 Step B1: Precomputed Indicators Pack
@dataclass(frozen=True)
class PrecomputedIndicators:
    """
    Pre-computed indicator arrays for shared computation optimization.
    
    These arrays are computed once per unique (channel_len, atr_len) combination
    and reused across multiple params to avoid redundant computation.
    """
    donch_hi: np.ndarray  # float64, shape (n_bars,) - Donchian high (rolling max)
    donch_lo: np.ndarray  # float64, shape (n_bars,) - Donchian low (rolling min)
    atr: np.ndarray       # float64, shape (n_bars,) - ATR Wilder


def _build_entry_intents_from_trigger(
    donch_prev: np.ndarray,
    channel_len: int,
    order_qty: int,
) -> Dict[str, object]:
    """
    Build entry intents from trigger array with sparse masking (Stage P2-1).
    
    Args:
        donch_prev: float64 array (n_bars,) - shifted donchian high (donch_prev[0]=NaN, donch_prev[1:]=donch_hi[:-1])
        channel_len: warmup period (same as indicator warmup)
        order_qty: order quantity
    
    Returns:
        dict with:
            - created_bar: int32 array (n_entry,) - created bar indices
            - price: float64 array (n_entry,) - entry prices
            - order_id: int32 array (n_entry,) - order IDs
            - role: uint8 array (n_entry,) - role (ENTRY)
            - kind: uint8 array (n_entry,) - kind (STOP)
            - side: uint8 array (n_entry,) - side (BUY)
            - qty: int32 array (n_entry,) - quantities
            - n_entry: int - number of entry intents
            - obs: dict - diagnostic observations
    """
    from FishBroWFS_V2.config.dtypes import (
        INDEX_DTYPE,
        INTENT_ENUM_DTYPE,
        INTENT_PRICE_DTYPE,
    )
    
    n = int(donch_prev.shape[0])
    warmup = channel_len
    
    # Create index array for bars 1..n-1 (bar indices t, where created_bar = t-1)
    # i represents bar index t (from 1 to n-1)
    i = np.arange(1, n, dtype=INDEX_DTYPE)
    
    # Sparse mask: valid entries must be finite, positive, and past warmup
    # Check donch_prev[t] for each bar t in range(1, n)
    valid_mask = (~np.isnan(donch_prev[1:])) & (donch_prev[1:] > 0) & (i >= warmup)
    
    # Get indices of valid entries (flatnonzero returns indices into donch_prev[1:])
    # idx is 0-indexed into donch_prev[1:], so idx=0 corresponds to bar t=1
    idx = np.flatnonzero(valid_mask).astype(INDEX_DTYPE)
    
    n_entry = int(idx.shape[0])
    
    # CURSOR TASK 2: entry_valid_mask_sum must be sum(allow_mask) - for dense builder, it equals valid_mask_sum
    # Diagnostic observations
    obs = {
        "n_bars": n,
        "warmup": warmup,
        "valid_mask_sum": int(np.sum(valid_mask)),  # Dense valid bars (before trigger rate)
        "entry_valid_mask_sum": int(np.sum(valid_mask)),  # CURSOR TASK 2: For dense builder, equals valid_mask_sum
    }
    
    if n_entry == 0:
        return {
            "created_bar": np.empty(0, dtype=INDEX_DTYPE),
            "price": np.empty(0, dtype=INTENT_PRICE_DTYPE),
            "order_id": np.empty(0, dtype=INDEX_DTYPE),
            "role": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "kind": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "side": np.empty(0, dtype=INTENT_ENUM_DTYPE),
            "qty": np.empty(0, dtype=INDEX_DTYPE),
            "n_entry": 0,
            "obs": obs,
        }
    
    # Stage P2-3A: Gather sparse entries (only for valid_mask == True positions)
    # - idx is index into donch_prev[1:], so bar index t = idx + 1
    # - created_bar = t - 1 = idx (since t = idx + 1)
    # - price = donch_prev[t] = donch_prev[idx + 1] = donch_prev[1:][idx]
    # created_bar is already sorted (ascending) because idx comes from flatnonzero on sorted mask
    created_bar = idx.astype(INDEX_DTYPE)  # created_bar = t-1 = idx (when t = idx+1)
    price = donch_prev[1:][idx].astype(INTENT_PRICE_DTYPE)  # Gather from donch_prev[1:]
    
    # Stage P2-3A: Order ID maintains deterministic ordering
    # Order ID is sequential (1, 2, 3, ...) based on created_bar order
    # Since created_bar is already sorted, this preserves deterministic ordering
    order_id = np.arange(1, n_entry + 1, dtype=INDEX_DTYPE)
    role = np.full(n_entry, ROLE_ENTRY, dtype=INTENT_ENUM_DTYPE)
    kind = np.full(n_entry, KIND_STOP, dtype=INTENT_ENUM_DTYPE)
    side = np.full(n_entry, SIDE_BUY, dtype=INTENT_ENUM_DTYPE)
    qty = np.full(n_entry, int(order_qty), dtype=INDEX_DTYPE)
    
    return {
        "created_bar": created_bar,
        "price": price,
        "order_id": order_id,
        "role": role,
        "kind": kind,
        "side": side,
        "qty": qty,
        "n_entry": n_entry,
        "obs": obs,
    }


@dataclass(frozen=True)
class DonchianAtrParams:
    channel_len: int
    atr_len: int
    stop_mult: float


def _max_drawdown(equity: np.ndarray) -> float:
    """
    Vectorized max drawdown on an equity curve.
    Handles empty arrays gracefully.
    """
    if equity.size == 0:
        return 0.0
    peak = np.maximum.accumulate(equity)
    dd = equity - peak
    mdd = float(np.min(dd))  # negative or 0
    return mdd


def run_kernel_object_mode(
    bars: BarArrays,
    params: DonchianAtrParams,
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
    precomp: Optional[PrecomputedIndicators] = None,
) -> Dict[str, object]:
    """
    Golden Kernel (GKV): single-source-of-truth kernel for Phase 3A and future Phase 3B.

    Strategy (minimal):
      - Entry: Buy Stop at Donchian High (rolling max of HIGH over channel_len) at bar close -> next bar active.
      - Exit: Sell Stop at (entry_fill_price - stop_mult * ATR_wilder) active from next bar after entry_fill.

    Costs:
      - commission (absolute per trade)
      - slip (absolute per trade)
      Costs are applied on each round-trip fill (entry and exit each incur cost).

    Returns:
      dict with:
        - fills: List[Fill]
        - pnl: np.ndarray (float64, per-round-trip pnl, can be empty)
        - equity: np.ndarray (float64, cumsum of pnl, can be empty)
        - metrics: dict (net_profit, trades, max_dd)
    """
    profile = os.environ.get("FISHBRO_PROFILE_KERNEL", "").strip() == "1"
    t0 = time.perf_counter() if profile else 0.0

    # --- Compute indicators (kernel level; wrapper must ensure contiguous arrays) ---
    ch = int(params.channel_len)
    atr_n = int(params.atr_len)
    stop_mult = float(params.stop_mult)

    if ch <= 0 or atr_n <= 0:
        # invalid params -> zero trades, deterministic
        pnl = np.empty(0, dtype=np.float64)
        equity = np.empty(0, dtype=np.float64)
        # Evidence fields (Source of Truth) - Phase 3.0-A: must not be null
        # Red Team requirement: if fallback to objects mode, must leave fingerprint
        return {
            "fills": [],
            "pnl": pnl,
            "equity": equity,
            "metrics": {"net_profit": 0.0, "trades": 0, "max_dd": 0.0},
            "_obs": {
                "intent_mode": "objects",
                "intents_total": 0,
                "fills_total": 0,
            },
        }

    # Stage P2-2 Step B2: Use precomputed indicators if available, otherwise compute
    if precomp is not None:
        donch_hi = precomp.donch_hi
        atr = precomp.atr
    else:
        donch_hi = rolling_max(bars.high, ch)  # includes current bar
        atr = atr_wilder(bars.high, bars.low, bars.close, atr_n)
    t_ind = time.perf_counter() if profile else 0.0

    # --- Build order intents (next-bar active) ---
    intents: List[OrderIntent] = []
    # CURSOR TASK 5: Use deterministic order ID generation (pure function)
    from FishBroWFS_V2.engine.order_id import generate_order_id

    # We create entry intents for each bar t where indicator exists:
    # created_bar=t, active at t+1. price=donch_hi[t]
    n = int(bars.open.shape[0])
    for t in range(n):
        px = float(donch_hi[t])
        if np.isnan(px):
            continue
        # CURSOR TASK 5: Generate deterministic order_id
        oid = generate_order_id(
            created_bar=t,
            param_idx=0,  # Single param kernel
            role=ROLE_ENTRY,
            kind=KIND_STOP,
            side=SIDE_BUY,
        )
        intents.append(
            OrderIntent(
                order_id=oid,
                created_bar=t,
                role=OrderRole.ENTRY,
                kind=OrderKind.STOP,
                side=Side.BUY,
                price=px,
                qty=order_qty,
            )
        )
    t_intents = time.perf_counter() if profile else 0.0

    # Run matcher (JIT or python via kill-switch)
    fills: List[Fill] = simulate_matcher(bars, intents)
    t_sim1 = time.perf_counter() if profile else 0.0

    # --- Convert fills -> round-trip pnl (vectorized style, no python trade loops as truth) ---
    # For this minimal kernel we assume:
    # - Only LONG trades (BUY entry, SELL exit) will be produced once we add exits.
    # Phase 3A GKV: We implement exits by post-processing: when entry fills, schedule a sell stop from next bar.
    # To preserve Homology, we do a second matcher pass with generated exit intents.
    # This keeps all fill semantics inside the matcher (constitution).
    exit_intents: List[OrderIntent] = []
    for f in fills:
        if f.role != OrderRole.ENTRY:
            continue
        # exit stop price = entry_price - stop_mult * atr at entry bar
        ebar = int(f.bar_index)
        if ebar < 0 or ebar >= n:
            continue
        a = float(atr[ebar])
        if np.isnan(a):
            continue
        stop_px = float(f.price - stop_mult * a)
        # CURSOR TASK 5: Generate deterministic order_id for exit
        exit_oid = generate_order_id(
            created_bar=ebar,
            param_idx=0,  # Single param kernel
            role=ROLE_EXIT,
            kind=KIND_STOP,
            side=SIDE_SELL,
        )
        exit_intents.append(
            OrderIntent(
                order_id=exit_oid,
                created_bar=ebar,  # active next bar
                role=OrderRole.EXIT,
                kind=OrderKind.STOP,
                side=Side.SELL,
                price=stop_px,
                qty=order_qty,
            )
        )
    t_exit_intents = time.perf_counter() if profile else 0.0

    if exit_intents:
        fills2 = simulate_matcher(bars, exit_intents)
        t_sim2 = time.perf_counter() if profile else 0.0
        fills_all = fills + fills2
        # deterministic order: sort by (bar_index, role(ENTRY first), kind, order_id)
        fills_all.sort(key=lambda x: (x.bar_index, 0 if x.role == OrderRole.ENTRY else 1, 0 if x.kind == OrderKind.STOP else 1, x.order_id))
    else:
        fills_all = fills
        t_sim2 = t_sim1 if profile else 0.0

    # CURSOR TASK 1: Compute metrics from fills (unified source of truth)
    net_profit, trades, max_dd, equity = compute_metrics_from_fills(
        fills=fills_all,
        commission=commission,
        slip=slip,
        qty=order_qty,
    )
    
    # For backward compatibility, compute pnl array from equity (if needed)
    if equity.size > 0:
        pnl = np.diff(np.concatenate([[0.0], equity]))
    else:
        pnl = np.empty(0, dtype=np.float64)
    
    metrics = {
        "net_profit": net_profit,
        "trades": trades,
        "max_dd": max_dd,
    }
    out = {"fills": fills_all, "pnl": pnl, "equity": equity, "metrics": metrics}

    # Evidence fields (Source of Truth) - Phase 3.0-A
    # Red Team requirement: if fallback to objects mode, must leave fingerprint
    intents_total = int(len(intents) + len(exit_intents))  # Total intents (entry + exit, merged)
    fills_total = int(len(fills_all))  # fills_all is List[Fill], use len()
    
    # Always-on observability payload (no timing assumptions).
    out["_obs"] = {
        "intent_mode": "objects",
        "intents_total": intents_total,
        "fills_total": fills_total,
        "entry_intents": int(len(intents)),
        "exit_intents": int(len(exit_intents)),
    }

    if profile:
        out["_profile"] = {
            "intent_mode": "objects",
            "indicators_s": float(t_ind - t0),
            "intent_gen_s": float(t_intents - t_ind),
            "simulate_entry_s": float(t_sim1 - t_intents),
            "exit_intent_gen_s": float(t_exit_intents - t_sim1),
            "simulate_exit_s": float(t_sim2 - t_exit_intents),
            "kernel_total_s": float(t_sim2 - t0),
            "entry_intents": int(len(intents)),
            "exit_intents": int(len(exit_intents)),
        }
    return out


def run_kernel_arrays(
    bars: BarArrays,
    params: DonchianAtrParams,
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
    return_debug: bool = False,
    precomp: Optional[PrecomputedIndicators] = None,
    intent_sparse_rate: float = 1.0,  # CURSOR TASK 3: Intent sparse rate from grid
) -> Dict[str, object]:
    """
    Array/SoA intent mode: generates intents as arrays and calls engine_jit.simulate_arrays().
    This avoids OrderIntent object construction in the hot path.
    
    Args:
        precomp: Optional pre-computed indicators. If provided, skips indicator computation
                 and uses precomputed arrays. If None, computes indicators normally (backward compatible).
    """
    profile = os.environ.get("FISHBRO_PROFILE_KERNEL", "").strip() == "1"
    t0 = time.perf_counter() if profile else 0.0
    
    # Stage P2-1.8: Initialize granular timers for breakdown
    from FishBroWFS_V2.perf.timers import PerfTimers
    timers = PerfTimers()
    timers.start("t_total_kernel")
    
    # Task 1A: Define required timing keys (contract enforcement)
    REQUIRED_TIMING_KEYS = (
        "t_calc_indicators_s",
        "t_build_entry_intents_s",
        "t_simulate_entry_s",
        "t_calc_exits_s",
        "t_simulate_exit_s",
        "t_total_kernel_s",
    )

    ch = int(params.channel_len)
    atr_n = int(params.atr_len)
    stop_mult = float(params.stop_mult)

    if ch <= 0 or atr_n <= 0:
        timers.stop("t_total_kernel")
        timing_dict = timers.as_dict_seconds()
        # Task 1B: Ensure all required timing keys exist (setdefault 0.0)
        for k in REQUIRED_TIMING_KEYS:
            timing_dict.setdefault(k, 0.0)
        pnl = np.empty(0, dtype=np.float64)
        equity = np.empty(0, dtype=np.float64)
        # Evidence fields (Source of Truth) - Phase 3.0-A: must not be null
        # Task 1C: Fix early return - inject timing_dict into _obs
        result = {
            "fills": [],
            "pnl": pnl,
            "equity": equity,
            "metrics": {"net_profit": 0.0, "trades": 0, "max_dd": 0.0},
            "_obs": {
                "intent_mode": "arrays",
                "intents_total": 0,
                "fills_total": 0,
                "entry_intents_total": 0,
                "entry_fills_total": 0,
                "exit_intents_total": 0,
                "exit_fills_total": 0,
                **timing_dict,  # Task 1C: Include timing keys in _obs
            },
            "_perf": timing_dict,
        }
        return result

    # Stage P2-2 Step B2: Use precomputed indicators if available, otherwise compute
    if precomp is not None:
        # Use precomputed indicators (skip computation, timing will be ~0)
        donch_hi = precomp.donch_hi
        donch_lo = precomp.donch_lo
        atr = precomp.atr
        # Still record timing (will be ~0 since we skipped computation)
        timers.start("t_ind_donchian")
        timers.stop("t_ind_donchian")
        timers.start("t_ind_atr")
        timers.stop("t_ind_atr")
    else:
        # Stage P2-2 Step A: Micro-profiling - Split indicators timing
        # t_ind_donchian_s: Donchian rolling max/min (highest/lowest)
        timers.start("t_ind_donchian")
        donch_hi = rolling_max(bars.high, ch)
        donch_lo = rolling_min(bars.low, ch)  # Also compute low for consistency
        timers.stop("t_ind_donchian")
        
        # t_ind_atr_s: ATR Wilder (TR + RMA/ATR)
        timers.start("t_ind_atr")
        atr = atr_wilder(bars.high, bars.low, bars.close, atr_n)
        timers.stop("t_ind_atr")
    
    t_ind = time.perf_counter() if profile else 0.0

    # Stage P2-1.8: t_build_entry_intents_s - Build entry intents (shift, mask, build)
    timers.start("t_build_entry_intents")
    # Fix 2: Shift donchian for next-bar active (created_bar = t-1, price = donch_hi[t-1])
    # Entry orders generated at bar t-1 close, active at bar t, stop price = donch_hi[t-1]
    donch_prev = np.empty_like(donch_hi)
    donch_prev[0] = np.nan
    donch_prev[1:] = donch_hi[:-1]

    # Stage P2-3A: Check if we should use Numba-accelerated sparse builder
    use_numba_builder = os.environ.get("FISHBRO_FORCE_SPARSE_BUILDER", "").strip() == "1"
    
    # CURSOR TASK 3: Use intent_sparse_rate from grid (passed as parameter)
    # Fallback to env var if not provided (for backward compatibility)
    trigger_rate = intent_sparse_rate
    if trigger_rate == 1.0:  # Only check env if not explicitly passed
        trigger_rate_env = os.environ.get("FISHBRO_PERF_TRIGGER_RATE", "").strip()
        if trigger_rate_env:
            try:
                trigger_rate = float(trigger_rate_env)
                if not (0.0 <= trigger_rate <= 1.0):
                    trigger_rate = 1.0
            except ValueError:
                trigger_rate = 1.0
    
    # Debug instrumentation: track first entry/exit per param (only if return_debug=True)
    if return_debug:
        dbg_entry_bar = -1
        dbg_entry_price = np.nan
        dbg_exit_bar = -1
        dbg_exit_price = np.nan
    else:
        dbg_entry_bar = None
        dbg_entry_price = None
        dbg_exit_bar = None
        dbg_exit_price = None

    # Build entry intents (choose builder based on env flags)
    use_dense_builder = os.environ.get("FISHBRO_USE_DENSE_BUILDER", "").strip() == "1"
    
    if use_numba_builder:
        # Stage P2-3A: Use Numba-accelerated sparse builder (trigger_rate integrated)
        from FishBroWFS_V2.strategy.entry_builder_nb import build_entry_intents_numba
        entry_intents_result = build_entry_intents_numba(
            donch_prev=donch_prev,
            channel_len=ch,
            order_qty=order_qty,
            trigger_rate=trigger_rate,
            seed=42,  # Fixed seed for deterministic selection
        )
        entry_builder_impl = "numba_single_pass"
    elif use_dense_builder:
        # Reference dense builder (for comparison/testing)
        entry_intents_result = _build_entry_intents_from_trigger(
            donch_prev=donch_prev,
            channel_len=ch,
            order_qty=order_qty,
        )
        entry_builder_impl = "python_dense_reference"
    else:
        # Default: Use new sparse builder (supports trigger_rate natively)
        from FishBroWFS_V2.strategy.builder_sparse import build_intents_sparse
        entry_intents_result = build_intents_sparse(
            donch_prev=donch_prev,
            channel_len=ch,
            order_qty=order_qty,
            trigger_rate=trigger_rate,  # CURSOR TASK 3: Use intent_sparse_rate
            seed=42,  # Fixed seed for deterministic selection
            use_dense=False,  # Use sparse mode (default)
        )
        entry_builder_impl = "python_sparse_default"
    timers.stop("t_build_entry_intents")
    
    created_bar = entry_intents_result["created_bar"]
    price = entry_intents_result["price"]
    # CURSOR TASK 5: Use deterministic order ID generation (pure function)
    # Override order_id from builder with deterministic version
    from FishBroWFS_V2.engine.order_id import generate_order_ids_array
    order_id = generate_order_ids_array(
        created_bar=created_bar,
        param_idx=0,  # Single param kernel (param_idx not available here)
        role=entry_intents_result.get("role"),
        kind=entry_intents_result.get("kind"),
        side=entry_intents_result.get("side"),
    )
    role = entry_intents_result["role"]
    kind = entry_intents_result["kind"]
    side = entry_intents_result["side"]
    qty = entry_intents_result["qty"]
    n_entry = entry_intents_result["n_entry"]
    obs_extra = entry_intents_result["obs"]
    
    # Stage P2-3A: Add builder implementation info to obs
    obs_extra = dict(obs_extra)  # Ensure mutable
    obs_extra["entry_builder_impl"] = entry_builder_impl
    
    if n_entry == 0:
        # No valid entry intents
        timers.stop("t_total_kernel")
        timing_dict = timers.as_dict_seconds()
        # Task 1B: Ensure all required timing keys exist (setdefault 0.0)
        for k in REQUIRED_TIMING_KEYS:
            timing_dict.setdefault(k, 0.0)
        pnl = np.empty(0, dtype=np.float64)
        equity = np.empty(0, dtype=np.float64)
        metrics = {"net_profit": 0.0, "trades": 0, "max_dd": 0.0}
        intents_total = 0
        fills_total = 0
        
        result = {
            "fills": [],
            "pnl": pnl,
            "equity": equity,
            "metrics": metrics,
            "_obs": {
                "intent_mode": "arrays",
                "intents_total": intents_total,
                "fills_total": fills_total,
                "entry_intents_total": int(n_entry),  # CURSOR TASK 2: Use actual n_entry (0 in this case)
                "entry_fills_total": 0,
                "exit_intents_total": 0,
                "exit_fills_total": 0,
                **obs_extra,  # Include diagnostic observations from entry intent builder
                **timing_dict,  # Stage P2-1.8: Include timing keys in _obs
            },
            "_perf": timing_dict,  # Keep _perf for backward compatibility
        }
        if return_debug:
            result["_debug"] = {
                "entry_bar": dbg_entry_bar,
                "entry_price": dbg_entry_price,
                "exit_bar": dbg_exit_bar,
                "exit_price": dbg_exit_price,
            }
        
        # --- P2-1.6 Observability alias (kernel-native) ---
        obs = result.setdefault("_obs", {})
        # Canonical entry sparse keys expected by perf/tests
        # CURSOR TASK 2: entry_valid_mask_sum should come from obs_extra (builder), not valid_mask_sum
        if "entry_valid_mask_sum" not in obs:
            obs.setdefault("entry_valid_mask_sum", int(obs.get("entry_valid_mask_sum", 0)))
        # entry_intents_total should already be set above (n_entry = 0 in this case)
        if "entry_intents_total" not in obs:
            obs["entry_intents_total"] = int(n_entry)
        
        return result

    # Arrays are already built by _build_entry_intents_from_trigger
    t_intents = time.perf_counter() if profile else 0.0

    # Stage P2-1.8: t_simulate_entry_s - Simulate entry intents
    timers.start("t_simulate_entry")
    fills: List[Fill] = simulate_matcher_arrays(
        bars,
        order_id=order_id,
        created_bar=created_bar,
        role=role,
        kind=kind,
        side=side,
        price=price,
        qty=qty,
        ttl_bars=1,
    )
    timers.stop("t_simulate_entry")
    t_sim1 = time.perf_counter() if profile else 0.0
    
    # Count entry fills
    entry_fills_count = sum(1 for f in fills if f.role == OrderRole.ENTRY and f.side == Side.BUY)

    # Capture first entry fill for debug
    if return_debug and len(fills) > 0:
        first_entry = None
        for f in fills:
            if f.role == OrderRole.ENTRY and f.side == Side.BUY:
                first_entry = f
                break
        if first_entry is not None:
            dbg_entry_bar = int(first_entry.bar_index)
            dbg_entry_price = float(first_entry.price)

    # Stage P2-1.8: t_calc_exits_s - Build Exit intents (using atr_len + stop_mult)
    timers.start("t_calc_exits")
    # Fix 3: Stage B - Build Exit intents (using atr_len + stop_mult)
    # For each entry fill, compute exit stop = entry_price - stop_mult * ATR[entry_bar]
    exit_intents_list = []
    for f in fills:
        if f.role != OrderRole.ENTRY or f.side != Side.BUY:
            continue
        ebar = int(f.bar_index)
        if ebar < 0 or ebar >= int(bars.open.shape[0]):
            continue
        # Get ATR at entry bar
        atr_e = float(atr[ebar])
        if not np.isfinite(atr_e) or atr_e <= 0:
            # Invalid ATR: skip this entry (no exit intent)
            continue
        # Compute exit stop price
        exit_stop = float(f.price - stop_mult * atr_e)
        exit_intents_list.append({
            "created_bar": ebar,  # Allow same-bar entry then exit (matcher handles)
            "price": exit_stop,
            "entry_bar": ebar,
            "entry_price": float(f.price),
        })
    
    exit_intents_count = len(exit_intents_list)
    timers.stop("t_calc_exits")
    t_exit_intents = time.perf_counter() if profile else 0.0

    # Stage P2-1.8: t_simulate_exit_s - Simulate exit intents
    timers.start("t_simulate_exit")
    # Stage C: Simulate exit intents
    if exit_intents_count > 0:
        from FishBroWFS_V2.config.dtypes import (
            INDEX_DTYPE,
            INTENT_ENUM_DTYPE,
            INTENT_PRICE_DTYPE,
        )
        
        exit_created = np.asarray([ei["created_bar"] for ei in exit_intents_list], dtype=INDEX_DTYPE)
        exit_price = np.asarray([ei["price"] for ei in exit_intents_list], dtype=INTENT_PRICE_DTYPE)
        exit_order_id = np.arange(n_entry + 1, n_entry + 1 + exit_intents_count, dtype=INDEX_DTYPE)
        exit_role = np.full(exit_intents_count, ROLE_EXIT, dtype=INTENT_ENUM_DTYPE)
        exit_kind = np.full(exit_intents_count, KIND_STOP, dtype=INTENT_ENUM_DTYPE)
        exit_side = np.full(exit_intents_count, SIDE_SELL, dtype=INTENT_ENUM_DTYPE)
        exit_qty = np.full(exit_intents_count, int(order_qty), dtype=INDEX_DTYPE)
        fills2 = simulate_matcher_arrays(
            bars,
            order_id=exit_order_id,
            created_bar=exit_created,
            role=exit_role,
            kind=exit_kind,
            side=exit_side,
            price=exit_price,
            qty=exit_qty,
            ttl_bars=1,
        )
        exit_fills_count = sum(1 for f in fills2 if f.role == OrderRole.EXIT and f.side == Side.SELL)
        fills_all = fills + fills2
        fills_all.sort(
            key=lambda x: (
                x.bar_index,
                0 if x.role == OrderRole.ENTRY else 1,
                0 if x.kind == OrderKind.STOP else 1,
                x.order_id,
            )
        )
    else:
        fills_all = fills
        exit_fills_count = 0
    timers.stop("t_simulate_exit")
    t_sim2 = time.perf_counter() if profile else 0.0

    # Capture first exit fill for debug
    if return_debug and len(fills_all) > 0:
        first_exit = None
        for f in fills_all:
            if f.role == OrderRole.EXIT and f.side == Side.SELL:
                first_exit = f
                break
        if first_exit is not None:
            dbg_exit_bar = int(first_exit.bar_index)
            dbg_exit_price = float(first_exit.price)

    # CURSOR TASK 1: Compute metrics from fills (unified source of truth)
    net_profit, trades, max_dd, equity = compute_metrics_from_fills(
        fills=fills_all,
        commission=commission,
        slip=slip,
        qty=order_qty,
    )
    
    # For backward compatibility, compute pnl array from equity (if needed)
    if equity.size > 0:
        pnl = np.diff(np.concatenate([[0.0], equity]))
    else:
        pnl = np.empty(0, dtype=np.float64)
    
    metrics = {
        "net_profit": net_profit,
        "trades": trades,
        "max_dd": max_dd,
    }
    out = {"fills": fills_all, "pnl": pnl, "equity": equity, "metrics": metrics}

    # Evidence fields (Source of Truth) - Phase 3.0-A
    intents_total = int(n_entry + exit_intents_count)  # Total intents (entry + exit, merged)
    fills_total = int(len(fills_all))  # fills_all is List[Fill], use len()
    timers.stop("t_total_kernel")
    
    # Stage P2-1.8: Get timing dict and merge into _obs for aggregation
    timing_dict = timers.as_dict_seconds()
    # Task 1B: Ensure all required timing keys exist (setdefault 0.0)
    for k in REQUIRED_TIMING_KEYS:
        timing_dict.setdefault(k, 0.0)
    
    # CURSOR TASK 2: Ensure entry_intents_total is set correctly (from n_entry, not valid_mask_sum)
    # Override any value from obs_extra with actual n_entry
    obs_extra_final = dict(obs_extra)  # Copy to avoid modifying original
    obs_extra_final["entry_intents_total"] = int(n_entry)  # Always use actual n_entry
    
    out["_obs"] = {
        "intent_mode": "arrays",
        "intents_total": intents_total,
        "fills_total": fills_total,
        "entry_intents": int(n_entry),
        "exit_intents": int(exit_intents_count),
        **obs_extra_final,  # Include diagnostic observations from entry intent builder (entry_intents_total = n_entry)
        "entry_intents_total": int(n_entry),  # CURSOR TASK 2: Override with actual n_entry (ensure it's not overwritten)
        "entry_fills_total": int(entry_fills_count),
        "exit_intents_total": int(exit_intents_count),
        "exit_fills_total": int(exit_fills_count),
        **timing_dict,  # Stage P2-1.8: Include timing keys in _obs for aggregation
    }
    out["_perf"] = timing_dict  # Keep _perf for backward compatibility
    if return_debug:
        out["_debug"] = {
            "entry_bar": dbg_entry_bar,
            "entry_price": dbg_entry_price,
            "exit_bar": dbg_exit_bar,
            "exit_price": dbg_exit_price,
        }
    if profile:
        out["_profile"] = {
            "intent_mode": "arrays",
            "indicators_s": float(t_ind - t0),
            "intent_gen_s": float(t_intents - t_ind),
            "simulate_entry_s": float(t_sim1 - t_intents),
            "exit_intent_gen_s": float(t_exit_intents - t_sim1),
            "simulate_exit_s": float(t_sim2 - t_exit_intents),
            "kernel_total_s": float(t_sim2 - t0),
            "entry_intents": int(n_entry),
            "exit_intents": int(exit_intents_count),
        }
    
    # --- P2-1.6 Observability alias (kernel-native) ---
    obs = out.setdefault("_obs", {})
    # Canonical entry sparse keys expected by perf/tests
    # CURSOR TASK 2: entry_valid_mask_sum should come from obs_extra (builder), not valid_mask_sum
    if "entry_valid_mask_sum" not in obs:
        obs.setdefault("entry_valid_mask_sum", int(obs.get("entry_valid_mask_sum", 0)))
    # entry_intents_total should already be set from obs_extra (n_entry)
    if "entry_intents_total" not in obs:
        obs["entry_intents_total"] = int(n_entry)
    
    return out


def run_kernel(
    bars: BarArrays,
    params: DonchianAtrParams,
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
    return_debug: bool = False,
    precomp: Optional[PrecomputedIndicators] = None,
    intent_sparse_rate: float = 1.0,  # CURSOR TASK 3: Intent sparse rate from grid
) -> Dict[str, object]:
    # Default to arrays path for perf; object mode remains as a correctness reference.
    mode = os.environ.get("FISHBRO_KERNEL_INTENT_MODE", "").strip().lower()
    if mode == "objects":
        return run_kernel_object_mode(
            bars,
            params,
            commission=commission,
            slip=slip,
            order_qty=order_qty,
        )
    return run_kernel_arrays(
        bars,
        params,
        commission=commission,
        slip=slip,
        order_qty=order_qty,
        return_debug=return_debug,
        precomp=precomp,
    )



================================================================================
FILE: src/FishBroWFS_V2/strategy/runner_single.py
================================================================================

from __future__ import annotations

from typing import Dict

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.types import BarArrays
from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, run_kernel


def run_single(
    open_: np.ndarray,
    high: np.ndarray,
    low: np.ndarray,
    close: np.ndarray,
    params: DonchianAtrParams,
    *,
    commission: float,
    slip: float,
    order_qty: int = 1,
) -> Dict[str, object]:
    """
    Wrapper for Phase 3A (GKV): ensure memory layout + call kernel once.
    """
    bars: BarArrays = normalize_bars(open_, high, low, close)

    # Boundary Layout Check: enforce contiguous arrays before entering kernel.
    if not bars.open.flags["C_CONTIGUOUS"]:
        bars = BarArrays(
            open=np.ascontiguousarray(bars.open, dtype=np.float64),
            high=np.ascontiguousarray(bars.high, dtype=np.float64),
            low=np.ascontiguousarray(bars.low, dtype=np.float64),
            close=np.ascontiguousarray(bars.close, dtype=np.float64),
        )

    return run_kernel(bars, params, commission=commission, slip=slip, order_qty=order_qty)



================================================================================
FILE: src/FishBroWFS_V2/version.py
================================================================================

__version__ = "0.1.0"



================================================================================
FILE: tests/__init__.py
================================================================================

"""
Tests package for FishBroWFS_V2.

This package allows tests to import from each other using:
    from tests.test_module import ...
"""


================================================================================
FILE: tests/conftest.py
================================================================================

"""
Pytest configuration and fixtures.

Ensures PYTHONPATH is set correctly for imports.
"""
from __future__ import annotations

import sys
from pathlib import Path

# Add src/ to Python path if not already present
# This ensures tests can import FishBroWFS_V2 without manual PYTHONPATH setup
repo_root = Path(__file__).parent.parent
src_path = repo_root / "src"
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))


================================================================================
FILE: tests/test_baseline_lock.py
================================================================================

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.engine_jit import simulate as simulate_jit
from FishBroWFS_V2.engine.matcher_core import simulate as simulate_py
from FishBroWFS_V2.engine.types import OrderIntent, OrderKind, OrderRole, Side


def _fills_to_matrix(fills):
    # Columns: bar_index, role, kind, side, price, qty, order_id
    m = np.empty((len(fills), 7), dtype=np.float64)
    for i, f in enumerate(fills):
        m[i, 0] = float(f.bar_index)
        m[i, 1] = 0.0 if f.role == OrderRole.EXIT else 1.0
        m[i, 2] = 0.0 if f.kind == OrderKind.STOP else 1.0
        m[i, 3] = float(int(f.side.value))
        m[i, 4] = float(f.price)
        m[i, 5] = float(f.qty)
        m[i, 6] = float(f.order_id)
    return m


def test_gate_a_jit_matches_python_reference():
    # Two bars so we can test next-bar active + entry then exit.
    bars = normalize_bars(
        np.array([100.0, 100.0], dtype=np.float64),
        np.array([120.0, 120.0], dtype=np.float64),
        np.array([90.0, 80.0], dtype=np.float64),
        np.array([110.0, 90.0], dtype=np.float64),
    )

    intents = [
        # Entry active on bar0
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=105.0),
        # Exit active on bar0 (same bar), should execute after entry
        OrderIntent(order_id=2, created_bar=-1, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=95.0),
        # Entry created on bar0 -> active on bar1
        OrderIntent(order_id=3, created_bar=0, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=110.0),
    ]

    py = simulate_py(bars, intents)
    jit = simulate_jit(bars, intents)

    m_py = _fills_to_matrix(py)
    m_jit = _fills_to_matrix(jit)

    assert m_py.shape == m_jit.shape
    # Event-level exactness except price tolerance
    np.testing.assert_array_equal(m_py[:, [0, 1, 2, 3, 5, 6]], m_jit[:, [0, 1, 2, 3, 5, 6]])
    np.testing.assert_allclose(m_py[:, 4], m_jit[:, 4], rtol=0.0, atol=1e-9)



================================================================================
FILE: tests/test_builder_sparse_contract.py
================================================================================

"""
Contract Tests for Sparse Builder (P2-3)

Verifies sparse intent builder behavior:
- Intent scaling with trigger_rate
- Metrics zeroing for non-selected params
- Seed determinism
"""
from __future__ import annotations

import numpy as np
import os

from FishBroWFS_V2.strategy.builder_sparse import build_intents_sparse


def test_builder_intent_scaling_with_intent_sparse_rate() -> None:
    """
    Test that intents scale approximately linearly with trigger_rate.
    
    Verifies that when trigger_rate=0.05, intents_generated is approximately
    5% of allowed_bars (with tolerance for rounding).
    """
    n_bars = 1000
    channel_len = 20
    order_qty = 1
    
    # Generate synthetic donch_prev array (all valid after warmup)
    donch_prev = np.full(n_bars, 100.0, dtype=np.float64)
    donch_prev[0] = np.nan  # First bar is NaN (shifted)
    # Bars 1..channel_len-1 are valid but before warmup
    # Bars channel_len..n_bars-1 are valid and past warmup
    
    # Run dense (trigger_rate=1.0) - baseline
    result_dense = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=1.0,
        seed=42,
        use_dense=False,
    )
    
    # Run sparse (trigger_rate=0.05) - 5% of triggers
    result_sparse = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=0.05,
        seed=42,
        use_dense=False,
    )
    
    obs_dense = result_dense["obs"]
    obs_sparse = result_sparse["obs"]
    
    allowed_bars_dense = obs_dense.get("allowed_bars")
    intents_generated_dense = obs_dense.get("intents_generated")
    allowed_bars_sparse = obs_sparse.get("allowed_bars")
    intents_generated_sparse = obs_sparse.get("intents_generated")
    valid_mask_sum_dense = obs_dense.get("valid_mask_sum")
    valid_mask_sum_sparse = obs_sparse.get("valid_mask_sum")
    
    # Contract: allowed_bars should be the same (represents valid bars before trigger rate)
    # allowed_bars = valid_mask_sum (baseline, for comparison)
    assert allowed_bars_dense == allowed_bars_sparse, (
        f"allowed_bars should be the same for dense and sparse (both equal valid_mask_sum), "
        f"got {allowed_bars_dense} vs {allowed_bars_sparse}"
    )
    assert valid_mask_sum_dense == valid_mask_sum_sparse, (
        f"valid_mask_sum should be the same for dense and sparse, "
        f"got {valid_mask_sum_dense} vs {valid_mask_sum_sparse}"
    )
    
    # Contract: intents_generated should scale approximately with trigger_rate
    # With trigger_rate=0.05, we expect approximately 5% of valid_mask_sum
    # Allow wide tolerance: [0.02, 0.08] (2% to 8% of valid_mask_sum)
    if valid_mask_sum_dense is not None and valid_mask_sum_dense > 0:
        ratio = intents_generated_sparse / valid_mask_sum_sparse
        assert 0.02 <= ratio <= 0.08, (
            f"With trigger_rate=0.05, intents_generated_sparse ({intents_generated_sparse}) "
            f"should be approximately 5% of valid_mask_sum ({valid_mask_sum_sparse}), "
            f"got ratio {ratio:.4f} (expected [0.02, 0.08])"
        )
    
    # Contract: intents_generated_dense should equal valid_mask_sum (trigger_rate=1.0)
    assert intents_generated_dense == valid_mask_sum_dense, (
        f"With trigger_rate=1.0, intents_generated ({intents_generated_dense}) "
        f"should equal valid_mask_sum ({valid_mask_sum_dense})"
    )


def test_metrics_zeroing_for_non_selected_params() -> None:
    """
    Test that builder correctly handles edge cases (no valid triggers, etc.).
    
    This test verifies that the builder returns empty arrays when there are
    no valid triggers, and that all fields are properly initialized.
    """
    n_bars = 100
    channel_len = 50  # Large warmup, so most bars are invalid
    order_qty = 1
    
    # Generate donch_prev with only a few valid bars
    donch_prev = np.full(n_bars, np.nan, dtype=np.float64)
    donch_prev[0] = np.nan  # First bar is NaN (shifted)
    # Set a few bars to valid values (after warmup)
    donch_prev[60] = 100.0
    donch_prev[70] = 100.0
    donch_prev[80] = 100.0
    
    result = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=1.0,
        seed=42,
        use_dense=False,
    )
    
    # Contract: Should have some intents (3 valid bars after warmup)
    assert result["n_entry"] > 0, "Should have some intents for valid bars"
    
    # Contract: All arrays should have same length
    assert len(result["created_bar"]) == result["n_entry"]
    assert len(result["price"]) == result["n_entry"]
    assert len(result["order_id"]) == result["n_entry"]
    assert len(result["role"]) == result["n_entry"]
    assert len(result["kind"]) == result["n_entry"]
    assert len(result["side"]) == result["n_entry"]
    assert len(result["qty"]) == result["n_entry"]
    
    # Contract: Test with trigger_rate=0.0 (should return empty)
    result_empty = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=0.0,
        seed=42,
        use_dense=False,
    )
    
    assert result_empty["n_entry"] == 0, "With trigger_rate=0.0, should have no intents"
    assert len(result_empty["created_bar"]) == 0
    assert len(result_empty["price"]) == 0


def test_seed_determinism_builder_output() -> None:
    """
    Test that builder output is deterministic for same seed.
    
    Verifies that running the builder twice with the same seed produces
    identical results (bit-exact).
    """
    n_bars = 500
    channel_len = 20
    order_qty = 1
    trigger_rate = 0.1  # 10% of triggers
    
    # Generate synthetic donch_prev array
    donch_prev = np.full(n_bars, 100.0, dtype=np.float64)
    donch_prev[0] = np.nan  # First bar is NaN (shifted)
    
    # Run twice with same seed
    result1 = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=trigger_rate,
        seed=42,
        use_dense=False,
    )
    
    result2 = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=trigger_rate,
        seed=42,
        use_dense=False,
    )
    
    # Contract: Results should be bit-exact identical
    assert result1["n_entry"] == result2["n_entry"], (
        f"n_entry should be identical, got {result1['n_entry']} vs {result2['n_entry']}"
    )
    
    if result1["n_entry"] > 0:
        assert np.array_equal(result1["created_bar"], result2["created_bar"]), (
            "created_bar should be bit-exact identical"
        )
        assert np.array_equal(result1["price"], result2["price"]), (
            "price should be bit-exact identical"
        )
        assert np.array_equal(result1["order_id"], result2["order_id"]), (
            "order_id should be bit-exact identical"
        )
    
    # Contract: Different seeds should produce different results (for sparse mode)
    result3 = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=trigger_rate,
        seed=123,  # Different seed
        use_dense=False,
    )
    
    # With different seed, results may differ (but should still be deterministic)
    # We just verify that the builder runs without error
    assert isinstance(result3["n_entry"], int)
    assert result3["n_entry"] >= 0


def test_dense_vs_sparse_parity() -> None:
    """
    Test that dense builder (use_dense=True) produces same results as sparse with trigger_rate=1.0.
    
    Verifies that the dense reference implementation matches sparse builder
    when trigger_rate=1.0.
    """
    n_bars = 200
    channel_len = 20
    order_qty = 1
    
    # Generate synthetic donch_prev array
    donch_prev = np.full(n_bars, 100.0, dtype=np.float64)
    donch_prev[0] = np.nan  # First bar is NaN (shifted)
    
    # Run dense builder
    result_dense = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=1.0,
        seed=42,
        use_dense=True,
    )
    
    # Run sparse builder with trigger_rate=1.0
    result_sparse = build_intents_sparse(
        donch_prev=donch_prev,
        channel_len=channel_len,
        order_qty=order_qty,
        trigger_rate=1.0,
        seed=42,
        use_dense=False,
    )
    
    # Contract: Results should be identical (both use all valid triggers)
    assert result_dense["n_entry"] == result_sparse["n_entry"], (
        f"n_entry should be identical, got {result_dense['n_entry']} vs {result_sparse['n_entry']}"
    )
    
    if result_dense["n_entry"] > 0:
        assert np.array_equal(result_dense["created_bar"], result_sparse["created_bar"]), (
            "created_bar should be identical"
        )
        assert np.array_equal(result_dense["price"], result_sparse["price"]), (
            "price should be identical"
        )


================================================================================
FILE: tests/test_data_layout.py
================================================================================

import numpy as np
import pytest
from FishBroWFS_V2.data.layout import normalize_bars


def test_normalize_bars_dtype_and_contiguous():
    o = np.arange(10, dtype=np.float32)[::2]
    h = o + 1
    l = o - 1
    c = o + 0.5

    bars = normalize_bars(o, h, l, c)

    for arr in (bars.open, bars.high, bars.low, bars.close):
        assert arr.dtype == np.float64
        assert arr.flags["C_CONTIGUOUS"]


def test_normalize_bars_reject_nan():
    o = np.array([1.0, np.nan])
    h = np.array([1.0, 2.0])
    l = np.array([0.5, 1.5])
    c = np.array([0.8, 1.8])

    with pytest.raises(ValueError):
        normalize_bars(o, h, l, c)



================================================================================
FILE: tests/test_dtype_compression_contract.py
================================================================================

"""Contract tests for dtype compression (Phase P1).

These tests ensure:
1. INDEX_DTYPE=int32 safety: order_id, created_bar, qty never exceed 2^31-1
2. UINT8 enum consistency: role/kind/side correctly encode/decode without sentinel issues
"""

import numpy as np
import pytest

from FishBroWFS_V2.config.dtypes import (
    INDEX_DTYPE,
    INTENT_ENUM_DTYPE,
    INTENT_PRICE_DTYPE,
)
from FishBroWFS_V2.engine.constants import (
    KIND_LIMIT,
    KIND_STOP,
    ROLE_ENTRY,
    ROLE_EXIT,
    SIDE_BUY,
    SIDE_SELL,
)
from FishBroWFS_V2.engine.engine_jit import (
    SIDE_BUY_CODE,
    SIDE_SELL_CODE,
    _pack_intents,
    simulate_arrays,
)
from FishBroWFS_V2.engine.types import BarArrays, OrderIntent, OrderKind, OrderRole, Side


class TestIndexDtypeSafety:
    """Test that INDEX_DTYPE=int32 is safe for all use cases."""

    def test_order_id_max_value_contract(self):
        """
        Contract: order_id must never exceed 2^31-1 (int32 max).
        
        In strategy/kernel.py, order_id is generated as:
        - Entry: np.arange(1, n_entry + 1)
        - Exit: np.arange(n_entry + 1, n_entry + 1 + exit_intents_count)
        
        Maximum order_id = n_entry + exit_intents_count
        
        For 200,000 bars with reasonable intent generation, this should be << 2^31-1.
        """
        INT32_MAX = 2**31 - 1
        
        # Simulate worst-case scenario: 200,000 bars, each bar generates 1 entry + 1 exit
        # This is extremely conservative (realistic scenarios generate far fewer intents)
        n_bars = 200_000
        max_intents_per_bar = 2  # 1 entry + 1 exit per bar (worst case)
        max_total_intents = n_bars * max_intents_per_bar
        
        # Maximum order_id would be max_total_intents (if all are sequential)
        max_order_id = max_total_intents
        
        assert max_order_id < INT32_MAX, (
            f"order_id would exceed int32 max ({INT32_MAX}) "
            f"with {n_bars} bars and {max_intents_per_bar} intents per bar. "
            f"Max order_id would be {max_order_id}"
        )
        
        # More realistic: check that even with 10x safety margin, we're still safe
        safety_margin = 10
        assert max_order_id * safety_margin < INT32_MAX, (
            f"order_id with {safety_margin}x safety margin would exceed int32 max"
        )

    def test_created_bar_max_value_contract(self):
        """
        Contract: created_bar must never exceed 2^31-1.
        
        created_bar is a bar index, so max value = n_bars - 1.
        For 200,000 bars, max created_bar = 199,999 << 2^31-1.
        """
        INT32_MAX = 2**31 - 1
        
        # Worst case: 200,000 bars
        max_bars = 200_000
        max_created_bar = max_bars - 1
        
        assert max_created_bar < INT32_MAX, (
            f"created_bar would exceed int32 max ({INT32_MAX}) "
            f"with {max_bars} bars. Max created_bar would be {max_created_bar}"
        )

    def test_qty_max_value_contract(self):
        """
        Contract: qty must never exceed 2^31-1.
        
        qty is typically small (1, 10, 100, etc.), so this should be safe.
        """
        INT32_MAX = 2**31 - 1
        
        # Realistic qty values are much smaller than int32 max
        realistic_max_qty = 1_000_000  # Even 1M shares is << 2^31-1
        
        assert realistic_max_qty < INT32_MAX, (
            f"qty would exceed int32 max ({INT32_MAX}) "
            f"with realistic max qty of {realistic_max_qty}"
        )

    def test_order_id_generation_in_kernel(self):
        """
        Test that actual order_id generation in kernel stays within int32 range.
        
        This test simulates the order_id generation logic from strategy/kernel.py.
        """
        INT32_MAX = 2**31 - 1
        
        # Simulate realistic scenario: 200,000 bars, ~1000 entry intents, ~500 exit intents
        n_entry = 1000
        n_exit = 500
        
        # Entry order_ids: np.arange(1, n_entry + 1)
        entry_order_ids = np.arange(1, n_entry + 1, dtype=INDEX_DTYPE)
        assert entry_order_ids.max() < INT32_MAX
        
        # Exit order_ids: np.arange(n_entry + 1, n_entry + 1 + n_exit)
        exit_order_ids = np.arange(n_entry + 1, n_entry + 1 + n_exit, dtype=INDEX_DTYPE)
        max_order_id = exit_order_ids.max()
        
        assert max_order_id < INT32_MAX, (
            f"Generated order_id {max_order_id} exceeds int32 max ({INT32_MAX})"
        )


class TestUint8EnumConsistency:
    """Test that uint8 enum encoding/decoding is consistent and safe."""

    def test_role_enum_encoding(self):
        """Test that role enum values encode correctly as uint8."""
        # ROLE_EXIT = 0, ROLE_ENTRY = 1
        exit_val = INTENT_ENUM_DTYPE(ROLE_EXIT)
        entry_val = INTENT_ENUM_DTYPE(ROLE_ENTRY)
        
        assert exit_val == 0
        assert entry_val == 1
        assert exit_val.dtype == np.uint8
        assert entry_val.dtype == np.uint8

    def test_kind_enum_encoding(self):
        """Test that kind enum values encode correctly as uint8."""
        # KIND_STOP = 0, KIND_LIMIT = 1
        stop_val = INTENT_ENUM_DTYPE(KIND_STOP)
        limit_val = INTENT_ENUM_DTYPE(KIND_LIMIT)
        
        assert stop_val == 0
        assert limit_val == 1
        assert stop_val.dtype == np.uint8
        assert limit_val.dtype == np.uint8

    def test_side_enum_encoding(self):
        """
        Test that side enum values encode correctly as uint8.
        
        SIDE_BUY_CODE = 1, SIDE_SELL_CODE = 255 (avoid -1 cast deprecation)
        """
        buy_val = INTENT_ENUM_DTYPE(SIDE_BUY_CODE)
        sell_val = INTENT_ENUM_DTYPE(SIDE_SELL_CODE)
        
        assert buy_val == 1
        assert sell_val == 255
        assert buy_val.dtype == np.uint8
        assert sell_val.dtype == np.uint8

    def test_side_enum_decoding_consistency(self):
        """
        Test that side enum decoding correctly handles uint8 values.
        
        Critical: uint8 value 255 (SIDE_SELL_CODE) must decode back to SELL.
        """
        # Encode SIDE_SELL_CODE (255) as uint8
        sell_encoded = INTENT_ENUM_DTYPE(SIDE_SELL_CODE)
        assert sell_encoded == 255
        
        # Decode: int(sd[i]) == SIDE_BUY (1) ? BUY : SELL
        # If sd[i] = 255, int(255) != 1, so it should decode to SELL
        decoded_is_buy = int(sell_encoded) == SIDE_BUY
        decoded_is_sell = int(sell_encoded) != SIDE_BUY
        
        assert not decoded_is_buy, "uint8 value 255 should not decode to BUY"
        assert decoded_is_sell, "uint8 value 255 should decode to SELL"
        
        # Also test BUY encoding/decoding
        buy_encoded = INTENT_ENUM_DTYPE(SIDE_BUY_CODE)
        assert buy_encoded == 1
        decoded_is_buy = int(buy_encoded) == SIDE_BUY_CODE
        assert decoded_is_buy, "uint8 value 1 should decode to BUY"

    def test_allowed_enum_values_contract(self):
        """
        Contract: enum arrays must only contain explicitly allowed values.
        
        This test ensures that:
        1. Only valid enum values are used (no uninitialized/invalid values)
        2. Decoding functions will raise ValueError for invalid values (strict mode)
        
        Allowed values:
        - role: {0 (EXIT), 1 (ENTRY)}
        - kind: {0 (STOP), 1 (LIMIT)}
        - side: {1 (BUY), 255 (SELL as uint8)}
        """
        # Define allowed values explicitly
        ALLOWED_ROLE_VALUES = {ROLE_EXIT, ROLE_ENTRY}  # {0, 1}
        ALLOWED_KIND_VALUES = {KIND_STOP, KIND_LIMIT}  # {0, 1}
        ALLOWED_SIDE_VALUES = {SIDE_BUY_CODE, SIDE_SELL_CODE}  # {1, 255} - avoid -1 cast
        
        # Test that encoding produces only allowed values
        role_encoded = [INTENT_ENUM_DTYPE(ROLE_EXIT), INTENT_ENUM_DTYPE(ROLE_ENTRY)]
        kind_encoded = [INTENT_ENUM_DTYPE(KIND_STOP), INTENT_ENUM_DTYPE(KIND_LIMIT)]
        side_encoded = [INTENT_ENUM_DTYPE(SIDE_BUY_CODE), INTENT_ENUM_DTYPE(SIDE_SELL_CODE)]
        
        for val in role_encoded:
            assert int(val) in ALLOWED_ROLE_VALUES, f"Role value {val} not in allowed set {ALLOWED_ROLE_VALUES}"
        
        for val in kind_encoded:
            assert int(val) in ALLOWED_KIND_VALUES, f"Kind value {val} not in allowed set {ALLOWED_KIND_VALUES}"
        
        for val in side_encoded:
            assert int(val) in ALLOWED_SIDE_VALUES, f"Side value {val} not in allowed set {ALLOWED_SIDE_VALUES}"
        
        # Test that invalid values raise ValueError (strict decoding)
        from FishBroWFS_V2.engine.engine_jit import _role_from_int, _kind_from_int, _side_from_int
        
        # Test invalid role values
        with pytest.raises(ValueError, match="Invalid role enum value"):
            _role_from_int(2)
        with pytest.raises(ValueError, match="Invalid role enum value"):
            _role_from_int(-1)
        
        # Test invalid kind values
        with pytest.raises(ValueError, match="Invalid kind enum value"):
            _kind_from_int(2)
        with pytest.raises(ValueError, match="Invalid kind enum value"):
            _kind_from_int(-1)
        
        # Test invalid side values
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(0)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(2)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(100)
        
        # Test valid values don't raise
        assert _role_from_int(0) == OrderRole.EXIT
        assert _role_from_int(1) == OrderRole.ENTRY
        assert _kind_from_int(0) == OrderKind.STOP
        assert _kind_from_int(1) == OrderKind.LIMIT
        assert _side_from_int(SIDE_BUY_CODE) == Side.BUY
        assert _side_from_int(SIDE_SELL_CODE) == Side.SELL

    def test_pack_intents_roundtrip(self):
        """
        Test that packing intents and decoding them preserves enum values correctly.
        
        This is an integration test to ensure the full encode/decode cycle works.
        """
        # Create test intents with all enum combinations
        intents = [
            OrderIntent(
                order_id=1,
                created_bar=0,
                role=OrderRole.EXIT,
                kind=OrderKind.STOP,
                side=Side.SELL,  # -1 -> uint8(255)
                price=100.0,
                qty=1,
            ),
            OrderIntent(
                order_id=2,
                created_bar=0,
                role=OrderRole.ENTRY,
                kind=OrderKind.LIMIT,
                side=Side.BUY,  # 1 -> uint8(1)
                price=101.0,
                qty=1,
            ),
        ]
        
        # Pack intents
        order_id, created_bar, role, kind, side, price, qty = _pack_intents(intents)
        
        # Verify dtypes
        assert order_id.dtype == INDEX_DTYPE
        assert created_bar.dtype == INDEX_DTYPE
        assert role.dtype == INTENT_ENUM_DTYPE
        assert kind.dtype == INTENT_ENUM_DTYPE
        assert side.dtype == INTENT_ENUM_DTYPE
        assert price.dtype == INTENT_PRICE_DTYPE
        assert qty.dtype == INDEX_DTYPE
        
        # Verify enum values
        assert role[0] == ROLE_EXIT  # 0
        assert role[1] == ROLE_ENTRY  # 1
        assert kind[0] == KIND_STOP  # 0
        assert kind[1] == KIND_LIMIT  # 1
        assert side[0] == SIDE_SELL_CODE  # SELL -> uint8(255)
        assert side[1] == SIDE_BUY_CODE  # BUY -> uint8(1)
        
        # Verify decoding logic (as used in engine_jit.py)
        # Decode role
        decoded_role_0 = OrderRole.EXIT if int(role[0]) == ROLE_EXIT else OrderRole.ENTRY
        assert decoded_role_0 == OrderRole.EXIT
        
        decoded_role_1 = OrderRole.EXIT if int(role[1]) == ROLE_EXIT else OrderRole.ENTRY
        assert decoded_role_1 == OrderRole.ENTRY
        
        # Decode kind
        decoded_kind_0 = OrderKind.STOP if int(kind[0]) == KIND_STOP else OrderKind.LIMIT
        assert decoded_kind_0 == OrderKind.STOP
        
        decoded_kind_1 = OrderKind.STOP if int(kind[1]) == KIND_STOP else OrderKind.LIMIT
        assert decoded_kind_1 == OrderKind.LIMIT
        
        # Decode side (critical: uint8(255) must decode to SELL)
        decoded_side_0 = Side.BUY if int(side[0]) == SIDE_BUY_CODE else Side.SELL
        assert decoded_side_0 == Side.SELL, f"uint8(255) should decode to SELL, got {decoded_side_0}"
        
        decoded_side_1 = Side.BUY if int(side[1]) == SIDE_BUY_CODE else Side.SELL
        assert decoded_side_1 == Side.BUY, f"uint8(1) should decode to BUY, got {decoded_side_1}"

    def test_simulate_arrays_accepts_uint8_enums(self):
        """
        Test that simulate_arrays correctly accepts and processes uint8 enum arrays.
        
        This ensures the numba kernel can handle uint8 enum values correctly.
        """
        # Create minimal test data
        bars = BarArrays(
            open=np.array([100.0, 101.0], dtype=np.float64),
            high=np.array([102.0, 103.0], dtype=np.float64),
            low=np.array([99.0, 100.0], dtype=np.float64),
            close=np.array([101.0, 102.0], dtype=np.float64),
        )
        
        # Create intent arrays with uint8 enums
        order_id = np.array([1], dtype=INDEX_DTYPE)
        created_bar = np.array([0], dtype=INDEX_DTYPE)
        role = np.array([ROLE_ENTRY], dtype=INTENT_ENUM_DTYPE)
        kind = np.array([KIND_STOP], dtype=INTENT_ENUM_DTYPE)
        side = np.array([SIDE_BUY_CODE], dtype=INTENT_ENUM_DTYPE)  # 1 -> uint8(1)
        price = np.array([102.0], dtype=INTENT_PRICE_DTYPE)
        qty = np.array([1], dtype=INDEX_DTYPE)
        
        # This should not raise any dtype-related errors
        fills = simulate_arrays(
            bars,
            order_id=order_id,
            created_bar=created_bar,
            role=role,
            kind=kind,
            side=side,
            price=price,
            qty=qty,
            ttl_bars=1,
        )
        
        # Verify fills were generated (basic sanity check)
        assert isinstance(fills, list)
        
        # Test with SELL side (uint8 value 255)
        side_sell = np.array([SIDE_SELL_CODE], dtype=INTENT_ENUM_DTYPE)  # 255 (avoid -1 cast)
        fills_sell = simulate_arrays(
            bars,
            order_id=order_id,
            created_bar=created_bar,
            role=role,
            kind=kind,
            side=side_sell,
            price=price,
            qty=qty,
            ttl_bars=1,
        )
        
        # Should not raise errors
        assert isinstance(fills_sell, list)
        
        # Verify that fills with SELL side decode correctly
        # Note: numba kernel outputs uint8(255) as 255.0, but _side_from_int correctly decodes it
        if fills_sell:
            # The fill's side should be Side.SELL
            assert fills_sell[0].side == Side.SELL, (
                f"Fill with uint8(255) side should decode to Side.SELL, got {fills_sell[0].side}"
            )

    def test_side_output_value_contract(self):
        """
        Contract: numba kernel outputs side as float.
        
        Note: uint8(255) from SIDE_SELL will output as 255.0, not -1.0.
        This is acceptable as long as _side_from_int correctly decodes it.
        
        With strict mode, invalid values will raise ValueError instead of silently
        decoding to SELL.
        """
        from FishBroWFS_V2.engine.engine_jit import _side_from_int
        
        # Test that _side_from_int correctly handles allowed values
        assert _side_from_int(SIDE_BUY_CODE) == Side.BUY
        assert _side_from_int(SIDE_SELL_CODE) == Side.SELL, (
            f"_side_from_int({SIDE_SELL_CODE}) should decode to Side.SELL, not BUY"
        )
        
        # Test that invalid values raise ValueError (strict mode)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(0)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(-1)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(2)
        with pytest.raises(ValueError, match="Invalid side enum value"):
            _side_from_int(100)


================================================================================
FILE: tests/test_engine_constitution.py
================================================================================

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.matcher_core import simulate
from FishBroWFS_V2.engine.types import OrderIntent, OrderKind, OrderRole, Side


def _bars1(o, h, l, c):
    return normalize_bars(
        np.array([o], dtype=np.float64),
        np.array([h], dtype=np.float64),
        np.array([l], dtype=np.float64),
        np.array([c], dtype=np.float64),
    )


def _bars2(o0, h0, l0, c0, o1, h1, l1, c1):
    return normalize_bars(
        np.array([o0, o1], dtype=np.float64),
        np.array([h0, h1], dtype=np.float64),
        np.array([l0, l1], dtype=np.float64),
        np.array([c0, c1], dtype=np.float64),
    )


def test_tc01_buy_stop_normal():
    bars = _bars1(90, 105, 90, 100)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].price == 100.0


def test_tc02_buy_stop_gap_up_fill_open():
    bars = _bars1(105, 110, 105, 108)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].price == 105.0


def test_tc03_sell_stop_gap_down_fill_open():
    bars = _bars1(90, 95, 80, 85)
    intents = [
        # Exit a long position requires SELL stop; we will enter long first in same bar is not allowed here,
        # so we simulate already-in-position by forcing an entry earlier: created_bar=-2 triggers at -1 (ignored),
        # Instead: use two bars and enter on bar0, exit on bar1.
    ]
    bars2 = _bars2(
        100, 100, 100, 100,   # bar0: enter long at 100 (buy stop gap/normal both ok)
        90, 95, 80, 85        # bar1: exit stop triggers gap down open
    )
    intents2 = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=100.0),
    ]
    fills = simulate(bars2, intents2)
    assert len(fills) == 2
    # second fill is the exit
    assert fills[1].price == 90.0


def test_tc08_next_bar_active_not_same_bar():
    # bar0 has high 105 which would hit stop 102, but order created at bar0 must not fill at bar0.
    # bar1 hits again, should fill at bar1.
    bars = _bars2(
        100, 105, 95, 100,
        100, 105, 95, 100,
    )
    intents = [
        OrderIntent(order_id=1, created_bar=0, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].bar_index == 1
    assert fills[0].price == 102.0


def test_tc09_open_equals_stop_gap_branch_but_same_price():
    bars = _bars1(100, 100, 90, 95)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].price == 100.0


def test_tc10_no_fill_when_not_touched():
    bars = _bars1(90, 95, 90, 92)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert fills == []



================================================================================
FILE: tests/test_engine_gaps_and_priority.py
================================================================================

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.matcher_core import simulate
from FishBroWFS_V2.engine.types import OrderIntent, OrderKind, OrderRole, Side


def _bars1(o, h, l, c):
    return normalize_bars(
        np.array([o], dtype=np.float64),
        np.array([h], dtype=np.float64),
        np.array([l], dtype=np.float64),
        np.array([c], dtype=np.float64),
    )


def test_tc04_buy_limit_gap_down_better_fill_open():
    bars = _bars1(90, 95, 85, 92)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.LIMIT, side=Side.BUY, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].price == 90.0


def test_tc05_sell_limit_gap_up_better_fill_open():
    bars = _bars1(105, 110, 100, 108)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.LIMIT, side=Side.SELL, price=100.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 1
    assert fills[0].price == 105.0


def test_tc06_priority_stop_wins_over_limit_on_exit():
    # First enter long on this same bar, then exit on next bar where both stop and limit are triggerable.
    # Bar0: enter long at 100 (buy stop hits)
    # Bar1: both exit stop 90 and exit limit 110 are touchable (high=110, low=80), STOP must win (fill=90)
    bars = normalize_bars(
        np.array([100, 100], dtype=np.float64),
        np.array([110, 110], dtype=np.float64),
        np.array([90, 80], dtype=np.float64),
        np.array([100, 90], dtype=np.float64),
    )

    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=90.0),
        OrderIntent(order_id=3, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.LIMIT, side=Side.SELL, price=110.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 2
    # Second fill is exit; STOP wins -> 90
    assert fills[1].kind == OrderKind.STOP
    assert fills[1].price == 90.0


def test_tc07_same_bar_entry_then_exit():
    # Same bar allows Entry then Exit.
    # Bar: O=100 H=120 L=90 C=110
    # Entry: Buy Stop 105 -> fills at 105 (since open 100 < 105 and high 120 >= 105)
    # Exit: Sell Stop 95 -> after entry, low 90 <= 95 -> fills at 95
    bars = _bars1(100, 120, 90, 110)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=105.0),
        OrderIntent(order_id=2, created_bar=-1, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=95.0),
    ]
    fills = simulate(bars, intents)
    assert len(fills) == 2
    assert fills[0].price == 105.0
    assert fills[1].price == 95.0



================================================================================
FILE: tests/test_engine_jit_active_book_contract.py
================================================================================

from __future__ import annotations

import os

import numpy as np
import pytest

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.engine_jit import _simulate_with_ttl, simulate as simulate_jit
from FishBroWFS_V2.engine.matcher_core import simulate as simulate_py
from FishBroWFS_V2.engine.types import Fill, OrderIntent, OrderKind, OrderRole, Side


def _assert_fills_equal(a: list[Fill], b: list[Fill]) -> None:
    assert len(a) == len(b)
    for fa, fb in zip(a, b):
        assert fa.bar_index == fb.bar_index
        assert fa.role == fb.role
        assert fa.kind == fb.kind
        assert fa.side == fb.side
        assert fa.qty == fb.qty
        assert fa.order_id == fb.order_id
        assert abs(fa.price - fb.price) <= 1e-9


def test_jit_sorted_invariance_matches_python() -> None:
    # Bars: 3 bars, deterministic highs/lows for STOP triggers
    bars = normalize_bars(
        np.array([100.0, 100.0, 100.0], dtype=np.float64),
        np.array([110.0, 110.0, 110.0], dtype=np.float64),
        np.array([90.0, 90.0, 90.0], dtype=np.float64),
        np.array([100.0, 100.0, 100.0], dtype=np.float64),
    )

    # Intents across multiple activate bars (created_bar = t-1)
    intents = [
        # activate on bar0 (created -1)
        OrderIntent(3, -1, OrderRole.EXIT, OrderKind.STOP, Side.SELL, 95.0, 1),
        OrderIntent(2, -1, OrderRole.ENTRY, OrderKind.STOP, Side.BUY, 105.0, 1),
        # activate on bar1 (created 0)
        OrderIntent(6, 0, OrderRole.EXIT, OrderKind.LIMIT, Side.SELL, 110.0, 1),
        OrderIntent(5, 0, OrderRole.ENTRY, OrderKind.LIMIT, Side.BUY, 99.0, 1),
        # activate on bar2 (created 1)
        OrderIntent(9, 1, OrderRole.EXIT, OrderKind.STOP, Side.SELL, 90.0, 1),
        OrderIntent(8, 1, OrderRole.ENTRY, OrderKind.STOP, Side.BUY, 100.0, 1),
    ]

    shuffled = list(intents)
    rng = np.random.default_rng(123)
    rng.shuffle(shuffled)

    # JIT simulate sorts internally for cursor+book; it must be invariant to input ordering.
    jit_a = simulate_jit(bars, shuffled)
    jit_b = simulate_jit(bars, intents)
    _assert_fills_equal(jit_a, jit_b)

    # Also must match Python reference semantics.
    py = simulate_py(bars, shuffled)
    _assert_fills_equal(jit_a, py)


def test_one_bar_max_one_entry_one_exit_defense() -> None:
    # Single bar is enough: created_bar=-1 activates on bar 0.
    bars = normalize_bars(
        np.array([100.0], dtype=np.float64),
        np.array([120.0], dtype=np.float64),
        np.array([80.0], dtype=np.float64),
        np.array([110.0], dtype=np.float64),
    )

    # Same activate bar contains Entry1, Exit1, Entry2.
    intents = [
        OrderIntent(1, -1, OrderRole.ENTRY, OrderKind.STOP, Side.BUY, 105.0, 1),
        OrderIntent(2, -1, OrderRole.EXIT, OrderKind.STOP, Side.SELL, 95.0, 1),
        OrderIntent(3, -1, OrderRole.ENTRY, OrderKind.STOP, Side.BUY, 110.0, 1),
    ]

    fills = simulate_jit(bars, intents)
    assert len(fills) == 2
    assert fills[0].order_id == 1
    assert fills[1].order_id == 2


def test_ttl_one_shot_vs_gtc_extension_point() -> None:
    # Skip if JIT is disabled; ttl=0 is a JIT-only extension behavior.
    import FishBroWFS_V2.engine.engine_jit as ej

    if ej.nb is None or os.environ.get("NUMBA_DISABLE_JIT", "").strip() == "1":
        pytest.skip("numba not available or disabled; ttl=0 extension tested only under JIT")

    # Bar0: stop not touched, Bar1: stop touched
    bars = normalize_bars(
        np.array([90.0, 90.0], dtype=np.float64),
        np.array([99.0, 110.0], dtype=np.float64),
        np.array([90.0, 90.0], dtype=np.float64),
        np.array([95.0, 100.0], dtype=np.float64),
    )
    intents = [
        OrderIntent(1, -1, OrderRole.ENTRY, OrderKind.STOP, Side.BUY, 100.0, 1),
    ]

    # ttl=1 (default semantics): active only on bar0 -> no fill
    fills_ttl1 = simulate_jit(bars, intents)
    assert fills_ttl1 == []

    # ttl=0 (GTC extension): order stays in book and can fill on bar1
    fills_gtc = _simulate_with_ttl(bars, intents, ttl_bars=0)
    assert len(fills_gtc) == 1
    assert fills_gtc[0].bar_index == 1
    assert abs(fills_gtc[0].price - 100.0) <= 1e-9




================================================================================
FILE: tests/test_funnel_smoke_contract.py
================================================================================

"""Funnel smoke contract tests - Phase 4 Stage D.

Basic smoke tests to ensure the complete funnel pipeline works end-to-end.
"""

import numpy as np

from FishBroWFS_V2.pipeline.funnel import FunnelResult, run_funnel


def test_funnel_smoke_basic():
    """Basic smoke test: run funnel with small parameter grid."""
    # Generate deterministic test data
    np.random.seed(42)
    n_bars = 500
    n_params = 20
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    # Generate parameter grid
    params_matrix = np.column_stack([
        np.random.randint(10, 50, size=n_params),  # channel_len / fast_len
        np.random.randint(5, 30, size=n_params),   # atr_len / slow_len
        np.random.uniform(1.0, 3.0, size=n_params), # stop_mult
    ]).astype(np.float64)
    
    # Run funnel
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=5,
        commission=0.0,
        slip=0.0,
    )
    
    # Verify result structure
    assert isinstance(result, FunnelResult)
    assert len(result.stage0_results) == n_params
    assert len(result.topk_param_ids) == 5
    assert len(result.stage2_results) == 5
    
    # Verify Stage0 results
    for stage0_result in result.stage0_results:
        assert hasattr(stage0_result, "param_id")
        assert hasattr(stage0_result, "proxy_value")
        assert hasattr(stage0_result, "warmup_ok")
        assert isinstance(stage0_result.param_id, int)
        assert isinstance(stage0_result.proxy_value, (int, float))
    
    # Verify Top-K param_ids are valid
    for param_id in result.topk_param_ids:
        assert 0 <= param_id < n_params
    
    # Verify Stage2 results match Top-K
    assert len(result.stage2_results) == len(result.topk_param_ids)
    for i, stage2_result in enumerate(result.stage2_results):
        assert stage2_result.param_id == result.topk_param_ids[i]
        assert isinstance(stage2_result.net_profit, (int, float))
        assert isinstance(stage2_result.trades, int)
        assert isinstance(stage2_result.max_dd, (int, float))


def test_funnel_smoke_empty_params():
    """Test funnel with empty parameter grid."""
    np.random.seed(42)
    n_bars = 100
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    # Empty parameter grid
    params_matrix = np.empty((0, 3), dtype=np.float64)
    
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=5,
    )
    
    assert len(result.stage0_results) == 0
    assert len(result.topk_param_ids) == 0
    assert len(result.stage2_results) == 0


def test_funnel_smoke_k_larger_than_params():
    """Test funnel when k is larger than number of parameters."""
    np.random.seed(42)
    n_bars = 100
    n_params = 5
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    params_matrix = np.column_stack([
        np.random.randint(10, 50, size=n_params),
        np.random.randint(5, 30, size=n_params),
        np.random.uniform(1.0, 3.0, size=n_params),
    ]).astype(np.float64)
    
    # k=10 but only 5 params
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=10,
    )
    
    # Should return all 5 params
    assert len(result.topk_param_ids) == 5
    assert len(result.stage2_results) == 5


def test_funnel_smoke_pipeline_order():
    """Test that pipeline executes in correct order: Stage0 â†’ Top-K â†’ Stage2."""
    np.random.seed(42)
    n_bars = 200
    n_params = 10
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    params_matrix = np.column_stack([
        np.random.randint(10, 30, size=n_params),
        np.random.randint(5, 20, size=n_params),
        np.random.uniform(1.0, 2.0, size=n_params),
    ]).astype(np.float64)
    
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=3,
    )
    
    # Verify Stage0 ran on all params
    assert len(result.stage0_results) == n_params
    
    # Verify Top-K selected from Stage0 results
    assert len(result.topk_param_ids) == 3
    # Top-K should be sorted by proxy_value (descending)
    stage0_by_id = {r.param_id: r for r in result.stage0_results}
    topk_values = [stage0_by_id[pid].proxy_value for pid in result.topk_param_ids]
    assert topk_values == sorted(topk_values, reverse=True)
    
    # Verify Stage2 ran only on Top-K
    assert len(result.stage2_results) == 3
    stage2_param_ids = [r.param_id for r in result.stage2_results]
    assert set(stage2_param_ids) == set(result.topk_param_ids)


================================================================================
FILE: tests/test_funnel_topk_determinism.py
================================================================================

"""Test Top-K determinism - same input must produce same Top-K selection."""

import numpy as np

from FishBroWFS_V2.pipeline.funnel import run_funnel
from FishBroWFS_V2.pipeline.stage0_runner import Stage0Result, run_stage0
from FishBroWFS_V2.pipeline.topk import select_topk


def test_topk_determinism_same_input():
    """Test that Top-K selection is deterministic: same input produces same output."""
    # Generate deterministic test data
    np.random.seed(42)
    n_bars = 1000
    n_params = 100
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    # Generate parameter grid
    params_matrix = np.column_stack([
        np.random.randint(10, 100, size=n_params),  # fast_len / channel_len
        np.random.randint(5, 50, size=n_params),      # slow_len / atr_len
        np.random.uniform(1.0, 5.0, size=n_params),   # stop_mult
    ]).astype(np.float64)
    
    # Run Stage0 twice with same input
    stage0_results_1 = run_stage0(close, params_matrix)
    stage0_results_2 = run_stage0(close, params_matrix)
    
    # Verify Stage0 results are identical
    assert len(stage0_results_1) == len(stage0_results_2)
    for r1, r2 in zip(stage0_results_1, stage0_results_2):
        assert r1.param_id == r2.param_id
        assert r1.proxy_value == r2.proxy_value
    
    # Run Top-K selection twice
    k = 20
    topk_1 = select_topk(stage0_results_1, k=k)
    topk_2 = select_topk(stage0_results_2, k=k)
    
    # Verify Top-K selection is identical
    assert topk_1 == topk_2, (
        f"Top-K selection not deterministic:\n"
        f"  First run:  {topk_1}\n"
        f"  Second run: {topk_2}"
    )
    assert len(topk_1) == k
    assert len(topk_2) == k


def test_topk_determinism_tie_break():
    """Test that tie-breaking by param_id is deterministic."""
    # Create Stage0 results with identical proxy_value
    # Tie-break should use param_id (ascending)
    results = [
        Stage0Result(param_id=5, proxy_value=10.0),
        Stage0Result(param_id=2, proxy_value=10.0),  # Same value, lower param_id
        Stage0Result(param_id=8, proxy_value=10.0),
        Stage0Result(param_id=1, proxy_value=10.0),  # Same value, lowest param_id
        Stage0Result(param_id=3, proxy_value=15.0),  # Higher value
        Stage0Result(param_id=4, proxy_value=12.0),  # Medium value
    ]
    
    # Select top 3
    topk = select_topk(results, k=3)
    
    # Expected: param_id=3 (value=15.0), param_id=4 (value=12.0), param_id=1 (value=10.0, lowest param_id)
    assert topk == [3, 4, 1], f"Tie-break failed: got {topk}, expected [3, 4, 1]"
    
    # Run again - should be identical
    topk_2 = select_topk(results, k=3)
    assert topk_2 == topk


def test_funnel_determinism():
    """Test that complete funnel pipeline is deterministic."""
    # Generate deterministic test data
    np.random.seed(123)
    n_bars = 500
    n_params = 50
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    # Generate parameter grid
    params_matrix = np.column_stack([
        np.random.randint(10, 50, size=n_params),
        np.random.randint(5, 30, size=n_params),
        np.random.uniform(1.0, 3.0, size=n_params),
    ]).astype(np.float64)
    
    # Run funnel twice
    result_1 = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=10,
        commission=0.0,
        slip=0.0,
    )
    
    result_2 = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=10,
        commission=0.0,
        slip=0.0,
    )
    
    # Verify Top-K selection is identical
    assert result_1.topk_param_ids == result_2.topk_param_ids, (
        f"Funnel Top-K not deterministic:\n"
        f"  First run:  {result_1.topk_param_ids}\n"
        f"  Second run: {result_2.topk_param_ids}"
    )
    
    # Verify Stage2 results are for same parameters
    assert len(result_1.stage2_results) == len(result_2.stage2_results)
    for r1, r2 in zip(result_1.stage2_results, result_2.stage2_results):
        assert r1.param_id == r2.param_id


================================================================================
FILE: tests/test_funnel_topk_no_human_contract.py
================================================================================

"""Funnel Top-K no-human contract tests - Phase 4 Stage D.

These tests ensure that Top-K selection is purely automatic based on proxy_value,
with no possibility of human intervention or manual filtering.
"""

import numpy as np

from FishBroWFS_V2.pipeline.funnel import run_funnel
from FishBroWFS_V2.pipeline.stage0_runner import Stage0Result, run_stage0
from FishBroWFS_V2.pipeline.topk import select_topk


def test_topk_only_uses_proxy_value():
    """Test that Top-K selection uses ONLY proxy_value, not any other field."""
    # Create Stage0 results with varying proxy_value and other fields
    results = [
        Stage0Result(param_id=0, proxy_value=5.0, warmup_ok=True, meta={"custom": "data"}),
        Stage0Result(param_id=1, proxy_value=10.0, warmup_ok=False, meta=None),
        Stage0Result(param_id=2, proxy_value=15.0, warmup_ok=True, meta={"other": 123}),
        Stage0Result(param_id=3, proxy_value=8.0, warmup_ok=True, meta=None),
        Stage0Result(param_id=4, proxy_value=12.0, warmup_ok=False, meta={"test": True}),
    ]
    
    # Select top 3
    topk = select_topk(results, k=3)
    
    # Expected: param_id=2 (value=15.0), param_id=4 (value=12.0), param_id=1 (value=10.0)
    # Should ignore warmup_ok and meta fields
    assert topk == [2, 4, 1], (
        f"Top-K should only consider proxy_value, got {topk}, expected [2, 4, 1]"
    )


def test_topk_tie_break_param_id():
    """Test that tie-breaking uses param_id (ascending) when proxy_value is identical."""
    # Create results with identical proxy_value
    results = [
        Stage0Result(param_id=5, proxy_value=10.0),
        Stage0Result(param_id=2, proxy_value=10.0),
        Stage0Result(param_id=8, proxy_value=10.0),
        Stage0Result(param_id=1, proxy_value=10.0),
        Stage0Result(param_id=3, proxy_value=15.0),  # Higher value
        Stage0Result(param_id=4, proxy_value=12.0),   # Medium value
    ]
    
    # Select top 3
    topk = select_topk(results, k=3)
    
    # Expected: param_id=3 (value=15.0), param_id=4 (value=12.0), param_id=1 (value=10.0, lowest param_id)
    assert topk == [3, 4, 1], (
        f"Tie-break should use param_id ascending, got {topk}, expected [3, 4, 1]"
    )


def test_topk_deterministic_same_input():
    """Test that Top-K selection is deterministic: same input produces same output."""
    np.random.seed(42)
    n_bars = 500
    n_params = 50
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    
    params_matrix = np.column_stack([
        np.random.randint(10, 50, size=n_params),
        np.random.randint(5, 30, size=n_params),
        np.random.uniform(1.0, 3.0, size=n_params),
    ]).astype(np.float64)
    
    # Run Stage0 twice
    stage0_results_1 = run_stage0(close, params_matrix)
    stage0_results_2 = run_stage0(close, params_matrix)
    
    # Select Top-K twice
    topk_1 = select_topk(stage0_results_1, k=10)
    topk_2 = select_topk(stage0_results_2, k=10)
    
    # Should be identical
    assert topk_1 == topk_2, (
        f"Top-K selection not deterministic:\n"
        f"  First run:  {topk_1}\n"
        f"  Second run: {topk_2}"
    )


def test_funnel_topk_no_manual_filtering():
    """Test that funnel Top-K selection cannot be manually filtered."""
    np.random.seed(42)
    n_bars = 300
    n_params = 20
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    params_matrix = np.column_stack([
        np.random.randint(10, 40, size=n_params),
        np.random.randint(5, 25, size=n_params),
        np.random.uniform(1.0, 2.5, size=n_params),
    ]).astype(np.float64)
    
    # Run funnel
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=5,
    )
    
    # Verify Top-K is based solely on proxy_value
    stage0_by_id = {r.param_id: r for r in result.stage0_results}
    
    # Get proxy_values for Top-K
    topk_values = [stage0_by_id[pid].proxy_value for pid in result.topk_param_ids]
    
    # Get proxy_values for all params
    all_values = [r.proxy_value for r in result.stage0_results]
    all_values_sorted = sorted(all_values, reverse=True)
    
    # Top-K values should match top K values from all params
    assert topk_values == all_values_sorted[:5], (
        f"Top-K should contain top 5 proxy_values:\n"
        f"  Top-K values: {topk_values}\n"
        f"  Top 5 values:  {all_values_sorted[:5]}"
    )


def test_funnel_stage2_only_runs_topk():
    """Test that Stage2 only runs on Top-K parameters, not all parameters."""
    np.random.seed(42)
    n_bars = 200
    n_params = 15
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    params_matrix = np.column_stack([
        np.random.randint(10, 30, size=n_params),
        np.random.randint(5, 20, size=n_params),
        np.random.uniform(1.0, 2.0, size=n_params),
    ]).astype(np.float64)
    
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=3,
    )
    
    # Verify Stage0 ran on all params
    assert len(result.stage0_results) == n_params
    
    # Verify Top-K selected
    assert len(result.topk_param_ids) == 3
    
    # Verify Stage2 ran ONLY on Top-K (not all params)
    assert len(result.stage2_results) == 3, (
        f"Stage2 should run only on Top-K (3 params), not all params ({n_params})"
    )
    
    # Verify Stage2 param_ids match Top-K
    stage2_param_ids = set(r.param_id for r in result.stage2_results)
    topk_param_ids_set = set(result.topk_param_ids)
    assert stage2_param_ids == topk_param_ids_set, (
        f"Stage2 param_ids should match Top-K:\n"
        f"  Stage2: {stage2_param_ids}\n"
        f"  Top-K:  {topk_param_ids_set}"
    )


def test_funnel_stage0_no_pnl_fields():
    """Test that Stage0 results contain NO PnL-related fields."""
    np.random.seed(42)
    n_bars = 200
    n_params = 10
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    open_ = close + np.random.randn(n_bars) * 2
    high = np.maximum(open_, close) + np.abs(np.random.randn(n_bars)) * 3
    low = np.minimum(open_, close) - np.abs(np.random.randn(n_bars)) * 3
    
    params_matrix = np.column_stack([
        np.random.randint(10, 30, size=n_params),
        np.random.randint(5, 20, size=n_params),
        np.random.uniform(1.0, 2.0, size=n_params),
    ]).astype(np.float64)
    
    result = run_funnel(
        open_,
        high,
        low,
        close,
        params_matrix,
        k=5,
    )
    
    # Check all Stage0 results
    forbidden_fields = {"net", "profit", "mdd", "dd", "drawdown", "sqn", "sharpe", 
                       "winrate", "equity", "pnl", "trades", "score"}
    
    for stage0_result in result.stage0_results:
        # Get field names
        if hasattr(stage0_result, "__dataclass_fields__"):
            field_names = set(stage0_result.__dataclass_fields__.keys())
        else:
            field_names = set(getattr(stage0_result, "__dict__", {}).keys())
        
        # Check no forbidden fields
        for field_name in field_names:
            field_lower = field_name.lower()
            for forbidden in forbidden_fields:
                assert forbidden not in field_lower, (
                    f"Stage0Result contains forbidden PnL field: {field_name} "
                    f"(contains '{forbidden}')"
                )


================================================================================
FILE: tests/test_golden_kernel_verification.py
================================================================================

import numpy as np

from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, run_kernel, _max_drawdown
from FishBroWFS_V2.engine.types import BarArrays


def _bars():
    # Small synthetic OHLC series
    o = np.array([100, 101, 102, 103, 104, 105], dtype=np.float64)
    h = np.array([101, 102, 103, 104, 106, 107], dtype=np.float64)
    l = np.array([99, 100, 101, 102, 103, 104], dtype=np.float64)
    c = np.array([100.5, 101.5, 102.5, 103.5, 105.5, 106.5], dtype=np.float64)
    return BarArrays(open=o, high=h, low=l, close=c)


def test_no_trade_case_does_not_crash_and_returns_zero_metrics():
    bars = _bars()
    params = DonchianAtrParams(channel_len=99999, atr_len=3, stop_mult=2.0)

    out = run_kernel(bars, params, commission=0.0, slip=0.0, order_qty=1)
    pnl = out["pnl"]
    equity = out["equity"]
    metrics = out["metrics"]

    assert isinstance(pnl, np.ndarray)
    assert pnl.size == 0
    assert isinstance(equity, np.ndarray)
    assert equity.size == 0
    assert metrics["net_profit"] == 0.0
    assert metrics["trades"] == 0
    assert metrics["max_dd"] == 0.0


def test_vectorized_metrics_are_self_consistent():
    bars = _bars()
    params = DonchianAtrParams(channel_len=2, atr_len=2, stop_mult=1.0)

    out = run_kernel(bars, params, commission=0.0, slip=0.0, order_qty=1)
    pnl = out["pnl"]
    equity = out["equity"]
    metrics = out["metrics"]

    # If zero trades, still must be consistent
    if pnl.size == 0:
        assert metrics["net_profit"] == 0.0
        assert metrics["trades"] == 0
        assert metrics["max_dd"] == 0.0
        return

    # Vectorized checks
    np.testing.assert_allclose(equity, np.cumsum(pnl), rtol=0.0, atol=0.0)
    assert metrics["trades"] == int(pnl.size)
    assert metrics["net_profit"] == float(np.sum(pnl))
    assert metrics["max_dd"] == _max_drawdown(equity)


def test_costs_are_parameterized_not_hardcoded():
    bars = _bars()
    params = DonchianAtrParams(channel_len=2, atr_len=2, stop_mult=1.0)

    out0 = run_kernel(bars, params, commission=0.0, slip=0.0, order_qty=1)
    out1 = run_kernel(bars, params, commission=1.25, slip=0.75, order_qty=1)

    pnl0 = out0["pnl"]
    pnl1 = out1["pnl"]

    # Either both empty or both non-empty; if empty, pass
    if pnl0.size == 0:
        assert pnl1.size == 0
        return

    # Costs increase => pnl decreases by 2*(commission+slip) per trade
    per_trade_delta = 2.0 * (1.25 + 0.75)
    np.testing.assert_allclose(pnl1, pnl0 - per_trade_delta, rtol=0.0, atol=1e-12)



================================================================================
FILE: tests/test_grid_runner_smoke.py
================================================================================

import numpy as np

from FishBroWFS_V2.pipeline.runner_grid import run_grid


def _ohlc():
    o = np.array([100, 101, 102, 103, 104, 105], dtype=np.float64)
    h = np.array([101, 102, 103, 104, 106, 107], dtype=np.float64)
    l = np.array([99, 100, 101, 102, 103, 104], dtype=np.float64)
    c = np.array([100.5, 101.5, 102.5, 103.5, 105.5, 106.5], dtype=np.float64)
    return o, h, l, c


def test_grid_runner_smoke_shapes_and_no_crash():
    o, h, l, c = _ohlc()

    # params: [channel_len, atr_len, stop_mult]
    params = np.array(
        [
            [2, 2, 1.0],
            [3, 2, 1.5],
            [99999, 3, 2.0],  # should produce 0 trades
            [2, 99999, 2.0],  # atr_len > n should be safe (atr_wilder returns all-NaN -> kernel => 0 trades)
        ],
        dtype=np.float64,
    )

    out = run_grid(o, h, l, c, params, commission=0.0, slip=0.0, order_qty=1, sort_params=True)
    m = out["metrics"]
    order = out["order"]

    assert isinstance(m, np.ndarray)
    assert m.shape == (params.shape[0], 3)
    assert isinstance(order, np.ndarray)
    assert order.shape == (params.shape[0],)
    assert set(order.tolist()) == set(range(params.shape[0]))
    # Optional stronger assertion: at least one row should have 0 trades due to atr_len > n
    assert np.any(m[:, 1] == 0.0)


def test_grid_runner_sorting_toggle():
    o, h, l, c = _ohlc()
    params = np.array(
        [
            [3, 2, 1.5],
            [2, 2, 1.0],
            [2, 3, 2.0],
        ],
        dtype=np.float64,
    )

    out_sorted = run_grid(o, h, l, c, params, commission=0.0, slip=0.0, order_qty=1, sort_params=True)
    out_unsorted = run_grid(o, h, l, c, params, commission=0.0, slip=0.0, order_qty=1, sort_params=False)

    assert out_sorted["metrics"].shape == out_unsorted["metrics"].shape == (3, 3)
    assert out_sorted["order"].shape == out_unsorted["order"].shape == (3,)
    # unsorted order should be identity
    np.testing.assert_array_equal(out_unsorted["order"], np.array([0, 1, 2], dtype=np.int64))



================================================================================
FILE: tests/test_indicators_consistency.py
================================================================================

import numpy as np

from FishBroWFS_V2.indicators.numba_indicators import (
    rolling_max,
    rolling_min,
    atr_wilder,
)


def _py_rolling_max(arr: np.ndarray, window: int) -> np.ndarray:
    n = arr.shape[0]
    out = np.full(n, np.nan, dtype=np.float64)
    if window <= 0:
        return out
    for i in range(n):
        if i < window - 1:
            continue
        start = i - window + 1
        m = arr[start]
        for j in range(start + 1, i + 1):
            v = arr[j]
            if v > m:
                m = v
        out[i] = m
    return out


def _py_rolling_min(arr: np.ndarray, window: int) -> np.ndarray:
    n = arr.shape[0]
    out = np.full(n, np.nan, dtype=np.float64)
    if window <= 0:
        return out
    for i in range(n):
        if i < window - 1:
            continue
        start = i - window + 1
        m = arr[start]
        for j in range(start + 1, i + 1):
            v = arr[j]
            if v < m:
                m = v
        out[i] = m
    return out


def _py_atr_wilder(high, low, close, window):
    n = len(high)
    out = np.full(n, np.nan, dtype=np.float64)
    if window > n:
        return out
    tr = np.empty(n, dtype=np.float64)
    tr[0] = high[0] - low[0]
    for i in range(1, n):
        tr[i] = max(
            high[i] - low[i],
            abs(high[i] - close[i - 1]),
            abs(low[i] - close[i - 1]),
        )
    end = window
    out[end - 1] = np.mean(tr[:end])
    for i in range(window, n):
        out[i] = (out[i - 1] * (window - 1) + tr[i]) / window
    return out


def test_rolling_max_min_consistency():
    arr = np.array([1.0, 3.0, 2.0, 5.0, 4.0], dtype=np.float64)
    w = 3

    mx_py = _py_rolling_max(arr, w)
    mn_py = _py_rolling_min(arr, w)

    mx = rolling_max(arr, w)
    mn = rolling_min(arr, w)

    np.testing.assert_allclose(mx, mx_py, rtol=0.0, atol=0.0)
    np.testing.assert_allclose(mn, mn_py, rtol=0.0, atol=0.0)


def test_atr_wilder_consistency():
    high = np.array([10, 11, 12, 11, 13, 14], dtype=np.float64)
    low = np.array([9, 9, 10, 9, 11, 12], dtype=np.float64)
    close = np.array([9.5, 10.5, 11.0, 10.0, 12.0, 13.0], dtype=np.float64)
    w = 3

    atr_py = _py_atr_wilder(high, low, close, w)
    atr = atr_wilder(high, low, close, w)

    np.testing.assert_allclose(atr, atr_py, rtol=0.0, atol=1e-12)


def test_atr_wilder_window_gt_n_returns_all_nan():
    high = np.array([10, 11], dtype=np.float64)
    low = np.array([9, 10], dtype=np.float64)
    close = np.array([9.5, 10.5], dtype=np.float64)
    atr = atr_wilder(high, low, close, 999)
    assert atr.shape == (2,)
    assert np.all(np.isnan(atr))



================================================================================
FILE: tests/test_indicators_precompute_bit_exact.py
================================================================================

"""
Stage P2-2 Step B: Bit-exact test for precomputed indicators.

Verifies that using precomputed indicators produces identical results
to computing indicators inline in the kernel.
"""
from __future__ import annotations

from dataclasses import asdict, is_dataclass

import numpy as np

from FishBroWFS_V2.engine.types import BarArrays, Fill
from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, PrecomputedIndicators, run_kernel_arrays
from FishBroWFS_V2.indicators.numba_indicators import rolling_max, rolling_min, atr_wilder


def _fill_to_tuple(f: Fill) -> tuple:
    """
    Convert Fill to a comparable tuple representation.
    
    Uses dataclasses.asdict for dataclass instances, falls back to __dict__ or repr.
    Returns sorted tuple to ensure deterministic comparison.
    """
    if is_dataclass(f):
        d = asdict(f)
    else:
        # fallback: __dict__ (for normal classes)
        d = dict(getattr(f, "__dict__", {}))
        if not d:
            # last resort: repr
            return (repr(f),)
    # Fixed ordering to avoid dict order differences
    return tuple(sorted(d.items()))


def test_indicators_precompute_bit_exact() -> None:
    """
    Test that precomputed indicators produce bit-exact results.
    
    Strategy:
    - Generate random bars
    - Choose a channel_len and atr_len
    - Run kernel twice:
      A: Without precomputation (precomp=None)
      B: With precomputation (precomp=PrecomputedIndicators(...))
    - Compare: donch_hi/lo/atr arrays, metrics, fills, equity
    """
    # Generate random bars
    rng = np.random.default_rng(42)
    n_bars = 500
    close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
    high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
    low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
    open_ = (high + low) / 2
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    bars = BarArrays(
        open=open_.astype(np.float64),
        high=high.astype(np.float64),
        low=low.astype(np.float64),
        close=close.astype(np.float64),
    )
    
    # Choose test parameters
    ch_len = 20
    atr_len = 10
    params = DonchianAtrParams(channel_len=ch_len, atr_len=atr_len, stop_mult=1.0)
    
    # Pre-compute indicators (same logic as runner_grid)
    donch_hi_precomp = rolling_max(bars.high, ch_len)
    donch_lo_precomp = rolling_min(bars.low, ch_len)
    atr_precomp = atr_wilder(bars.high, bars.low, bars.close, atr_len)
    
    precomp = PrecomputedIndicators(
        donch_hi=donch_hi_precomp,
        donch_lo=donch_lo_precomp,
        atr=atr_precomp,
    )
    
    # Run A: Without precomputation
    result_a = run_kernel_arrays(
        bars=bars,
        params=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        precomp=None,
    )
    
    # Run B: With precomputation
    result_b = run_kernel_arrays(
        bars=bars,
        params=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        precomp=precomp,
    )
    
    # Verify indicators are bit-exact (if we could access them)
    # Note: We can't directly access internal arrays, but we verify outputs
    
    # Verify metrics are identical
    metrics_a = result_a["metrics"]
    metrics_b = result_b["metrics"]
    assert metrics_a["net_profit"] == metrics_b["net_profit"], "net_profit must be identical"
    assert metrics_a["trades"] == metrics_b["trades"], "trades must be identical"
    assert metrics_a["max_dd"] == metrics_b["max_dd"], "max_dd must be identical"
    
    # Verify fills are identical
    fills_a = result_a["fills"]
    fills_b = result_b["fills"]
    assert len(fills_a) == len(fills_b), "fills count must be identical"
    for i, (fill_a, fill_b) in enumerate(zip(fills_a, fills_b)):
        assert _fill_to_tuple(fill_a) == _fill_to_tuple(fill_b), f"fill[{i}] must be identical"
    
    # Verify equity arrays are bit-exact
    equity_a = result_a["equity"]
    equity_b = result_b["equity"]
    assert equity_a.shape == equity_b.shape, "equity shape must be identical"
    np.testing.assert_array_equal(equity_a, equity_b, "equity must be bit-exact")
    
    # Verify pnl arrays are bit-exact
    pnl_a = result_a["pnl"]
    pnl_b = result_b["pnl"]
    assert pnl_a.shape == pnl_b.shape, "pnl shape must be identical"
    np.testing.assert_array_equal(pnl_a, pnl_b, "pnl must be bit-exact")
    
    # Verify observability counts are identical
    obs_a = result_a.get("_obs", {})
    obs_b = result_b.get("_obs", {})
    assert obs_a.get("intents_total") == obs_b.get("intents_total"), "intents_total must be identical"
    assert obs_a.get("fills_total") == obs_b.get("fills_total"), "fills_total must be identical"


================================================================================
FILE: tests/test_kernel_parity_contract.py
================================================================================

"""Kernel parity contract tests - Phase 4 Stage C.

These tests ensure that Cursor kernel results are bit-level identical to matcher_core.
This is a critical contract: any deviation indicates a semantic bug.

Tests use simulate_run() unified entry point to ensure we test the actual API used in production.
"""

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.simulate import simulate_run
from FishBroWFS_V2.engine.types import OrderIntent, OrderKind, OrderRole, Side


def _bars1(o, h, l, c):
    """Helper to create single-bar BarArrays."""
    return normalize_bars(
        np.array([o], dtype=np.float64),
        np.array([h], dtype=np.float64),
        np.array([l], dtype=np.float64),
        np.array([c], dtype=np.float64),
    )


def _bars2(o0, h0, l0, c0, o1, h1, l1, c1):
    """Helper to create two-bar BarArrays."""
    return normalize_bars(
        np.array([o0, o1], dtype=np.float64),
        np.array([h0, h1], dtype=np.float64),
        np.array([l0, l1], dtype=np.float64),
        np.array([c0, c1], dtype=np.float64),
    )


def _bars3(o0, h0, l0, c0, o1, h1, l1, c1, o2, h2, l2, c2):
    """Helper to create three-bar BarArrays."""
    return normalize_bars(
        np.array([o0, o1, o2], dtype=np.float64),
        np.array([h0, h1, h2], dtype=np.float64),
        np.array([l0, l1, l2], dtype=np.float64),
        np.array([c0, c1, c2], dtype=np.float64),
    )


def _compute_position_path(fills):
    """
    Compute position path from fills sequence.
    
    Returns list of (bar_index, position) tuples where position is:
    - 0: flat
    - 1: long
    - -1: short
    """
    pos_path = []
    current_pos = 0
    
    # Group fills by bar_index
    fills_by_bar = {}
    for fill in fills:
        bar_idx = fill.bar_index
        if bar_idx not in fills_by_bar:
            fills_by_bar[bar_idx] = []
        fills_by_bar[bar_idx].append(fill)
    
    # Process fills chronologically
    for bar_idx in sorted(fills_by_bar.keys()):
        bar_fills = fills_by_bar[bar_idx]
        # Sort by role (ENTRY first), then kind, then order_id
        bar_fills.sort(key=lambda f: (
            0 if f.role == OrderRole.ENTRY else 1,
            0 if f.kind == OrderKind.STOP else 1,
            f.order_id
        ))
        
        for fill in bar_fills:
            if fill.role == OrderRole.ENTRY:
                if fill.side == Side.BUY:
                    current_pos = 1
                else:
                    current_pos = -1
            elif fill.role == OrderRole.EXIT:
                current_pos = 0
        
        pos_path.append((bar_idx, current_pos))
    
    return pos_path


def _assert_fills_identical(cursor_fills, reference_fills):
    """Assert that two fill sequences are bit-level identical."""
    assert len(cursor_fills) == len(reference_fills), (
        f"Fill count mismatch: cursor={len(cursor_fills)}, reference={len(reference_fills)}"
    )
    
    for i, (c_fill, r_fill) in enumerate(zip(cursor_fills, reference_fills)):
        assert c_fill.bar_index == r_fill.bar_index, (
            f"Fill {i}: bar_index mismatch: cursor={c_fill.bar_index}, reference={r_fill.bar_index}"
        )
        assert c_fill.role == r_fill.role, (
            f"Fill {i}: role mismatch: cursor={c_fill.role}, reference={r_fill.role}"
        )
        assert c_fill.kind == r_fill.kind, (
            f"Fill {i}: kind mismatch: cursor={c_fill.kind}, reference={r_fill.kind}"
        )
        assert c_fill.side == r_fill.side, (
            f"Fill {i}: side mismatch: cursor={c_fill.side}, reference={r_fill.side}"
        )
        assert c_fill.price == r_fill.price, (
            f"Fill {i}: price mismatch: cursor={c_fill.price}, reference={r_fill.price}"
        )
        assert c_fill.qty == r_fill.qty, (
            f"Fill {i}: qty mismatch: cursor={c_fill.qty}, reference={r_fill.qty}"
        )
        assert c_fill.order_id == r_fill.order_id, (
            f"Fill {i}: order_id mismatch: cursor={c_fill.order_id}, reference={r_fill.order_id}"
        )


def _assert_position_path_identical(cursor_fills, reference_fills):
    """Assert that position paths are identical."""
    cursor_path = _compute_position_path(cursor_fills)
    reference_path = _compute_position_path(reference_fills)
    
    assert cursor_path == reference_path, (
        f"Position path mismatch:\n"
        f"  cursor: {cursor_path}\n"
        f"  reference: {reference_path}"
    )


def test_parity_next_bar_activation():
    """Test next-bar activation rule: order created at bar N activates at bar N+1."""
    # Order created at bar 0, should activate at bar 1
    bars = _bars2(
        100, 105, 95, 100,  # bar 0: high=105 would hit stop 102, but order not active yet
        100, 105, 95, 100,  # bar 1: order activates, should fill
    )
    intents = [
        OrderIntent(order_id=1, created_bar=0, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    
    # Verify: should fill at bar 1, not bar 0
    assert len(cursor_result.fills) == 1
    assert cursor_result.fills[0].bar_index == 1


def test_parity_stop_fill_price_exact():
    """Test stop fill price = stop_price (not max(open, stop_price))."""
    # Buy stop at 100, open=95, high=105 -> should fill at 100 (stop_price), not 105
    bars = _bars1(95, 105, 90, 100)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].price == 100.0  # stop_price, not high


def test_parity_stop_fill_price_gap_up():
    """Test stop fill price on gap up: fill at open if open >= stop_price."""
    # Buy stop at 100, open=105 (gap up) -> should fill at 105 (open), not 100
    bars = _bars1(105, 110, 105, 108)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].price == 105.0  # open (gap branch)


def test_parity_stop_fill_price_gap_down():
    """Test stop fill price on gap down: fill at open if open <= stop_price."""
    # Sell stop at 100, open=90 (gap down) -> should fill at 90 (open), not 100
    bars = _bars2(
        100, 100, 100, 100,  # bar 0: enter long
        90, 95, 80, 85,      # bar 1: exit stop gap down
    )
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    # Exit fill should be at open (90) due to gap down
    assert cursor_result.fills[1].price == 90.0


def test_parity_same_bar_entry_then_exit():
    """Test same-bar entry then exit is allowed."""
    # Same bar: entry buy stop 105, exit sell stop 95
    # Bar: O=100 H=120 L=90
    # Entry: Buy Stop 105 -> fills at 105
    # Exit: Sell Stop 95 -> fills at 95 (after entry)
    bars = _bars1(100, 120, 90, 110)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=105.0),
        OrderIntent(order_id=2, created_bar=-1, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=95.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    
    assert len(cursor_result.fills) == 2
    assert cursor_result.fills[0].role == OrderRole.ENTRY
    assert cursor_result.fills[0].price == 105.0
    assert cursor_result.fills[1].role == OrderRole.EXIT
    assert cursor_result.fills[1].price == 95.0
    assert cursor_result.fills[0].bar_index == cursor_result.fills[1].bar_index


def test_parity_stop_priority_over_limit():
    """Test STOP priority over LIMIT (same role, same bar)."""
    # Entry: Buy Stop 102 and Buy Limit 110 both triggerable
    # STOP must win
    bars = _bars1(100, 115, 95, 105)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
        OrderIntent(order_id=2, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.LIMIT, side=Side.BUY, price=110.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].kind == OrderKind.STOP
    assert cursor_result.fills[0].order_id == 1


def test_parity_stop_priority_exit():
    """Test STOP priority over LIMIT on exit."""
    # Enter long first, then exit with both stop and limit triggerable
    # STOP must win
    bars = _bars2(
        100, 100, 100, 100,  # bar 0: enter long
        100, 110, 80, 90,    # bar 1: exit stop 90 and exit limit 110 both triggerable
    )
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=90.0),
        OrderIntent(order_id=3, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.LIMIT, side=Side.SELL, price=110.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    
    # Exit fill should be STOP
    assert cursor_result.fills[1].kind == OrderKind.STOP
    assert cursor_result.fills[1].order_id == 2


def test_parity_order_id_tie_break():
    """Test order_id tie-break when kind is same."""
    # Two STOP orders, lower order_id should win
    bars = _bars1(100, 110, 95, 105)
    intents = [
        OrderIntent(order_id=2, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].order_id == 1  # Lower order_id wins


def test_parity_limit_gap_down_better_fill():
    """Test limit order gap down: fill at open if better."""
    # Buy limit at 100, open=90 (gap down) -> should fill at 90 (open), not 100
    bars = _bars1(90, 95, 85, 92)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.LIMIT, side=Side.BUY, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].price == 90.0  # open (better fill)


def test_parity_limit_gap_up_better_fill():
    """Test limit order gap up: fill at open if better."""
    # Sell limit at 100, open=105 (gap up) -> should fill at 105 (open), not 100
    bars = _bars1(105, 110, 100, 108)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.LIMIT, side=Side.SELL, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].price == 105.0  # open (better fill)


def test_parity_no_fill_when_not_touched():
    """Test no fill when price not touched."""
    bars = _bars1(90, 95, 90, 92)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert len(cursor_result.fills) == 0


def test_parity_open_equals_stop_gap_branch():
    """Test open equals stop price: gap branch but same price."""
    bars = _bars1(100, 100, 90, 95)
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    assert cursor_result.fills[0].price == 100.0  # open == stop_price


def test_parity_multiple_bars_complex():
    """Test complex multi-bar scenario with entry and exit."""
    bars = _bars3(
        100, 105, 95, 100,   # bar 0: enter long at 102 (buy stop)
        100, 110, 80, 90,    # bar 1: exit stop 90 triggers
        95, 100, 90, 95,     # bar 2: no fills
    )
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=102.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=90.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    
    # Verify position path
    pos_path = _compute_position_path(cursor_result.fills)
    assert pos_path == [(0, 1), (1, 0)]  # Enter at bar 0, exit at bar 1


def test_parity_entry_skipped_when_position_exists():
    """Test that entry is skipped when position already exists."""
    # Enter long at bar 0, then at bar 1 try to enter again (should be skipped) and exit
    bars = _bars2(
        100, 100, 100, 100,  # bar 0: enter long
        100, 110, 90, 100,   # bar 1: exit stop 95 triggers, entry stop 105 also triggerable but skipped
    )
    intents = [
        OrderIntent(order_id=1, created_bar=-1, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=100.0),
        OrderIntent(order_id=2, created_bar=0, role=OrderRole.EXIT, kind=OrderKind.STOP, side=Side.SELL, price=95.0),
        OrderIntent(order_id=3, created_bar=0, role=OrderRole.ENTRY, kind=OrderKind.STOP, side=Side.BUY, price=105.0),
    ]
    
    # Use unified simulate_run() entry point
    cursor_result = simulate_run(bars, intents, use_reference=False)
    reference_result = simulate_run(bars, intents, use_reference=True)
    
    _assert_fills_identical(cursor_result.fills, reference_result.fills)
    _assert_position_path_identical(cursor_result.fills, reference_result.fills)
    
    # Should have entry at bar 0 and exit at bar 1
    # Entry at bar 1 should be skipped (position already exists)
    assert len(cursor_result.fills) == 2
    assert cursor_result.fills[0].bar_index == 0
    assert cursor_result.fills[0].role == OrderRole.ENTRY
    assert cursor_result.fills[1].bar_index == 1
    assert cursor_result.fills[1].role == OrderRole.EXIT


================================================================================
FILE: tests/test_perf_breakdown_contract.py
================================================================================

"""
Stage P2-1.8: Contract Tests for Granular Breakdown and Extended Observability

Tests that verify:
- Granular timing keys exist and are non-negative floats
- Extended observability keys exist (entry/exit intents/fills totals)
- Accounting consistency (intents_total == entry + exit, fills_total == entry + exit)
- run_grid output contains timing keys in perf dict
"""
from __future__ import annotations

import os
import numpy as np

from FishBroWFS_V2.strategy.kernel import run_kernel_arrays, DonchianAtrParams
from FishBroWFS_V2.engine.types import BarArrays
from FishBroWFS_V2.pipeline.runner_grid import run_grid


def test_perf_breakdown_keys_existence() -> None:
    """
    D1: Contract test - Verify granular timing keys exist in _obs and are floats >= 0.0
    Also verify that t_total_kernel_s >= max(stage_times) for sanity check.
    
    Contract: keys always exist, values always float >= 0.0.
    (When perf harness runs with profiling enabled, these will naturally become >0 real data.)
    """
    import os
    # Ensure clean environment for test
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    # Task 2: Kernel profiling is optional - keys will always exist (may be 0.0 if not profiled)
    # We can optionally enable profiling to get real timing data, but it's not required for contract
    old_profile_kernel = os.environ.get("FISHBRO_PROFILE_KERNEL")
    # Optionally enable profiling to get real timing values (not required - keys exist regardless)
    # Uncomment the line below if you want to test with profiling enabled:
    # os.environ["FISHBRO_PROFILE_KERNEL"] = "1"
    
    try:
        n_bars = 200
        warmup = 20
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        bars = BarArrays(
            open=open_.astype(np.float64),
            high=high.astype(np.float64),
            low=low.astype(np.float64),
            close=close.astype(np.float64),
        )
        
        params = DonchianAtrParams(channel_len=warmup, atr_len=10, stop_mult=1.0)
        
        result = run_kernel_arrays(
            bars=bars,
            params=params,
            commission=0.0,
            slip=0.0,
            order_qty=1,
        )
        
        # Verify _obs exists and contains timing keys
        assert "_obs" in result, "_obs must exist in kernel result"
        obs = result["_obs"]
        assert isinstance(obs, dict), "_obs must be a dict"
        
        # Required timing keys (now in _obs, not _perf)
        # Task 2: Contract - keys always exist, values always float >= 0.0
        timing_keys = [
            "t_calc_indicators_s",
            "t_build_entry_intents_s",
            "t_simulate_entry_s",
            "t_calc_exits_s",
            "t_simulate_exit_s",
            "t_total_kernel_s",
        ]
        
        stage_times = []
        for key in timing_keys:
            assert key in obs, f"{key} must exist in _obs (keys always exist, even if 0.0)"
            value = obs[key]
            assert isinstance(value, float), f"{key} must be float, got {type(value)}"
            assert value >= 0.0, f"{key} must be >= 0.0, got {value}"
            if key != "t_total_kernel_s":
                stage_times.append(value)
        
        # Sanity check: total time should be >= max of individual stage times
        # (allowing some overhead for timer calls and other operations)
        # Note: This check only makes sense if profiling was enabled (values > 0)
        t_total = obs["t_total_kernel_s"]
        if stage_times and t_total > 0.0:
            max_stage = max(stage_times)
            # Allow equality or small overhead
            assert t_total >= max_stage, (
                f"t_total_kernel_s ({t_total}) should be >= max(stage_times) ({max_stage})"
            )
    finally:
        # Restore environment
        # restore trigger rate
        if old_trigger_rate is None:
            os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
        else:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate
        
        # restore kernel profiling flag
        if old_profile_kernel is None:
            os.environ.pop("FISHBRO_PROFILE_KERNEL", None)
        else:
            os.environ["FISHBRO_PROFILE_KERNEL"] = old_profile_kernel


def test_extended_observability_keys_existence() -> None:
    """
    D1: Contract test - Verify extended observability keys exist in _obs
    """
    import os
    # Ensure clean environment for test
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    
    try:
        n_bars = 200
        warmup = 20
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        bars = BarArrays(
            open=open_.astype(np.float64),
            high=high.astype(np.float64),
            low=low.astype(np.float64),
            close=close.astype(np.float64),
        )
        
        params = DonchianAtrParams(channel_len=warmup, atr_len=10, stop_mult=1.0)
        
        result = run_kernel_arrays(
            bars=bars,
            params=params,
            commission=0.0,
            slip=0.0,
            order_qty=1,
        )
        
        # Verify _obs exists and contains extended keys
        assert "_obs" in result, "_obs must exist in kernel result"
        obs = result["_obs"]
        assert isinstance(obs, dict), "_obs must be a dict"
        
        # Required observability keys
        obs_keys = [
            "entry_intents_total",
            "entry_fills_total",
            "exit_intents_total",
            "exit_fills_total",
        ]
        
        for key in obs_keys:
            assert key in obs, f"{key} must exist in _obs"
            value = obs[key]
            assert isinstance(value, int), f"{key} must be int, got {type(value)}"
            assert value >= 0, f"{key} must be >= 0, got {value}"
    finally:
        # Restore environment
        if old_trigger_rate is not None:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate


def test_accounting_consistency() -> None:
    """
    D2: Contract test - Verify accounting consistency
    intents_total == entry_intents_total + exit_intents_total
    fills_total == entry_fills_total + exit_fills_total
    Also verify entry_intents_total == valid_mask_sum in arrays mode
    """
    import os
    # Ensure clean environment for test
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    
    try:
        n_bars = 200
        warmup = 20
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        bars = BarArrays(
            open=open_.astype(np.float64),
            high=high.astype(np.float64),
            low=low.astype(np.float64),
            close=close.astype(np.float64),
        )
        
        params = DonchianAtrParams(channel_len=warmup, atr_len=10, stop_mult=1.0)
        
        result = run_kernel_arrays(
            bars=bars,
            params=params,
            commission=0.0,
            slip=0.0,
            order_qty=1,
        )
        
        obs = result["_obs"]
        
        # Verify intents_total consistency
        intents_total = obs.get("intents_total", 0)
        entry_intents_total = obs.get("entry_intents_total", 0)
        exit_intents_total = obs.get("exit_intents_total", 0)
        
        assert intents_total == entry_intents_total + exit_intents_total, (
            f"intents_total ({intents_total}) must equal "
            f"entry_intents_total ({entry_intents_total}) + exit_intents_total ({exit_intents_total})"
        )
        
        # Verify fills_total consistency
        fills_total = obs.get("fills_total", 0)
        entry_fills_total = obs.get("entry_fills_total", 0)
        exit_fills_total = obs.get("exit_fills_total", 0)
        
        assert fills_total == entry_fills_total + exit_fills_total, (
            f"fills_total ({fills_total}) must equal "
            f"entry_fills_total ({entry_fills_total}) + exit_fills_total ({exit_fills_total})"
        )
        
        # Verify entry_intents_total == valid_mask_sum (arrays mode contract)
        if "valid_mask_sum" in obs and "entry_intents_total" in obs:
            valid_mask_sum = obs.get("valid_mask_sum", 0)
            entry_intents = obs.get("entry_intents_total", 0)
            assert entry_intents == valid_mask_sum, (
                f"entry_intents_total ({entry_intents}) must equal valid_mask_sum ({valid_mask_sum})"
            )
    finally:
        # Restore environment
        if old_trigger_rate is not None:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate


def test_run_grid_perf_contains_timing_keys(monkeypatch) -> None:
    """
    Contract test - Verify run_grid output contains timing keys in perf dict.
    This ensures timing aggregation works correctly at grid level.
    """
    # Task 1: Explicitly enable kernel profiling (required for timing collection)
    old_profile_kernel = os.environ.get("FISHBRO_PROFILE_KERNEL")
    os.environ["FISHBRO_PROFILE_KERNEL"] = "1"
    
    # Enable profile mode to ensure timing collection
    monkeypatch.setenv("FISHBRO_PROFILE_GRID", "1")
    
    try:
        n_bars = 200
        n_params = 5
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate minimal params
        params = np.array([
            [20, 10, 1.0],
            [25, 12, 1.5],
            [30, 15, 2.0],
            [35, 18, 1.0],
            [40, 20, 1.5],
        ], dtype=np.float64)
        
        result = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=False,
        )
        
        # Verify perf dict exists
        assert "perf" in result, "perf must exist in run_grid result"
        perf = result["perf"]
        assert isinstance(perf, dict), "perf must be a dict"
        
        # Stage P2-2 Step A: Required micro-profiling timing keys (aggregated across params)
        # Task 2: Since profile is enabled, timing keys must exist
        timing_keys = [
            "t_ind_donchian_s",
            "t_ind_atr_s",
            "t_build_entry_intents_s",
            "t_simulate_entry_s",
            "t_calc_exits_s",
            "t_simulate_exit_s",
            "t_total_kernel_s",
        ]
        
        for key in timing_keys:
            assert key in perf, f"{key} must exist in perf dict when profile is enabled"
            value = perf[key]
            assert isinstance(value, float), f"{key} must be float, got {type(value)}"
            assert value >= 0.0, f"{key} must be >= 0.0, got {value}"
        
        # Stage P2-2 Step A: Memoization potential assessment keys
        unique_keys = [
            "unique_channel_len_count",
            "unique_atr_len_count",
            "unique_ch_atr_pair_count",
        ]
        
        for key in unique_keys:
            assert key in perf, f"{key} must exist in perf dict"
            value = perf[key]
            assert isinstance(value, int), f"{key} must be int, got {type(value)}"
            assert value >= 1, f"{key} must be >= 1, got {value}"
    finally:
        # Task 1: Restore FISHBRO_PROFILE_KERNEL environment variable
        if old_profile_kernel is None:
            os.environ.pop("FISHBRO_PROFILE_KERNEL", None)
        else:
            os.environ["FISHBRO_PROFILE_KERNEL"] = old_profile_kernel


================================================================================
FILE: tests/test_perf_env_config_contract.py
================================================================================

"""Test perf harness environment variable configuration contract.

Ensures that FISHBRO_PERF_BARS and FISHBRO_PERF_PARAMS env vars are correctly parsed.
"""

import os
import sys
from pathlib import Path
from unittest.mock import patch


def _get_perf_config():
    """
    Helper to get perf config values by reading the script file.
    This avoids import issues with scripts/ module.
    """
    script_path = Path(__file__).parent.parent / "scripts" / "perf_grid.py"
    
    # Read and parse the constants
    with open(script_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # Extract default values from the file
    # Look for: TIER_JIT_BARS = int(os.environ.get("FISHBRO_PERF_BARS", "20000"))
    import re
    
    bars_match = re.search(r'TIER_JIT_BARS\s*=\s*int\(os\.environ\.get\("FISHBRO_PERF_BARS",\s*"(\d+)"\)\)', content)
    params_match = re.search(r'TIER_JIT_PARAMS\s*=\s*int\(os\.environ\.get\("FISHBRO_PERF_PARAMS",\s*"(\d+)"\)\)', content)
    
    default_bars = int(bars_match.group(1)) if bars_match else None
    default_params = int(params_match.group(1)) if params_match else None
    
    return default_bars, default_params


def test_perf_env_bars_parsing():
    """Test that FISHBRO_PERF_BARS env var is correctly parsed."""
    with patch.dict(os.environ, {"FISHBRO_PERF_BARS": "50000"}, clear=False):
        # Simulate the parsing logic
        bars = int(os.environ.get("FISHBRO_PERF_BARS", "20000"))
        assert bars == 50000


def test_perf_env_params_parsing():
    """Test that FISHBRO_PERF_PARAMS env var is correctly parsed."""
    with patch.dict(os.environ, {"FISHBRO_PERF_PARAMS": "5000"}, clear=False):
        # Simulate the parsing logic
        params = int(os.environ.get("FISHBRO_PERF_PARAMS", "1000"))
        assert params == 5000


def test_perf_env_both_parsing():
    """Test that both env vars can be set simultaneously."""
    with patch.dict(os.environ, {
        "FISHBRO_PERF_BARS": "30000",
        "FISHBRO_PERF_PARAMS": "3000",
    }, clear=False):
        bars = int(os.environ.get("FISHBRO_PERF_BARS", "20000"))
        params = int(os.environ.get("FISHBRO_PERF_PARAMS", "1000"))
        
        assert bars == 30000
        assert params == 3000


def test_perf_env_defaults():
    """Test that defaults are baseline (20000Ã—1000) when env vars are not set."""
    # Ensure env vars are not set for this test
    env_backup = {}
    for key in ["FISHBRO_PERF_BARS", "FISHBRO_PERF_PARAMS"]:
        if key in os.environ:
            env_backup[key] = os.environ[key]
            del os.environ[key]
    
    try:
        # Check defaults match baseline
        default_bars, default_params = _get_perf_config()
        assert default_bars == 20000, f"Expected default bars=20000, got {default_bars}"
        assert default_params == 1000, f"Expected default params=1000, got {default_params}"
        
        # Verify parsing logic uses defaults
        bars = int(os.environ.get("FISHBRO_PERF_BARS", "20000"))
        params = int(os.environ.get("FISHBRO_PERF_PARAMS", "1000"))
        assert bars == 20000
        assert params == 1000
    finally:
        # Restore env vars
        for key, value in env_backup.items():
            os.environ[key] = value


================================================================================
FILE: tests/test_perf_evidence_chain.py
================================================================================

from __future__ import annotations

import numpy as np

from FishBroWFS_V2.pipeline.runner_grid import run_grid


def test_perf_evidence_chain_exists() -> None:
    """
    Phase 3.0-D: Contract Test - Evidence Chain Existence
    
    Purpose: Lock down that evidence fields always exist and are non-null.
    This test only verifies evidence existence, not timing or strategy quality.
    """
    # Use minimal data: bars=50, params=3
    n_bars = 50
    n_params = 3
    
    # Generate synthetic OHLC data
    rng = np.random.default_rng(42)
    close = 100.0 + np.cumsum(rng.standard_normal(n_bars)).astype(np.float64)
    high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
    low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
    open_ = (high + low) / 2 + rng.standard_normal(n_bars) * 0.5
    
    # Ensure high >= max(open, close) and low <= min(open, close)
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # Generate minimal params: [channel_len, atr_len, stop_mult]
    params = np.array(
        [
            [10, 5, 1.0],
            [15, 7, 1.5],
            [20, 10, 2.0],
        ],
        dtype=np.float64,
    )
    
    # Run grid runner (array path)
    # Note: perf field is always present in runner output (Phase 3.0-B)
    out = run_grid(
        open_=open_,
        high=high,
        low=low,
        close=close,
        params_matrix=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        sort_params=False,
    )
    
    # Verify perf field exists
    assert "perf" in out, "perf field must exist in runner output"
    perf = out["perf"]
    assert isinstance(perf, dict), "perf must be a dict"
    
    # Phase 3.0-D: Assert evidence fields exist and are non-null
    # 1. intent_mode must be "arrays"
    assert "intent_mode" in perf, "intent_mode must exist in perf"
    assert perf["intent_mode"] == "arrays", (
        f"intent_mode expected 'arrays' but got '{perf['intent_mode']}'"
    )
    
    # 2. intents_total must exist, be non-null, and > 0
    assert "intents_total" in perf, "intents_total must exist in perf"
    assert perf["intents_total"] is not None, "intents_total must not be None"
    assert isinstance(perf["intents_total"], (int, np.integer)), (
        f"intents_total must be an integer, got {type(perf['intents_total'])}"
    )
    assert int(perf["intents_total"]) > 0, (
        f"intents_total must be > 0, got {perf['intents_total']}"
    )
    
    # 3. fills_total must exist and be non-null (can be 0, but not None)
    assert "fills_total" in perf, "fills_total must exist in perf"
    assert perf["fills_total"] is not None, "fills_total must not be None"
    assert isinstance(perf["fills_total"], (int, np.integer)), (
        f"fills_total must be an integer, got {type(perf['fills_total'])}"
    )
    # fills_total can be 0 (no trades), but must not be None


================================================================================
FILE: tests/test_perf_grid_profile_report.py
================================================================================

from __future__ import annotations

import cProfile

from FishBroWFS_V2.perf.profile_report import _format_profile_report


def test_profile_report_markers_present() -> None:
    pr = cProfile.Profile()
    pr.enable()
    _ = sum(range(10_000))  # tiny workload, deterministic
    pr.disable()
    report = _format_profile_report(
        lane_id="3",
        n_bars=2000,
        n_params=100,
        jit_enabled=True,
        sort_params=False,
        topn=10,
        mode="",
        pr=pr,
    )
    assert "__PROFILE_START__" in report
    assert "pstats sort: cumtime" in report
    assert "__PROFILE_END__" in report




================================================================================
FILE: tests/test_perf_obs_contract.py
================================================================================

"""Contract tests for perf observability (Stage P2-1.5).

These tests ensure that entry sparse observability fields are correctly
propagated from kernel to perf JSON output.
"""

import numpy as np
import pytest

from FishBroWFS_V2.pipeline.runner_grid import run_grid


def test_perf_obs_entry_sparse_fields():
    """
    Contract: perf dict must contain entry sparse observability fields.
    
    This test directly calls run_grid (no subprocess) to verify that:
    1. entry_valid_mask_sum is present in perf dict
    2. entry_intents_total is present in perf dict
    3. entry_valid_mask_sum == entry_intents_total (contract)
    4. entry_intents_per_bar_avg is correctly calculated
    """
    # Generate small synthetic data (fast test)
    n_bars = 2000
    n_params = 50
    
    rng = np.random.default_rng(42)
    close = 10000 + np.cumsum(rng.standard_normal(n_bars)) * 10
    high = close + np.abs(rng.standard_normal(n_bars)) * 5
    low = close - np.abs(rng.standard_normal(n_bars)) * 5
    open_ = (high + low) / 2 + rng.standard_normal(n_bars)
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # Generate params matrix (channel_len, atr_len, stop_mult)
    params_matrix = np.column_stack([
        np.random.randint(10, 30, size=n_params),  # channel_len
        np.random.randint(5, 20, size=n_params),   # atr_len
        np.random.uniform(1.0, 2.0, size=n_params),  # stop_mult
    ]).astype(np.float64)
    
    # Call run_grid (will use arrays mode by default)
    result = run_grid(
        open_=open_,
        high=high,
        low=low,
        close=close,
        params_matrix=params_matrix,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        sort_params=False,
    )
    
    # Verify result structure
    assert "perf" in result, "result must contain 'perf' dict"
    perf = result["perf"]
    assert isinstance(perf, dict), "perf must be a dict"
    
    # Verify entry sparse observability fields exist
    assert "entry_valid_mask_sum" in perf, (
        "perf must contain 'entry_valid_mask_sum' field"
    )
    assert "entry_intents_total" in perf, (
        "perf must contain 'entry_intents_total' field"
    )
    
    entry_valid_mask_sum = perf["entry_valid_mask_sum"]
    entry_intents_total = perf["entry_intents_total"]
    
    # Verify types
    assert isinstance(entry_valid_mask_sum, (int, np.integer)), (
        f"entry_valid_mask_sum must be int, got {type(entry_valid_mask_sum)}"
    )
    assert isinstance(entry_intents_total, (int, np.integer)), (
        f"entry_intents_total must be int, got {type(entry_intents_total)}"
    )
    
    # Contract: entry_valid_mask_sum == entry_intents_total
    assert entry_valid_mask_sum == entry_intents_total, (
        f"entry_valid_mask_sum ({entry_valid_mask_sum}) must equal "
        f"entry_intents_total ({entry_intents_total})"
    )
    
    # Verify entry_intents_per_bar_avg if present
    if "entry_intents_per_bar_avg" in perf:
        entry_intents_per_bar_avg = perf["entry_intents_per_bar_avg"]
        assert isinstance(entry_intents_per_bar_avg, (float, np.floating)), (
            f"entry_intents_per_bar_avg must be float, got {type(entry_intents_per_bar_avg)}"
        )
        
        # Verify calculation: entry_intents_per_bar_avg == entry_intents_total / n_bars
        expected_avg = entry_intents_total / n_bars
        assert abs(entry_intents_per_bar_avg - expected_avg) <= 1e-12, (
            f"entry_intents_per_bar_avg ({entry_intents_per_bar_avg}) must equal "
            f"entry_intents_total / n_bars ({expected_avg})"
        )
    
    # Verify intents_total_reported is present (preserves original)
    if "intents_total_reported" in perf:
        intents_total_reported = perf["intents_total_reported"]
        assert isinstance(intents_total_reported, (int, np.integer)), (
            f"intents_total_reported must be int, got {type(intents_total_reported)}"
        )
        # intents_total_reported should equal original intents_total
        if "intents_total" in perf:
            assert intents_total_reported == perf["intents_total"], (
                f"intents_total_reported ({intents_total_reported}) should equal "
                f"intents_total ({perf['intents_total']})"
            )


def test_perf_obs_entry_sparse_non_zero():
    """
    Contract: With valid data, entry sparse fields should be non-zero.
    
    This ensures that sparse masking is actually working and producing
    observable results.
    """
    # Generate data that should produce some valid intents
    n_bars = 1000
    n_params = 20
    
    rng = np.random.default_rng(42)
    close = 10000 + np.cumsum(rng.standard_normal(n_bars)) * 10
    high = close + np.abs(rng.standard_normal(n_bars)) * 5
    low = close - np.abs(rng.standard_normal(n_bars)) * 5
    open_ = (high + low) / 2 + rng.standard_normal(n_bars)
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    # Use reasonable params (should produce valid donch_hi)
    params_matrix = np.column_stack([
        np.full(n_params, 20, dtype=np.float64),  # channel_len = 20
        np.full(n_params, 14, dtype=np.float64),  # atr_len = 14
        np.full(n_params, 2.0, dtype=np.float64),  # stop_mult = 2.0
    ])
    
    result = run_grid(
        open_=open_,
        high=high,
        low=low,
        close=close,
        params_matrix=params_matrix,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        sort_params=False,
    )
    
    perf = result.get("perf", {})
    if "entry_valid_mask_sum" in perf and "entry_intents_total" in perf:
        entry_valid_mask_sum = perf["entry_valid_mask_sum"]
        entry_intents_total = perf["entry_intents_total"]
        
        # With valid data and reasonable params, we should have some intents
        # (but allow for edge cases where all are filtered)
        assert entry_valid_mask_sum >= 0, "entry_valid_mask_sum must be non-negative"
        assert entry_intents_total >= 0, "entry_intents_total must be non-negative"
        
        # With n_bars=1000 and channel_len=20, we should have some valid intents
        # after warmup (at least a few)
        if n_bars > 100:  # Only check if we have enough bars
            # Conservative: allow for edge cases but expect some intents
            # In practice, with valid data, we should have >> 0
            pass  # Just verify non-negative, don't enforce minimum


================================================================================
FILE: tests/test_perf_trigger_rate_contract.py
================================================================================

"""
Stage P2-1.6: Contract Tests for Trigger Rate Masking

Tests that verify trigger_rate control works correctly:
- entry_intents_total scales linearly with trigger_rate
- entry_valid_mask_sum == entry_intents_total
- Deterministic behavior (same seed â†’ same result)
"""
from __future__ import annotations

import numpy as np
import os

from FishBroWFS_V2.perf.scenario_control import apply_trigger_rate_mask


def test_trigger_rate_mask_rate_1_0_no_change() -> None:
    """
    Test that trigger_rate=1.0 preserves all valid triggers unchanged.
    """
    n_bars = 2000
    warmup = 100
    
    # Create trigger array: warmup period NaN, rest are valid positive values
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    # Apply mask with rate=1.0
    masked = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=1.0,
        warmup=warmup,
        seed=42,
    )
    
    # Should be unchanged
    assert np.array_equal(trigger, masked, equal_nan=True), (
        "trigger_rate=1.0 should not change trigger array"
    )


def test_trigger_rate_mask_rate_0_05_approximately_5_percent() -> None:
    """
    Test that trigger_rate=0.05 results in approximately 5% of valid triggers.
    Allows Â±20% relative error to account for random fluctuations.
    """
    n_bars = 2000
    warmup = 100
    n_valid_expected = n_bars - warmup  # Valid positions after warmup
    
    # Create trigger array: warmup period NaN, rest are valid positive values
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    # Apply mask with rate=0.05
    masked = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=42,
    )
    
    # Count valid (finite) positions after warmup
    valid_after_warmup = np.isfinite(masked[warmup:])
    n_valid_actual = int(np.sum(valid_after_warmup))
    
    # Expected: approximately 5% of valid positions
    expected_min = int(n_valid_expected * 0.05 * 0.8)  # 80% of 5% (lower bound)
    expected_max = int(n_valid_expected * 0.05 * 1.2)  # 120% of 5% (upper bound)
    
    assert expected_min <= n_valid_actual <= expected_max, (
        f"Expected ~5% valid triggers ({expected_min}-{expected_max}), "
        f"got {n_valid_actual} ({n_valid_actual/n_valid_expected*100:.2f}%)"
    )


def test_trigger_rate_mask_deterministic() -> None:
    """
    Test that same seed and same input produce identical mask results.
    """
    n_bars = 2000
    warmup = 100
    
    # Create trigger array
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    # Apply mask twice with same parameters
    masked1 = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=42,
    )
    
    masked2 = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=42,
    )
    
    # Should be identical
    assert np.array_equal(masked1, masked2, equal_nan=True), (
        "Same seed and input should produce identical mask results"
    )


def test_trigger_rate_mask_different_seeds_different_results() -> None:
    """
    Test that different seeds produce different mask results (when rate < 1.0).
    """
    n_bars = 2000
    warmup = 100
    
    # Create trigger array
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    # Apply mask with different seeds
    masked1 = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=42,
    )
    
    masked2 = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=999,
    )
    
    # Should be different (very unlikely to be identical with different seeds)
    assert not np.array_equal(masked1, masked2, equal_nan=True), (
        "Different seeds should produce different mask results"
    )


def test_trigger_rate_mask_preserves_warmup_nan() -> None:
    """
    Test that warmup period NaN positions are preserved (not masked).
    """
    n_bars = 2000
    warmup = 100
    
    # Create trigger array: warmup period NaN, rest are valid
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    # Apply mask
    masked = apply_trigger_rate_mask(
        trigger=trigger,
        trigger_rate=0.05,
        warmup=warmup,
        seed=42,
    )
    
    # Warmup period should remain NaN
    assert np.all(np.isnan(masked[:warmup])), (
        "Warmup period should remain NaN after masking"
    )


def test_trigger_rate_mask_linear_scaling() -> None:
    """
    Test that valid trigger count scales approximately linearly with trigger_rate.
    """
    n_bars = 2000
    warmup = 100
    n_valid_expected = n_bars - warmup
    
    # Create trigger array
    trigger = np.full(n_bars, np.nan, dtype=np.float64)
    trigger[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    rates = [0.1, 0.3, 0.5, 0.7, 0.9]
    valid_counts = []
    
    for rate in rates:
        masked = apply_trigger_rate_mask(
            trigger=trigger,
            trigger_rate=rate,
            warmup=warmup,
            seed=42,
        )
        n_valid = int(np.sum(np.isfinite(masked[warmup:])))
        valid_counts.append(n_valid)
    
    # Check approximate linearity: valid_counts[i] / valid_counts[j] â‰ˆ rates[i] / rates[j]
    # Use first and last as reference
    ratio_expected = rates[-1] / rates[0]  # 0.9 / 0.1 = 9.0
    ratio_actual = valid_counts[-1] / valid_counts[0] if valid_counts[0] > 0 else 0
    
    # Allow Â±30% error for random fluctuations
    assert 0.7 * ratio_expected <= ratio_actual <= 1.3 * ratio_expected, (
        f"Valid counts should scale linearly with rate. "
        f"Expected ratio ~{ratio_expected:.2f}, got {ratio_actual:.2f}. "
        f"Counts: {valid_counts}"
    )


def test_trigger_rate_mask_preserves_dtype() -> None:
    """
    Test that masking preserves the input dtype.
    """
    n_bars = 200
    warmup = 20
    
    # Test with float64
    trigger_f64 = np.full(n_bars, np.nan, dtype=np.float64)
    trigger_f64[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float64)
    
    masked_f64 = apply_trigger_rate_mask(
        trigger=trigger_f64,
        trigger_rate=0.5,
        warmup=warmup,
        seed=42,
    )
    
    assert masked_f64.dtype == np.float64, (
        f"Expected float64, got {masked_f64.dtype}"
    )
    
    # Test with float32
    trigger_f32 = np.full(n_bars, np.nan, dtype=np.float32)
    trigger_f32[warmup:] = np.arange(1, n_bars - warmup + 1, dtype=np.float32)
    
    masked_f32 = apply_trigger_rate_mask(
        trigger=trigger_f32,
        trigger_rate=0.5,
        warmup=warmup,
        seed=42,
    )
    
    assert masked_f32.dtype == np.float32, (
        f"Expected float32, got {masked_f32.dtype}"
    )


def test_trigger_rate_mask_integration_with_kernel() -> None:
    """
    Integration test: verify that trigger_rate affects entry_intents_total in run_kernel_arrays.
    This test uses run_kernel_arrays directly (no subprocess) to verify the integration.
    """
    from FishBroWFS_V2.strategy.kernel import run_kernel_arrays, DonchianAtrParams
    from FishBroWFS_V2.engine.types import BarArrays
    
    n_bars = 200
    warmup = 20
    
    # Generate simple OHLC data
    rng = np.random.default_rng(42)
    close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
    high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
    low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
    open_ = (high + low) / 2
    
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    
    bars = BarArrays(
        open=open_.astype(np.float64),
        high=high.astype(np.float64),
        low=low.astype(np.float64),
        close=close.astype(np.float64),
    )
    
    params = DonchianAtrParams(channel_len=warmup, atr_len=10, stop_mult=1.0)
    
    # Test with trigger_rate=1.0 (baseline) - explicitly set to avoid env interference
    os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
    result_1_0 = run_kernel_arrays(
        bars=bars,
        params=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
    )
    
    # Contract test: fail fast if keys missing (no .get() with defaults)
    entry_intents_1_0 = result_1_0["_obs"]["entry_intents_total"]
    valid_mask_sum_1_0 = result_1_0["_obs"]["entry_valid_mask_sum"]
    assert entry_intents_1_0 == valid_mask_sum_1_0
    
    # Test with trigger_rate=0.5
    os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "0.5"
    result_0_5 = run_kernel_arrays(
        bars=bars,
        params=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
    )
    
    # Contract test: fail fast if keys missing (no .get() with defaults)
    entry_intents_0_5 = result_0_5["_obs"]["entry_intents_total"]
    valid_mask_sum_0_5 = result_0_5["_obs"]["entry_valid_mask_sum"]
    assert entry_intents_0_5 == valid_mask_sum_0_5
    
    # Cleanup
    os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    
    # Verify that entry_intents_0_5 is approximately 50% of entry_intents_1_0
    # Allow Â±30% error for random fluctuations and warmup/NaN deterministic effects
    if entry_intents_1_0 > 0:
        ratio = entry_intents_0_5 / entry_intents_1_0
        assert 0.35 <= ratio <= 0.65, (
            f"With trigger_rate=0.5, expected entry_intents ~50% of baseline, "
            f"got {ratio*100:.1f}% (baseline={entry_intents_1_0}, actual={entry_intents_0_5})"
        )


================================================================================
FILE: tests/test_runner_grid_perf_observability.py
================================================================================

from __future__ import annotations

import numpy as np

from FishBroWFS_V2.pipeline.runner_grid import run_grid


def test_run_grid_perf_fields_present_and_non_negative(monkeypatch) -> None:
    # Enable perf observability.
    monkeypatch.setenv("FISHBRO_PROFILE_GRID", "1")

    o = np.array([100, 101, 102, 103, 104, 105], dtype=np.float64)
    h = np.array([101, 102, 103, 104, 106, 107], dtype=np.float64)
    l = np.array([99, 100, 101, 102, 103, 104], dtype=np.float64)
    c = np.array([100.5, 101.5, 102.5, 103.5, 105.5, 106.5], dtype=np.float64)

    params = np.array([[2, 2, 1.0], [3, 2, 1.5]], dtype=np.float64)
    out = run_grid(o, h, l, c, params, commission=0.0, slip=0.0, order_qty=1, sort_params=False)

    assert "perf" in out
    perf = out["perf"]
    assert isinstance(perf, dict)

    for k in ("t_features", "t_indicators", "t_intent_gen", "t_simulate"):
        assert k in perf
        # allow None (JSON null) when measurement is unavailable; never assume 0 is meaningful
        if perf[k] is not None:
            assert float(perf[k]) >= 0.0

    assert "simulate_impl" in perf
    assert perf["simulate_impl"] in ("jit", "py")

    assert "intents_total" in perf
    if perf["intents_total"] is not None:
        assert int(perf["intents_total"]) >= 0

    # Perf harness hook: confirm we can observe intent mode when profiling is enabled.
    assert "intent_mode" in perf
    if perf["intent_mode"] is not None:
        assert perf["intent_mode"] in ("arrays", "objects")




================================================================================
FILE: tests/test_sparse_intents_contract.py
================================================================================

"""
Stage P2-3A: Contract Tests for Sparse Entry Intents (Grid Level)

Verifies that entry intents are truly sparse at grid level:
- entry_intents_total == entry_valid_mask_sum (not Bars Ã— Params)
- Sparse builder produces identical results to dense builder (same triggers)
"""
from __future__ import annotations

from dataclasses import asdict, is_dataclass

import numpy as np
import os

from FishBroWFS_V2.engine.types import Fill
from FishBroWFS_V2.pipeline.runner_grid import run_grid


def _fill_to_tuple(f: Fill) -> tuple:
    """
    Convert Fill to a comparable tuple representation.
    
    Uses dataclasses.asdict for dataclass instances, falls back to __dict__ or repr.
    Returns sorted tuple to ensure deterministic comparison.
    """
    if is_dataclass(f):
        d = asdict(f)
    else:
        # fallback: __dict__ (for normal classes)
        d = dict(getattr(f, "__dict__", {}))
        if not d:
            # last resort: repr
            return (repr(f),)
    # Fixed ordering to avoid dict order differences
    return tuple(sorted(d.items()))


def test_grid_sparse_intents_count() -> None:
    """
    Test that grid-level entry intents count scales with trigger_rate (param-subsample).
    
    This test verifies the core sparse contract at grid level:
    - entry_intents_total == entry_valid_mask_sum
    - entry_intents_total scales approximately linearly with trigger_rate
    """
    # Ensure clean environment
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    old_param_subsample_rate = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
    old_profile_grid = os.environ.pop("FISHBRO_PROFILE_GRID", None)
    
    try:
        n_bars = 500
        n_params = 30  # Enough params to make "unique repetition" meaningful
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix (at least 10-50 params for meaningful unique repetition)
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 10)  # Vary channel_len (20-29)
            atr_len = 10 + (i % 5)  # Vary atr_len (10-14)
            stop_mult = 1.0 + (i % 3) * 0.5  # Vary stop_mult (1.0, 1.5, 2.0)
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Fix param_subsample_rate=1.0 (all params) to test trigger_rate effect on intents
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = "1.0"
        os.environ["FISHBRO_PROFILE_GRID"] = "1"
        
        # Run Dense (trigger_rate=1.0) - baseline
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
        
        result_dense = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Run Sparse (trigger_rate=0.05) - bar/intent-level sparsity
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "0.05"
        
        result_sparse = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify perf dicts exist
        perf_dense = result_dense.get("perf", {})
        perf_sparse = result_sparse.get("perf", {})
        
        assert isinstance(perf_dense, dict), "perf_dense must be a dict"
        assert isinstance(perf_sparse, dict), "perf_sparse must be a dict"
        
        # Core contract: entry_intents_total == entry_valid_mask_sum (both runs)
        entry_intents_dense = perf_dense.get("entry_intents_total")
        entry_valid_mask_dense = perf_dense.get("entry_valid_mask_sum")
        entry_intents_sparse = perf_sparse.get("entry_intents_total")
        entry_valid_mask_sparse = perf_sparse.get("entry_valid_mask_sum")
        
        assert entry_intents_dense == entry_valid_mask_dense, (
            f"Dense: entry_intents_total ({entry_intents_dense}) "
            f"must equal entry_valid_mask_sum ({entry_valid_mask_dense})"
        )
        assert entry_intents_sparse == entry_valid_mask_sparse, (
            f"Sparse: entry_intents_total ({entry_intents_sparse}) "
            f"must equal entry_valid_mask_sum ({entry_valid_mask_sparse})"
        )
        
        # Contract: entry_intents_sparse should be approximately trigger_rate * entry_intents_dense
        # With trigger_rate=0.05, we expect approximately 5% of dense baseline
        # Allow wide tolerance: [0.02, 0.08] (2% to 8% of dense)
        if entry_intents_dense is not None and entry_intents_dense > 0:
            ratio = entry_intents_sparse / entry_intents_dense
            assert 0.02 <= ratio <= 0.08, (
                f"With trigger_rate=0.05, entry_intents_sparse ({entry_intents_sparse}) "
                f"should be approximately 5% of entry_intents_dense ({entry_intents_dense}), "
                f"got ratio {ratio:.4f} (expected [0.02, 0.08])"
            )
        
    finally:
        # Restore environment
        if old_trigger_rate is None:
            os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
        else:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate
        
        if old_param_subsample_rate is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = old_param_subsample_rate
        
        if old_profile_grid is None:
            os.environ.pop("FISHBRO_PROFILE_GRID", None)
        else:
            os.environ["FISHBRO_PROFILE_GRID"] = old_profile_grid


def test_sparse_vs_dense_builder_parity() -> None:
    """
    Test that sparse builder produces identical results to dense builder (same triggers).
    
    This test verifies determinism parity:
    - Same triggers set â†’ same results (metrics, fills)
    - Order ID determinism
    - Bit-exact parity
    
    Uses FISHBRO_FORCE_SPARSE_BUILDER=1 to test numba builder vs python builder.
    """
    # Ensure clean environment
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    old_force_sparse = os.environ.pop("FISHBRO_FORCE_SPARSE_BUILDER", None)
    
    try:
        n_bars = 300
        n_params = 20
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 10)
            atr_len = 10 + (i % 5)
            stop_mult = 1.0 + (i % 3) * 0.5
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Run A: trigger_rate=1.0, force_sparse=0 (Python builder)
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
        os.environ.pop("FISHBRO_FORCE_SPARSE_BUILDER", None)  # Ensure not set
        
        result_a = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Run B: trigger_rate=1.0, force_sparse=1 (Numba builder, same triggers)
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
        os.environ["FISHBRO_FORCE_SPARSE_BUILDER"] = "1"
        
        result_b = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify metrics are identical (bit-exact)
        metrics_a = result_a.get("metrics")
        metrics_b = result_b.get("metrics")
        
        assert metrics_a is not None, "metrics_a must exist"
        assert metrics_b is not None, "metrics_b must exist"
        
        # Compare metrics arrays (should be bit-exact)
        np.testing.assert_array_equal(metrics_a, metrics_b, "metrics must be bit-exact")
        
        # Verify sparse contract holds in both runs
        perf_a = result_a.get("perf", {})
        perf_b = result_b.get("perf", {})
        
        if isinstance(perf_a, dict) and isinstance(perf_b, dict):
            entry_intents_a = perf_a.get("entry_intents_total")
            entry_intents_b = perf_b.get("entry_intents_total")
            
            if entry_intents_a is not None and entry_intents_b is not None:
                assert entry_intents_a == entry_intents_b, (
                    f"entry_intents_total should be identical (same triggers): "
                    f"A={entry_intents_a}, B={entry_intents_b}"
                )
        
    finally:
        # Restore environment
        if old_trigger_rate is None:
            os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
        else:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate
        
        if old_force_sparse is None:
            os.environ.pop("FISHBRO_FORCE_SPARSE_BUILDER", None)
        else:
            os.environ["FISHBRO_FORCE_SPARSE_BUILDER"] = old_force_sparse


def test_created_bar_sorted() -> None:
    """
    Test that created_bar arrays are sorted (ascending).
    
    Note: This test verifies the sparse builder contract that created_bar must be
    sorted. We verify this indirectly through the sparse contract consistency.
    """
    # Ensure clean environment
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    
    try:
        n_bars = 200
        n_params = 10
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 5)
            atr_len = 10 + (i % 3)
            stop_mult = 1.0
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Run grid
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
        
        result = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify sparse contract: entry_intents_total == entry_valid_mask_sum
        perf = result.get("perf", {})
        if isinstance(perf, dict):
            entry_intents_total = perf.get("entry_intents_total")
            entry_valid_mask_sum = perf.get("entry_valid_mask_sum")
            
            if entry_intents_total is not None and entry_valid_mask_sum is not None:
                assert entry_intents_total == entry_valid_mask_sum, (
                    f"Sparse contract: entry_intents_total ({entry_intents_total}) "
                    f"must equal entry_valid_mask_sum ({entry_valid_mask_sum})"
                )
        
        # Note: created_bar sorted verification would require accessing internal arrays
        # For now, we verify the sparse contract which implies created_bar is sorted
        # (since flatnonzero returns sorted indices)
        
    finally:
        # Restore environment
        if old_trigger_rate is None:
            os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
        else:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate


================================================================================
FILE: tests/test_sparse_intents_mvp_contract.py
================================================================================

"""Contract tests for sparse intents MVP (Stage P2-1).

These tests ensure:
1. created_bar is sorted (deterministic ordering)
2. intents_total drops significantly with sparse masking
3. Vectorization parity remains bit-exact
"""

import numpy as np
import pytest

from FishBroWFS_V2.config.dtypes import INDEX_DTYPE
from FishBroWFS_V2.engine.types import BarArrays
from FishBroWFS_V2.strategy.kernel import (
    DonchianAtrParams,
    _build_entry_intents_from_trigger,
    run_kernel_arrays,
)


def _expected_entry_count(donch_prev: np.ndarray, warmup: int) -> int:
    """
    Calculate expected entry count using the same mask rules as production.
    
    Production mask (from _build_entry_intents_from_trigger):
    - i = np.arange(1, n)  # bar indices t (from 1 to n-1)
    - valid_mask = (~np.isnan(donch_prev[1:])) & (donch_prev[1:] > 0) & (i >= warmup)
    
    This helper replicates that exact logic.
    """
    n = donch_prev.size
    # Create index array for bars 1..n-1 (bar indices t, where created_bar = t-1)
    i = np.arange(1, n, dtype=INDEX_DTYPE)
    # Sparse mask: valid entries must be finite, positive, and past warmup
    valid_mask = (~np.isnan(donch_prev[1:])) & (donch_prev[1:] > 0) & (i >= warmup)
    return int(np.count_nonzero(valid_mask))


def _make_donch_hi_with_trigger_rate(
    n_bars: int,
    warmup: int,
    trigger_rate: float,
    seed: int = 42,
) -> np.ndarray:
    """
    Generate donch_hi array with controlled trigger rate.
    
    Args:
        n_bars: number of bars
        warmup: warmup period (bars before warmup are NaN)
        trigger_rate: fraction of bars after warmup that should be valid (0.0-1.0)
        seed: random seed
    
    Returns:
        donch_hi array (float64, n_bars):
        - Bars 0..warmup-1: NaN
        - Bars warmup..n_bars-1: trigger_rate fraction are positive values, rest are NaN
    """
    rng = np.random.default_rng(seed)
    
    donch_hi = np.full(n_bars, np.nan, dtype=np.float64)
    
    # After warmup, set trigger_rate fraction to positive values
    post_warmup_bars = n_bars - warmup
    if post_warmup_bars > 0:
        n_valid = int(post_warmup_bars * trigger_rate)
        if n_valid > 0:
            # Select random indices after warmup
            valid_indices = rng.choice(
                np.arange(warmup, n_bars),
                size=n_valid,
                replace=False,
            )
            # Set valid indices to positive values (e.g., 100.0 + small random)
            donch_hi[valid_indices] = 100.0 + rng.random(n_valid) * 10.0
    
    return donch_hi


class TestSparseIntentsMVP:
    """Test sparse intents MVP contract."""

    def test_sparse_intents_created_bar_is_sorted(self):
        """
        Contract: created_bar must be sorted (non-decreasing).
        
        This ensures deterministic ordering and that sparse masking preserves
        the original bar sequence.
        """
        n_bars = 1000
        warmup = 20
        trigger_rate = 0.1
        
        # Generate donch_hi with controlled trigger rate
        donch_hi = _make_donch_hi_with_trigger_rate(n_bars, warmup, trigger_rate, seed=42)
        
        # Create donch_prev (shifted for next-bar active)
        donch_prev = np.empty_like(donch_hi)
        donch_prev[0] = np.nan
        donch_prev[1:] = donch_hi[:-1]
        
        # Build entry intents
        result = _build_entry_intents_from_trigger(
            donch_prev=donch_prev,
            channel_len=warmup,
            order_qty=1,
        )
        
        created_bar = result["created_bar"]
        n_entry = result["n_entry"]
        
        # Verify n_entry matches expected count (exact match using production mask rules)
        expected = _expected_entry_count(donch_prev, warmup)
        assert n_entry == expected, (
            f"n_entry ({n_entry}) should equal expected ({expected}) "
            f"calculated using production mask rules"
        )
        
        # Verify created_bar is sorted (non-decreasing)
        if n_entry > 1:
            assert np.all(created_bar[1:] >= created_bar[:-1]), (
                f"created_bar must be sorted (non-decreasing). "
                f"Got: {created_bar[:10]} ... (showing first 10)"
            )
        
        # Hard consistency check: created_bar must match flatnonzero result exactly
        # This locks in the ordering contract
        i = np.arange(1, donch_prev.size, dtype=INDEX_DTYPE)
        valid_mask = (~np.isnan(donch_prev[1:])) & (donch_prev[1:] > 0) & (i >= warmup)
        idx = np.flatnonzero(valid_mask).astype(created_bar.dtype)
        assert np.array_equal(created_bar[:n_entry], idx), (
            f"created_bar must exactly match flatnonzero result. "
            f"Got: {created_bar[:min(10, n_entry)]}, "
            f"Expected: {idx[:min(10, len(idx))]}"
        )

    def test_sparse_intents_total_drops_order_of_magnitude(self):
        """
        Contract: intents_total should drop significantly with sparse masking.
        
        With controlled trigger rate (e.g., 5%), intents_total should be << n_bars.
        This test directly controls donch_hi to ensure precise trigger rate.
        """
        n_bars = 1000
        warmup = 20
        trigger_rate = 0.05  # 5% trigger rate
        
        # Generate donch_hi with controlled trigger rate
        donch_hi = _make_donch_hi_with_trigger_rate(n_bars, warmup, trigger_rate, seed=42)
        
        # Create donch_prev (shifted for next-bar active)
        donch_prev = np.empty_like(donch_hi)
        donch_prev[0] = np.nan
        donch_prev[1:] = donch_hi[:-1]
        
        # Build entry intents
        result = _build_entry_intents_from_trigger(
            donch_prev=donch_prev,
            channel_len=warmup,
            order_qty=1,
        )
        
        n_entry = result["n_entry"]
        obs = result["obs"]
        
        # Verify diagnostic observations
        assert obs["n_bars"] == n_bars
        assert obs["warmup"] == warmup
        assert obs["valid_mask_sum"] == n_entry
        
        # Verify n_entry matches expected count (exact match using production mask rules)
        expected = _expected_entry_count(donch_prev, warmup)
        assert n_entry == expected, (
            f"n_entry ({n_entry}) should equal expected ({expected}) "
            f"calculated using production mask rules"
        )
        
        # Order-of-magnitude contract: n_entry should be significantly less than n_bars
        # This is the core contract of this test
        # Conservative threshold: 6% of (n_bars - warmup) as upper bound
        max_expected_ratio = 0.06  # 6% conservative upper bound
        max_expected = int((n_bars - warmup) * max_expected_ratio)
        
        assert n_entry <= max_expected, (
            f"n_entry ({n_entry}) should be <= {max_expected} "
            f"({max_expected_ratio*100}% of post-warmup bars) "
            f"with trigger_rate={trigger_rate}, n_bars={n_bars}, warmup={warmup}. "
            f"Sparse masking should significantly reduce intent count (order-of-magnitude reduction)."
        )
        
        # Also verify it's not zero (unless trigger_rate is too low)
        if trigger_rate > 0:
            # With 5% trigger rate, we should have some intents
            assert n_entry > 0, (
                f"Expected some intents with trigger_rate={trigger_rate}, "
                f"but got n_entry={n_entry}"
            )

    def test_vectorization_parity_still_bit_exact(self):
        """
        Contract: Vectorization parity tests should still pass after sparse masking.
        
        This test ensures that sparse masking doesn't break existing parity contracts.
        We rely on the existing test_vectorization_parity.py to verify this.
        
        This test is a placeholder to document the requirement.
        """
        # This test doesn't need to re-implement parity checks.
        # It's sufficient to ensure that make check passes all existing tests.
        # The actual parity verification is in tests/test_vectorization_parity.py
        
        # Basic sanity check: sparse masking should produce valid results
        n_bars = 100
        bars = BarArrays(
            open=np.arange(100, 200, dtype=np.float64),
            high=np.arange(101, 201, dtype=np.float64),
            low=np.arange(99, 199, dtype=np.float64),
            close=np.arange(100, 200, dtype=np.float64),
        )
        
        params = DonchianAtrParams(
            channel_len=10,
            atr_len=5,
            stop_mult=1.5,
        )
        
        result = run_kernel_arrays(
            bars,
            params,
            commission=0.0,
            slip=0.0,
            order_qty=1,
        )
        
        # Verify result structure is intact
        assert "fills" in result
        assert "metrics" in result
        assert "_obs" in result
        assert "intents_total" in result["_obs"]
        
        # Verify diagnostic observations are present
        assert "n_bars" in result["_obs"]
        assert "warmup" in result["_obs"]
        assert "valid_mask_sum" in result["_obs"]
        
        # Verify intents_total is reasonable
        intents_total = result["_obs"]["intents_total"]
        assert intents_total >= 0
        assert intents_total <= n_bars  # Should be <= n_bars due to sparse masking
        
        # Note: Full parity verification is done by test_vectorization_parity.py
        # This test just ensures the basic contract is met


================================================================================
FILE: tests/test_stage0_contract.py
================================================================================

from __future__ import annotations

"""
Stage 0 Contract Tests

Stage 0 must remain a "vector/proxy" layer:
  - MUST NOT import engine/matcher/strategy kernel/pipeline grid runner.
  - MUST NOT create OrderIntent/Fill objects.

These tests are intentionally strict: they prevent "silent scope creep"
that would destroy throughput and blur semantics.
"""

import ast
from pathlib import Path


def _read(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def test_stage0_does_not_import_engine_or_runner_grid() -> None:
    root = Path(__file__).resolve().parent.parent
    p = root / "src" / "FishBroWFS_V2" / "stage0" / "ma_proxy.py"
    code = _read(p)
    tree = ast.parse(code)

    banned_prefixes = (
        "FishBroWFS_V2.engine",
        "FishBroWFS_V2.strategy",
        "FishBroWFS_V2.pipeline",
    )

    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for a in node.names:
                name = a.name
                assert not name.startswith(banned_prefixes), f"banned import: {name}"
        if isinstance(node, ast.ImportFrom):
            mod = node.module or ""
            assert not mod.startswith(banned_prefixes), f"banned import-from: {mod}"


def test_stage0_file_exists() -> None:
    root = Path(__file__).resolve().parent.parent
    p = root / "src" / "FishBroWFS_V2" / "stage0" / "ma_proxy.py"
    assert p.exists(), "Stage0 module must exist"




================================================================================
FILE: tests/test_stage0_ma_proxy.py
================================================================================

from __future__ import annotations

import numpy as np

from FishBroWFS_V2.stage0.ma_proxy import stage0_score_ma_proxy


def test_stage0_scores_shape_and_ordering_trend_series() -> None:
    # Simple upward trend: MA(5)-MA(20) should be mostly positive => positive score
    n = 500
    close = np.linspace(100.0, 200.0, n, dtype=np.float64)

    params = np.array(
        [
            [5.0, 20.0, 0.0],
            [20.0, 5.0, 0.0],  # inverted => should score worse
            [1.0, 2.0, 0.0],
        ],
        dtype=np.float64,
    )

    scores = stage0_score_ma_proxy(close, params)
    assert scores.shape == (3,)
    assert np.isfinite(scores[0])
    assert np.isfinite(scores[1])
    assert np.isfinite(scores[2])
    assert scores[0] > scores[1]


def test_stage0_rejects_invalid_lengths() -> None:
    close = np.linspace(100.0, 101.0, 50, dtype=np.float64)
    params = np.array([[0.0, 10.0], [10.0, 0.0], [1000.0, 5.0]], dtype=np.float64)
    scores = stage0_score_ma_proxy(close, params)
    assert scores.shape == (3,)
    assert scores[0] == -np.inf
    assert scores[1] == -np.inf
    assert scores[2] == -np.inf




================================================================================
FILE: tests/test_stage0_no_pnl_contract.py
================================================================================

"""Test Stage0 contract: must NOT contain any PnL/metrics fields.

Stage0 is a proxy ranking stage and must not compute any PnL-related metrics.
This test enforces the contract by checking that Stage0Result does not contain
forbidden PnL/metrics fields.
"""

import inspect
import numpy as np

from FishBroWFS_V2.pipeline.stage0_runner import Stage0Result, run_stage0


# Blacklist of forbidden field names (PnL/metrics related)
FORBIDDEN_FIELD_NAMES = {
    "net",
    "profit",
    "mdd",
    "dd",
    "drawdown",
    "sqn",
    "sharpe",
    "winrate",
    "win_rate",
    "equity",
    "pnl",
    "return",
    "returns",
    "trades",
    "trade",
    "final",
    "score",
    "metric",
    "metrics",
}


def test_stage0_result_no_pnl_fields():
    """Test that Stage0Result dataclass does not contain forbidden PnL fields."""
    # Get all field names from Stage0Result
    if hasattr(Stage0Result, "__dataclass_fields__"):
        field_names = set(Stage0Result.__dataclass_fields__.keys())
    else:
        # Fallback: inspect annotations
        annotations = getattr(Stage0Result, "__annotations__", {})
        field_names = set(annotations.keys())
    
    # Check each field name against blacklist
    violations = []
    for field_name in field_names:
        field_lower = field_name.lower()
        for forbidden in FORBIDDEN_FIELD_NAMES:
            if forbidden in field_lower:
                violations.append(field_name)
                break
    
    assert len(violations) == 0, (
        f"Stage0Result contains forbidden PnL/metrics fields: {violations}\n"
        f"Allowed fields: {field_names}\n"
        f"Forbidden keywords: {FORBIDDEN_FIELD_NAMES}"
    )


def test_stage0_result_allowed_fields_only():
    """Test that Stage0Result only contains allowed fields."""
    # Allowed fields (from spec)
    allowed_fields = {"param_id", "proxy_value", "warmup_ok", "meta"}
    
    if hasattr(Stage0Result, "__dataclass_fields__"):
        actual_fields = set(Stage0Result.__dataclass_fields__.keys())
    else:
        annotations = getattr(Stage0Result, "__annotations__", {})
        actual_fields = set(annotations.keys())
    
    # Check that all fields are in allowed set
    unexpected = actual_fields - allowed_fields
    assert len(unexpected) == 0, (
        f"Stage0Result contains unexpected fields: {unexpected}\n"
        f"Allowed fields: {allowed_fields}\n"
        f"Actual fields: {actual_fields}"
    )


def test_stage0_runner_no_pnl_computation():
    """Test that run_stage0() does not compute PnL metrics."""
    # Generate test data
    np.random.seed(42)
    n_bars = 1000
    n_params = 50
    
    close = 10000 + np.cumsum(np.random.randn(n_bars)) * 10
    params_matrix = np.column_stack([
        np.random.randint(10, 100, size=n_params),
        np.random.randint(5, 50, size=n_params),
        np.random.uniform(1.0, 5.0, size=n_params),
    ]).astype(np.float64)
    
    # Run Stage0
    results = run_stage0(close, params_matrix)
    
    # Verify results structure
    assert len(results) == n_params
    
    for result in results:
        # Verify required fields exist
        assert hasattr(result, "param_id")
        assert hasattr(result, "proxy_value")
        
        # Verify param_id is valid
        assert isinstance(result.param_id, int)
        assert 0 <= result.param_id < n_params
        
        # Verify proxy_value is numeric (can be -inf for invalid params)
        assert isinstance(result.proxy_value, (int, float))
        
        # Verify no PnL fields exist (check attribute names)
        result_dict = result.__dict__ if hasattr(result, "__dict__") else {}
        for field_name in result_dict.keys():
            field_lower = field_name.lower()
            for forbidden in FORBIDDEN_FIELD_NAMES:
                assert forbidden not in field_lower, (
                    f"Stage0Result contains forbidden field: {field_name} "
                    f"(contains '{forbidden}')"
                )


def test_stage0_result_string_representation():
    """Test that Stage0Result string representation does not contain PnL keywords."""
    result = Stage0Result(
        param_id=0,
        proxy_value=10.5,
        warmup_ok=True,
        meta=None,
    )
    
    # Convert to string representation
    result_str = str(result).lower()
    result_repr = repr(result).lower()
    
    # Check that string representations don't contain forbidden keywords
    for forbidden in FORBIDDEN_FIELD_NAMES:
        assert forbidden not in result_str, (
            f"Stage0Result string representation contains forbidden keyword '{forbidden}': {result_str}"
        )
        assert forbidden not in result_repr, (
            f"Stage0Result repr contains forbidden keyword '{forbidden}': {result_repr}"
        )


================================================================================
FILE: tests/test_stage0_proxies.py
================================================================================

from __future__ import annotations

import numpy as np
import pytest

from FishBroWFS_V2.stage0.proxies import (
    activity_proxy,
    activity_proxy_nb,
    activity_proxy_py,
    trend_proxy,
    trend_proxy_nb,
    trend_proxy_py,
    vol_proxy,
    vol_proxy_nb,
    vol_proxy_py,
)

try:
    import numba as nb

    NUMBA_AVAILABLE = nb is not None
except Exception:
    NUMBA_AVAILABLE = False


def _generate_ohlc_trend(n: int, seed: int = 42) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Generate upward trend OHLC data."""
    rng = np.random.default_rng(seed)
    close = np.linspace(100.0, 200.0, n, dtype=np.float64)
    noise = rng.standard_normal(n) * 2.0
    close = close + noise
    high = close + np.abs(rng.standard_normal(n)) * 1.0
    low = close - np.abs(rng.standard_normal(n)) * 1.0
    open_ = (high + low) / 2 + rng.standard_normal(n) * 0.5
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    return open_, high, low, close


def _generate_ohlc_sine(n: int, seed: int = 999) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Generate oscillating (sine wave) OHLC data."""
    rng = np.random.default_rng(seed)
    t = np.linspace(0, 4 * np.pi, n)
    close = 100.0 + 20.0 * np.sin(t) + rng.standard_normal(n) * 1.0
    high = close + np.abs(rng.standard_normal(n)) * 1.0
    low = close - np.abs(rng.standard_normal(n)) * 1.0
    open_ = (high + low) / 2 + rng.standard_normal(n) * 0.5
    high = np.maximum(high, np.maximum(open_, close))
    low = np.minimum(low, np.minimum(open_, close))
    return open_, high, low, close


# ============================================================================
# Parity Tests (nb vs py)
# ============================================================================


def test_trend_proxy_parity() -> None:
    """Test parity between Numba and Python versions of trend_proxy."""
    if not NUMBA_AVAILABLE:
        pytest.skip("Numba not available")

    open_, high, low, close = _generate_ohlc_trend(500, seed=42)

    # Generate random params
    rng = np.random.default_rng(123)
    n_params = 200
    params = np.empty((n_params, 2), dtype=np.float64)
    params[:, 0] = rng.integers(5, 50, size=n_params)  # fast
    params[:, 1] = rng.integers(20, 100, size=n_params)  # slow

    scores_nb = trend_proxy_nb(open_, high, low, close, params)
    scores_py = trend_proxy_py(open_, high, low, close, params)

    assert scores_nb.shape == scores_py.shape == (n_params,)

    # Check finite scores match
    finite_mask = np.isfinite(scores_py)
    assert np.all(np.isfinite(scores_py[finite_mask]))
    assert np.allclose(scores_nb[finite_mask], scores_py[finite_mask], rtol=0, atol=1e-12)

    # Check -inf matches
    inf_mask = ~finite_mask
    assert np.all(np.isinf(scores_nb[inf_mask]))
    assert np.all(np.isinf(scores_py[inf_mask]))


def test_vol_proxy_parity() -> None:
    """Test parity between Numba and Python versions of vol_proxy."""
    if not NUMBA_AVAILABLE:
        pytest.skip("Numba not available")

    open_, high, low, close = _generate_ohlc_trend(500, seed=42)

    # Generate random params
    rng = np.random.default_rng(456)
    n_params = 200
    params = np.empty((n_params, 2), dtype=np.float64)
    params[:, 0] = rng.integers(5, 50, size=n_params)  # atr_len
    params[:, 1] = rng.uniform(0.2, 1.5, size=n_params)  # stop_mult

    scores_nb = vol_proxy_nb(open_, high, low, close, params)
    scores_py = vol_proxy_py(open_, high, low, close, params)

    assert scores_nb.shape == scores_py.shape == (n_params,)

    finite_mask = np.isfinite(scores_py)
    assert np.all(np.isfinite(scores_py[finite_mask]))
    assert np.allclose(scores_nb[finite_mask], scores_py[finite_mask], rtol=0, atol=1e-12)

    inf_mask = ~finite_mask
    assert np.all(np.isinf(scores_nb[inf_mask]))
    assert np.all(np.isinf(scores_py[inf_mask]))


def test_activity_proxy_parity() -> None:
    """Test parity between Numba and Python versions of activity_proxy."""
    if not NUMBA_AVAILABLE:
        pytest.skip("Numba not available")

    open_, high, low, close = _generate_ohlc_trend(500, seed=42)

    # Generate random params
    rng = np.random.default_rng(789)
    n_params = 200
    params = np.empty((n_params, 1), dtype=np.float64)
    params[:, 0] = rng.integers(5, 50, size=n_params)  # channel_len

    scores_nb = activity_proxy_nb(open_, high, low, close, params)
    scores_py = activity_proxy_py(open_, high, low, close, params)

    assert scores_nb.shape == scores_py.shape == (n_params,)

    finite_mask = np.isfinite(scores_py)
    assert np.all(np.isfinite(scores_py[finite_mask]))
    # Activity proxy uses log1p, so allow slightly larger tolerance
    assert np.allclose(scores_nb[finite_mask], scores_py[finite_mask], rtol=0, atol=1e-10)

    inf_mask = ~finite_mask
    assert np.all(np.isinf(scores_nb[inf_mask]))
    assert np.all(np.isinf(scores_py[inf_mask]))


# ============================================================================
# Semantic Tests
# ============================================================================


def test_trend_proxy_sanity_upward_trend() -> None:
    """Test that upward trend produces positive trend_score."""
    open_, high, low, close = _generate_ohlc_trend(500, seed=42)

    # Good params: fast < slow, reasonable values
    params_good = np.array([[10.0, 30.0], [15.0, 50.0]], dtype=np.float64)
    scores_good = trend_proxy(open_, high, low, close, params_good)

    # Bad params: inverted (fast >= slow)
    params_bad = np.array([[30.0, 10.0], [50.0, 15.0]], dtype=np.float64)
    scores_bad = trend_proxy(open_, high, low, close, params_bad)

    assert np.all(np.isfinite(scores_good))
    assert np.all(np.isfinite(scores_bad))

    # Good params should score better (or at least not worse) than inverted
    # In upward trend, fast < slow should give positive score
    assert scores_good[0] > 0.0 or scores_good[1] > 0.0


def test_activity_proxy_sanity_oscillation_vs_trend() -> None:
    """Test that oscillating sequence has higher activity than trend."""
    # Generate oscillating data
    open_sine, high_sine, low_sine, close_sine = _generate_ohlc_sine(500, seed=999)
    # Generate trend data
    open_trend, high_trend, low_trend, close_trend = _generate_ohlc_trend(500, seed=42)

    # Same params for both (channel_len only)
    params = np.array([[10.0], [15.0]], dtype=np.float64)

    scores_sine = activity_proxy(open_sine, high_sine, low_sine, close_sine, params)
    scores_trend = activity_proxy(open_trend, high_trend, low_trend, close_trend, params)

    assert np.all(np.isfinite(scores_sine))
    assert np.all(np.isfinite(scores_trend))

    # Oscillating sequence should have higher activity (more breakout triggers)
    assert np.mean(scores_sine) > np.mean(scores_trend)


def test_vol_proxy_sanity_positive_scores() -> None:
    """Test that vol_proxy returns finite scores for valid params."""
    open_, high, low, close = _generate_ohlc_trend(500, seed=42)

    params = np.array([[10.0, 0.5], [20.0, 1.0], [30.0, 1.5]], dtype=np.float64)  # [atr_len, stop_mult]
    scores = vol_proxy(open_, high, low, close, params)

    assert np.all(np.isfinite(scores))
    # Vol proxy scores are negative (-log1p(stop_mean)), but finite
    assert np.all(scores <= 0.0)  # Scores are negative (closer to 0 is better)


def test_proxies_reject_invalid_params() -> None:
    """Test that all proxies return -inf for invalid params."""
    open_, high, low, close = _generate_ohlc_trend(100, seed=42)

    # Invalid: too large
    params_invalid = np.array([[1000.0, 2000.0]], dtype=np.float64)

    scores_trend = trend_proxy(open_, high, low, close, params_invalid)
    params_activity_invalid = np.array([[1000.0]], dtype=np.float64)
    scores_activity = activity_proxy(open_, high, low, close, params_activity_invalid)

    assert np.all(np.isinf(scores_trend))
    assert np.all(np.isinf(scores_activity))
    assert np.all(scores_trend < 0)
    assert np.all(scores_activity < 0)

    # Invalid: zero or negative
    params_invalid2 = np.array([[0.0, 10.0], [-5.0, 10.0]], dtype=np.float64)

    scores_trend2 = trend_proxy(open_, high, low, close, params_invalid2)
    params_activity_invalid2 = np.array([[0.0], [-5.0]], dtype=np.float64)
    scores_activity2 = activity_proxy(open_, high, low, close, params_activity_invalid2)

    assert np.all(np.isinf(scores_trend2))
    assert np.all(np.isinf(scores_activity2))

    # Vol proxy: invalid
    params_vol_invalid = np.array([[1000.0, 0.5], [500.0, -1.0]], dtype=np.float64)  # [atr_len, stop_mult]
    scores_vol = vol_proxy(open_, high, low, close, params_vol_invalid)
    assert np.all(np.isinf(scores_vol))


================================================================================
FILE: tests/test_stage0_proxy_rank_corr.py
================================================================================

from __future__ import annotations

import os

import numpy as np
import pytest

from FishBroWFS_V2.pipeline.metrics_schema import (
    METRICS_COL_MAX_DD,
    METRICS_COL_NET_PROFIT,
    METRICS_COL_TRADES,
    METRICS_COLUMN_NAMES,
)
from FishBroWFS_V2.pipeline.runner_grid import run_grid
from FishBroWFS_V2.stage0.proxies import activity_proxy, trend_proxy, vol_proxy

try:
    import numba as nb
except Exception:
    nb = None  # type: ignore


def _rankdata(x: np.ndarray) -> np.ndarray:
    """
    Compute ranks for Spearman correlation (handles ties with average rank).

    Args:
        x: 1D array

    Returns:
        ranks: 1D array of ranks (1-indexed, ties get average rank)
    """
    n = x.shape[0]
    if n == 0:
        return np.empty(0, dtype=np.float64)

    # Get sorted indices
    sorted_indices = np.argsort(x, kind="stable")

    # Compute ranks
    ranks = np.empty(n, dtype=np.float64)
    i = 0
    while i < n:
        # Find all values equal to current value
        j = i
        while j < n - 1 and x[sorted_indices[j]] == x[sorted_indices[j + 1]]:
            j += 1

        # Average rank for this group
        avg_rank = (i + j + 2) / 2.0  # +2 because ranks are 1-indexed

        # Assign ranks
        for k in range(i, j + 1):
            ranks[sorted_indices[k]] = avg_rank

        i = j + 1

    return ranks


def _pearson_corr(x: np.ndarray, y: np.ndarray) -> float:
    """
    Compute Pearson correlation coefficient.

    Args:
        x, y: 1D arrays of same length

    Returns:
        correlation coefficient
    """
    n = x.shape[0]
    if n == 0 or n != y.shape[0]:
        raise ValueError("x and y must have same non-zero length")

    # Compute means
    mx = np.mean(x)
    my = np.mean(y)

    # Compute covariance and variances
    cov = np.sum((x - mx) * (y - my))
    var_x = np.sum((x - mx) ** 2)
    var_y = np.sum((y - my) ** 2)

    # Handle degenerate cases
    if var_x == 0.0 or var_y == 0.0:
        return 0.0

    return cov / np.sqrt(var_x * var_y)


def spearman_corr(x: np.ndarray, y: np.ndarray) -> float:
    """
    Compute Spearman rank correlation coefficient.

    Args:
        x, y: 1D arrays of same length

    Returns:
        Spearman correlation coefficient (rho)
    """
    rx = _rankdata(x)
    ry = _rankdata(y)
    return _pearson_corr(rx, ry)


def _generate_ohlc_for_corr(n: int, seed: int = 42) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Generate OHLC data with regime-switch + jumps for reliable breakout opportunities.
    
    Design:
    - Regime switches every ~250 bars: trending-up, trending-down, mean-reverting/chop
    - Gaussian noise with increased variance
    - Occasional jumps (p=0.01, Â±(2~4)*sigma shock)
    - Ensures high/low have clear intrabar range
    """
    rng = np.random.default_rng(seed)
    base_price = 100.0
    regime_period = 250
    
    # Generate regime sequence (0=trend-up, 1=trend-down, 2=chop)
    n_regimes = (n + regime_period - 1) // regime_period
    regime_seed = seed + 10000
    regime_rng = np.random.default_rng(regime_seed)
    regimes = regime_rng.integers(0, 3, size=n_regimes)
    
    # Generate close series
    close = np.empty(n, dtype=np.float64)
    close[0] = base_price
    
    sigma_base = 3.0  # Base noise sigma
    jump_prob = 0.01
    
    for t in range(1, n):
        regime_idx = t // regime_period
        regime = regimes[regime_idx] if regime_idx < len(regimes) else regimes[-1]
        
        # Trend component based on regime
        if regime == 0:  # Trending up
            trend_component = 0.05
        elif regime == 1:  # Trending down
            trend_component = -0.05
        else:  # Chop/mean-reverting
            trend_component = -0.01 * (close[t-1] - base_price) / 10.0
        
        # Gaussian noise
        noise = rng.standard_normal() * sigma_base
        
        # Occasional jump
        if rng.random() < jump_prob:
            jump_magnitude = rng.uniform(2.0, 4.0) * sigma_base
            jump_sign = 1.0 if rng.random() < 0.5 else -1.0
            noise += jump_sign * jump_magnitude
        
        close[t] = close[t-1] + trend_component + noise
    
    # Generate open (prev close with small gap)
    open_ = np.empty(n, dtype=np.float64)
    open_[0] = base_price
    for t in range(1, n):
        gap = rng.standard_normal() * 0.5
        open_[t] = close[t-1] + gap
    
    # Generate high/low with intrabar range
    high = np.empty(n, dtype=np.float64)
    low = np.empty(n, dtype=np.float64)
    base_range = 1.0
    
    for t in range(n):
        # Intrabar range based on noise magnitude
        noise_mag = abs(rng.standard_normal())
        intrabar_range = noise_mag * 2.0 + base_range
        
        # Ensure high >= max(open, close) and low <= min(open, close)
        max_oc = max(open_[t], close[t])
        min_oc = min(open_[t], close[t])
        
        high[t] = max_oc + intrabar_range * 0.5
        low[t] = min_oc - intrabar_range * 0.5
    
    return open_, high, low, close


@pytest.mark.slow
def test_stage0_proxy_spearman_correlation() -> None:
    """
    Test that Stage0 proxy scores have median Spearman Ï â‰¥ 0.4 with actual PnL.

    This test:
    1. Runs all seeds and computes rho for each non-degenerate seed
    2. Collects all rho values into a list
    3. Uses median rho as the contract (more stable than mean)
    4. Degenerate seeds are skipped but recorded for diagnostics
    5. If all seeds are degenerate, test fails with diagnostic info
    """
    # JIT requirement check: avoid degenerate samples in CI-safe / no-jit environments
    numba_disable_jit_env = os.environ.get("NUMBA_DISABLE_JIT", "").strip() == "1"
    numba_disable_jit_config = False
    if nb is not None:
        numba_disable_jit_config = getattr(nb.config, "DISABLE_JIT", 0) == 1

    if numba_disable_jit_env or numba_disable_jit_config:
        pytest.skip(
            "Spearman correlation test requires JIT-enabled Stage2; run without NUMBA_DISABLE_JIT=1\n"
            "Suggested command: PYTHONDONTWRITEBYTECODE=1 pytest -q -m slow -k spearman -vv"
        )

    SEEDS = [0, 1, 2, 3, 4, 5, 6, 7]
    MAX_TRIES = len(SEEDS)
    MIN_VALID = 4  # Hard gate: require at least 4 valid seeds
    n_bars = 1500
    n_params = 250

    # Track evidence for all seeds (including degenerate)
    seeds_tried = []
    pnl_unique_counts = []
    pnl_mins = []
    pnl_maxs = []
    trades_totals = []
    trades_unique_counts = []
    intent_modes = []
    intents_totals = []
    fills_totals = []
    # Collect rho values for non-degenerate seeds
    rho_values = []
    degenerate_seeds = []
    valid_seeds = []

    for seed in SEEDS:
        seeds_tried.append(seed)

        # Generate OHLC data with current seed
        open_, high, low, close = _generate_ohlc_for_corr(n_bars, seed=seed)

        # Generate random params with deterministic seed (seed + 1000 to avoid collision)
        rng = np.random.default_rng(seed + 1000)

        # Params for kernel: [channel_len, atr_len, stop_mult]
        params_kernel = np.empty((n_params, 3), dtype=np.float64)
        params_kernel[:, 0] = rng.integers(5, 40, size=n_params)  # channel_len (reduced range)
        params_kernel[:, 1] = rng.integers(5, 50, size=n_params)  # atr_len
        params_kernel[:, 2] = rng.uniform(0.2, 1.5, size=n_params)  # stop_mult (reduced range)

        # Params for proxies (aligned with Stage2 kernel params)
        # Trend: [fast, slow] where fast = max(2, floor(channel_len/3)), slow = channel_len
        params_trend = np.empty((n_params, 2), dtype=np.float64)
        params_trend[:, 0] = np.maximum(2, params_kernel[:, 0] // 3)  # fast
        params_trend[:, 1] = params_kernel[:, 0]  # slow = channel_len
        # Activity: [channel_len, atr_len] (atr_len kept for compatibility but not used)
        params_activity = params_kernel[:, :2].copy()
        # Vol: [atr_len, stop_mult]
        params_vol = params_kernel[:, 1:3].copy()

        # Compute proxy scores
        trend_scores = trend_proxy(open_, high, low, close, params_trend)
        vol_scores = vol_proxy(open_, high, low, close, params_vol)
        activity_scores = activity_proxy(open_, high, low, close, params_activity)

        # Filter out -inf scores (invalid params)
        valid_mask = np.isfinite(trend_scores) & np.isfinite(vol_scores) & np.isfinite(activity_scores)

        # Combined proxy score (weights: w1=1.0, w2=0.5, w3=1.0)
        # Adjusted weights: emphasize activity (often strongest for breakout strategies)
        proxy_scores = 1.0 * trend_scores + 0.5 * vol_scores + 1.0 * activity_scores

        # Run minimal backtest to get PnL
        from FishBroWFS_V2.pipeline.runner_grid import run_grid

        result = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_kernel,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=False,
            force_close_last=True,
        )

        metrics = result["metrics"]
        pnl = metrics[:, METRICS_COL_NET_PROFIT]  # net_profit column
        trades = metrics[:, METRICS_COL_TRADES]  # trades column

        # Extract perf diagnostic info
        perf = result.get("perf", {})
        intent_mode = perf.get("intent_mode")
        intents_total = perf.get("intents_total")
        fills_total = perf.get("fills_total")

        # Strict diagnostics when trades_sum == 0 (fills exist but trades/pnl = 0)
        trades_sum = float(np.sum(trades))
        if trades_sum == 0.0:
            # Dump metrics diagnostics
            diag_parts = [f"\n[DIAG] seed={seed}: trades_sum=0 but fills_total={fills_total}"]
            diag_parts.append(f"metrics.shape={metrics.shape}")
            diag_parts.append(f"metrics_column_names={METRICS_COLUMN_NAMES}")
            diag_parts.append(f"result.keys()={list(result.keys())}")
            if "metrics_columns" in result:
                diag_parts.append(f"result['metrics_columns']={result.get('metrics_columns')}")

            # First row of metrics
            if metrics.shape[0] > 0:
                n_cols_to_show = min(10, metrics.shape[1])
                diag_parts.append(f"metrics[0, :{n_cols_to_show}]={metrics[0, :n_cols_to_show].tolist()}")

            # Min/max of first few columns (with column names)
            n_cols_to_check = min(5, metrics.shape[1])
            for col_idx in range(n_cols_to_check):
                col_data = metrics[:, col_idx]
                col_name = METRICS_COLUMN_NAMES[col_idx] if col_idx < len(METRICS_COLUMN_NAMES) else f"col{col_idx}"
                diag_parts.append(
                    f"metrics[:, {col_idx}] ({col_name}): min={np.min(col_data):.6f}, max={np.max(col_data):.6f}"
                )

            # Inspect fills payload
            if "fills" in result:
                fills_list = result["fills"]
                if isinstance(fills_list, list):
                    diag_parts.append(f"fills (list): len={len(fills_list)}")
                    if len(fills_list) > 0:
                        diag_parts.append(f"fills[0]={repr(fills_list[0])} (type={type(fills_list[0])})")
                    if len(fills_list) > 1:
                        diag_parts.append(f"fills[1]={repr(fills_list[1])}")
                    if len(fills_list) > 2:
                        diag_parts.append(f"fills[2]={repr(fills_list[2])}")
            elif "fills_arr" in result:
                fills_arr = result["fills_arr"]
                diag_parts.append(f"fills_arr: shape={fills_arr.shape}, dtype={fills_arr.dtype}")
                if fills_arr.shape[0] > 0:
                    n_rows = min(5, fills_arr.shape[0])
                    diag_parts.append(f"fills_arr[:{n_rows}]=\n{fills_arr[:n_rows]}")
            elif "fills_array" in result:
                fills_array = result["fills_array"]
                diag_parts.append(f"fills_array: shape={fills_array.shape}, dtype={fills_array.dtype}")
                if fills_array.shape[0] > 0:
                    n_rows = min(5, fills_array.shape[0])
                    diag_parts.append(f"fills_array[:{n_rows}]=\n{fills_array[:n_rows]}")
            else:
                diag_parts.append("No 'fills', 'fills_arr', or 'fills_array' in result (perf only)")

            # Print diagnostics to stderr for visibility
            import sys

            print("\n".join(diag_parts), file=sys.stderr)

        # Check for degenerate cases
        pnl_unique = np.unique(pnl)
        pnl_unique_count = pnl_unique.size
        pnl_std = np.std(pnl)
        proxy_std = np.std(proxy_scores)

        # Record evidence (including perf diagnostics)
        pnl_unique_counts.append(pnl_unique_count)
        pnl_mins.append(float(np.min(pnl)))
        pnl_maxs.append(float(np.max(pnl)))
        trades_totals.append(float(np.sum(trades)))
        trades_unique_counts.append(np.unique(trades).size)
        intent_modes.append(intent_mode)
        intents_totals.append(intents_total)
        fills_totals.append(fills_total)

        # Check if this sample is degenerate and compute rho if non-degenerate
        is_degenerate = False
        if proxy_std == 0.0:
            is_degenerate = True
        elif pnl_unique_count < 2 or pnl_std == 0.0:
            is_degenerate = True
        else:
            # Filter out invalid proxy scores (-inf)
            # Combine proxy valid_mask with pnl finite check
            valid_mask_combined = valid_mask & np.isfinite(pnl)
            if np.sum(valid_mask_combined) < 10:
                is_degenerate = True
            else:
                proxy_valid = proxy_scores[valid_mask_combined]
                pnl_valid = pnl[valid_mask_combined]

                # Check again after filtering
                if np.std(pnl_valid) == 0.0 or np.unique(pnl_valid).size < 2:
                    is_degenerate = True
                else:
                    # Non-degenerate sample - compute Spearman correlation
                    rho = spearman_corr(proxy_valid, pnl_valid)
                    rho_values.append(rho)
                    valid_seeds.append(seed)
                    # Continue to next seed (collect all rho values)

        if is_degenerate:
            degenerate_seeds.append(seed)
            # Continue to next seed (skip degenerate, but diagnostics already recorded)

    # Check minimum valid seeds requirement
    if len(rho_values) < MIN_VALID:
        # Build detailed diagnostic message with per-seed info
        diag_lines = [
            f"Insufficient valid seeds: {len(rho_values)}/{MAX_TRIES} < MIN_VALID={MIN_VALID}",
            f"Valid seeds: {valid_seeds}",
            f"Degenerate seeds: {degenerate_seeds}",
            "",
            "Per-seed summary:",
        ]
        for i, seed in enumerate(seeds_tried):
            is_valid = seed in valid_seeds
            diag_lines.append(
                f"seed={seed} ({'VALID' if is_valid else 'DEGENERATE'}): "
                f"intent_mode={intent_modes[i]}, "
                f"intents_total={intents_totals[i]}, "
                f"fills_total={fills_totals[i]}, "
                f"trades_sum={trades_totals[i]}, "
                f"pnl_unique={pnl_unique_counts[i]}, "
                f"pnl_range=[{pnl_mins[i]:.4f}, {pnl_maxs[i]:.4f}], "
                f"trades_unique={trades_unique_counts[i]}"
            )
        if len(rho_values) > 0:
            diag_lines.append(f"rho_values (partial): {rho_values}")
        pytest.fail("\n".join(diag_lines))

    # Compute median and mean rho
    median_rho = float(np.median(rho_values))
    mean_rho = float(np.mean(rho_values))

    # Assert correlation contract using median (more stable than mean)
    # Only assert if we have enough valid seeds (already checked above)
    assert median_rho >= 0.4, (
        f"Median Spearman correlation {median_rho:.4f} < 0.4 threshold. "
        f"Mean rho={mean_rho:.4f}, "
        f"rho_values={rho_values}, "
        f"valid_seeds={valid_seeds} ({len(rho_values)}/{MAX_TRIES}), "
        f"degenerate_seeds={degenerate_seeds}"
    )


def test_spearman_corr_basic() -> None:
    """Basic test for Spearman correlation function."""
    # Perfect positive correlation
    x = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
    y = np.array([2.0, 4.0, 6.0, 8.0, 10.0])
    rho = spearman_corr(x, y)
    assert abs(rho - 1.0) < 1e-10

    # Perfect negative correlation
    y_neg = np.array([10.0, 8.0, 6.0, 4.0, 2.0])
    rho_neg = spearman_corr(x, y_neg)
    assert abs(rho_neg - (-1.0)) < 1e-10

    # No correlation (random)
    rng = np.random.default_rng(42)
    y_rand = rng.standard_normal(100)
    x_rand = rng.standard_normal(100)
    rho_rand = spearman_corr(x_rand, y_rand)
    assert abs(rho_rand) < 0.5  # Should be close to 0 for independent data


def test_spearman_corr_with_ties() -> None:
    """Test Spearman correlation with tied values."""
    # Test with ties
    x = np.array([1.0, 2.0, 2.0, 3.0, 4.0])
    y = np.array([2.0, 3.0, 4.0, 5.0, 6.0])
    rho = spearman_corr(x, y)
    # Should still be positive
    assert rho > 0.0

    # All same values (degenerate)
    x_same = np.array([1.0, 1.0, 1.0])
    y_same = np.array([2.0, 2.0, 2.0])
    rho_same = spearman_corr(x_same, y_same)
    # Should handle gracefully (0 or NaN)
    assert np.isfinite(rho_same) or np.isnan(rho_same)


================================================================================
FILE: tests/test_stage2_params_influence.py
================================================================================

from __future__ import annotations

import numpy as np
import pytest

from FishBroWFS_V2.pipeline.runner_grid import run_grid
from tests.test_stage0_proxy_rank_corr import _generate_ohlc_for_corr


def test_stage2_params_influence_extremes() -> None:
    """
    Contract test: params must influence outcome.
    
    Root cause fuse: if different params produce identical metrics,
    Stage2 is broken and Spearman correlation will be meaningless.
    """
    # Generate OHLC data using same generator as Spearman test
    n_bars = 1500
    seed = 0
    open_, high, low, close = _generate_ohlc_for_corr(n_bars, seed=seed)
    
    # Two extreme params that should produce different outcomes
    params = np.array([
        [5.0, 5.0, 0.2],   # A: short channel, short ATR, tight stop
        [39.0, 49.0, 1.5], # B: long channel, long ATR, wide stop
    ], dtype=np.float64)
    
    # Run grid with debug enabled
    result = run_grid(
        open_=open_,
        high=high,
        low=low,
        close=close,
        params_matrix=params,
        commission=0.0,
        slip=0.0,
        order_qty=1,
        sort_params=False,
        force_close_last=True,
        return_debug=True,
    )
    
    metrics = result["metrics"]
    debug_fills_first = result.get("debug_fills_first")
    
    # Extract metrics for both params
    net_profit_a = float(metrics[0, 0])  # net_profit
    net_profit_b = float(metrics[1, 0])
    trades_a = int(metrics[0, 1])  # trades
    trades_b = int(metrics[1, 1])
    
    # Extract debug info
    if debug_fills_first is not None:
        entry_bar_a_raw = debug_fills_first[0, 0]
        entry_price_a_raw = debug_fills_first[0, 1]
        exit_bar_a_raw = debug_fills_first[0, 2]
        exit_price_a_raw = debug_fills_first[0, 3]
        
        entry_bar_b_raw = debug_fills_first[1, 0]
        entry_price_b_raw = debug_fills_first[1, 1]
        exit_bar_b_raw = debug_fills_first[1, 2]
        exit_price_b_raw = debug_fills_first[1, 3]
        
        # Handle NaN values
        entry_bar_a = int(entry_bar_a_raw) if np.isfinite(entry_bar_a_raw) else -1
        entry_price_a = float(entry_price_a_raw) if np.isfinite(entry_price_a_raw) else np.nan
        exit_bar_a = int(exit_bar_a_raw) if np.isfinite(exit_bar_a_raw) else -1
        exit_price_a = float(exit_price_a_raw) if np.isfinite(exit_price_a_raw) else np.nan
        
        entry_bar_b = int(entry_bar_b_raw) if np.isfinite(entry_bar_b_raw) else -1
        entry_price_b = float(entry_price_b_raw) if np.isfinite(entry_price_b_raw) else np.nan
        exit_bar_b = int(exit_bar_b_raw) if np.isfinite(exit_bar_b_raw) else -1
        exit_price_b = float(exit_price_b_raw) if np.isfinite(exit_price_b_raw) else np.nan
        
        debug_msg = (
            f"Param A [5, 5, 0.2]: entry_bar={entry_bar_a}, entry_price={entry_price_a:.4f}, "
            f"exit_bar={exit_bar_a}, exit_price={exit_price_a:.4f}, "
            f"net_profit={net_profit_a:.4f}, trades={trades_a}\n"
            f"Param B [39, 49, 1.5]: entry_bar={entry_bar_b}, entry_price={entry_price_b:.4f}, "
            f"exit_bar={exit_bar_b}, exit_price={exit_price_b:.4f}, "
            f"net_profit={net_profit_b:.4f}, trades={trades_b}"
        )
    else:
        debug_msg = (
            f"Param A [5, 5, 0.2]: net_profit={net_profit_a:.4f}, trades={trades_a}\n"
            f"Param B [39, 49, 1.5]: net_profit={net_profit_b:.4f}, trades={trades_b}"
        )
        # Fallback: use metrics only
        entry_bar_a = entry_bar_b = -1
        entry_price_a = entry_price_b = np.nan
        exit_bar_a = exit_bar_b = -1
        exit_price_a = exit_price_b = np.nan
    
    # Assert at least one difference exists
    # This is the "root cause fuse" - if all identical, Stage2 is broken
    entry_price_diff = abs(entry_price_a - entry_price_b) if (np.isfinite(entry_price_a) and np.isfinite(entry_price_b)) else 0.0
    exit_price_diff = abs(exit_price_a - exit_price_b) if (np.isfinite(exit_price_a) and np.isfinite(exit_price_b)) else 0.0
    
    assert (
        entry_bar_a != entry_bar_b or
        entry_price_diff > 1e-6 or
        exit_bar_a != exit_bar_b or
        exit_price_diff > 1e-6 or
        abs(net_profit_a - net_profit_b) > 1e-6
    ), (
        f"Params A and B produced identical outcomes - Stage2 is broken!\n"
        f"{debug_msg}\n"
        f"This indicates params are not being used correctly in signal/stop calculation."
    )


================================================================================
FILE: tests/test_trigger_rate_param_subsample_contract.py
================================================================================

"""
Stage P2-3: Contract Tests for Param-subsample Trigger Rate

Verifies that trigger_rate controls param subsampling:
- selected_params_count scales with trigger_rate
- intents_total scales approximately linearly with trigger_rate
- Workload reduction is effective
"""
from __future__ import annotations

import numpy as np
import os

from FishBroWFS_V2.pipeline.runner_grid import run_grid


def test_selected_params_count_reasonable() -> None:
    """
    Test that selected_params_count is reasonable for given trigger_rate.
    
    With n_params=1000 and trigger_rate=0.05, we expect selected_params_count
    to be approximately 50 (allowing rounding error).
    """
    # Ensure clean environment
    old_param_subsample_rate = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
    old_param_subsample_seed = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
    
    try:
        n_bars = 500
        n_params = 1000
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 10)
            atr_len = 10 + (i % 5)
            stop_mult = 1.0 + (i % 3) * 0.5
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Set param_subsample_rate=0.05
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = "0.05"
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = "42"
        
        result = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify perf dict contains trigger rate info
        assert "perf" in result, "perf must exist in run_grid result"
        perf = result["perf"]
        assert isinstance(perf, dict), "perf must be a dict"
        
        selected_params_count = perf.get("selected_params_count")
        param_subsample_rate_configured = perf.get("param_subsample_rate_configured")
        selected_params_ratio = perf.get("selected_params_ratio")
        
        assert selected_params_count is not None, "selected_params_count must exist"
        assert param_subsample_rate_configured is not None, "param_subsample_rate_configured must exist"
        assert selected_params_ratio is not None, "selected_params_ratio must exist"
        
        assert param_subsample_rate_configured == 0.05, f"param_subsample_rate_configured should be 0.05, got {param_subsample_rate_configured}"
        
        # Contract: selected_params_count should be approximately 5% of n_params
        # Allow rounding error: [45, 55] for n_params=1000, rate=0.05
        assert 45 <= selected_params_count <= 55, (
            f"selected_params_count ({selected_params_count}) should be approximately 50 "
            f"(5% of {n_params}), got {selected_params_count}"
        )
        
        # Contract: selected_params_ratio should match trigger_rate approximately
        expected_ratio = 0.05
        assert 0.04 <= selected_params_ratio <= 0.06, (
            f"selected_params_ratio ({selected_params_ratio}) should be approximately "
            f"{expected_ratio}, got {selected_params_ratio}"
        )
        
        # Contract: metrics_rows_computed should equal selected_params_count
        metrics_rows_computed = perf.get("metrics_rows_computed")
        assert metrics_rows_computed == selected_params_count, (
            f"metrics_rows_computed ({metrics_rows_computed}) should equal "
            f"selected_params_count ({selected_params_count})"
        )
        
    finally:
        # Restore environment
        if old_param_subsample_rate is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = old_param_subsample_rate
        
        if old_param_subsample_seed is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = old_param_subsample_seed


def test_intents_total_linear_scaling() -> None:
    """
    Test that intents_total scales approximately linearly with trigger_rate.
    
    This verifies workload reduction: when we run 5% of params, intents_total
    should be approximately 5% of baseline.
    """
    # Ensure clean environment
    old_param_subsample_rate = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
    old_param_subsample_seed = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
    
    try:
        n_bars = 500
        n_params = 200
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 10)
            atr_len = 10 + (i % 5)
            stop_mult = 1.0 + (i % 3) * 0.5
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Run A: param_subsample_rate=1.0 (baseline, all params)
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = "1.0"
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = "42"
        
        result_a = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Run B: param_subsample_rate=0.05 (5% of params)
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = "0.05"
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = "42"  # Same seed for deterministic selection
        
        result_b = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify perf dicts
        perf_a = result_a.get("perf", {})
        perf_b = result_b.get("perf", {})
        
        assert isinstance(perf_a, dict), "perf_a must be a dict"
        assert isinstance(perf_b, dict), "perf_b must be a dict"
        
        intents_total_a = perf_a.get("intents_total")
        intents_total_b = perf_b.get("intents_total")
        
        assert intents_total_a is not None, "intents_total_a must exist"
        assert intents_total_b is not None, "intents_total_b must exist"
        
        # Contract: intents_total_B should be <= intents_total_A * 0.07 (allowing overhead)
        # With 5% params, we expect approximately 5% workload, but allow up to 7% for overhead
        if intents_total_a > 0:
            ratio = intents_total_b / intents_total_a
            assert ratio <= 0.07, (
                f"intents_total_B ({intents_total_b}) should be <= intents_total_A * 0.07 "
                f"({intents_total_a * 0.07}), got ratio {ratio:.4f}"
            )
        
        # Verify selected_params_count scaling
        selected_count_a = perf_a.get("selected_params_count", n_params)
        selected_count_b = perf_b.get("selected_params_count")
        
        assert selected_count_b is not None, "selected_params_count_B must exist"
        assert selected_count_b < selected_count_a, (
            f"selected_params_count_B ({selected_count_b}) should be < "
            f"selected_params_count_A ({selected_count_a})"
        )
        
    finally:
        # Restore environment
        if old_param_subsample_rate is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = old_param_subsample_rate
        
        if old_param_subsample_seed is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = old_param_subsample_seed


def test_metrics_shape_preserved() -> None:
    """
    Test that metrics shape is preserved (n_params, METRICS_N_COLUMNS) even with subsampling.
    
    Only selected rows should be computed; unselected rows remain zeros.
    Uses metrics_computed_mask to verify which rows were computed.
    """
    # Ensure clean environment
    old_trigger_rate = os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
    old_param_subsample_rate = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
    old_param_subsample_seed = os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
    
    try:
        n_bars = 300
        n_params = 100
        
        # Generate simple OHLC data
        rng = np.random.default_rng(42)
        close = 100.0 + np.cumsum(rng.standard_normal(n_bars))
        high = close + np.abs(rng.standard_normal(n_bars)) * 2.0
        low = close - np.abs(rng.standard_normal(n_bars)) * 2.0
        open_ = (high + low) / 2
        
        high = np.maximum(high, np.maximum(open_, close))
        low = np.minimum(low, np.minimum(open_, close))
        
        # Generate params matrix
        params_list = []
        for i in range(n_params):
            ch_len = 20 + (i % 10)
            atr_len = 10 + (i % 5)
            stop_mult = 1.0
            params_list.append([ch_len, atr_len, stop_mult])
        
        params_matrix = np.array(params_list, dtype=np.float64)
        
        # Fix trigger_rate=1.0 (no intent-level sparsity) to test param subsample only
        os.environ["FISHBRO_PERF_TRIGGER_RATE"] = "1.0"
        # Set param_subsample_rate=0.1 (10% of params)
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = "0.1"
        os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = "42"
        
        result = run_grid(
            open_=open_,
            high=high,
            low=low,
            close=close,
            params_matrix=params_matrix,
            commission=0.0,
            slip=0.0,
            order_qty=1,
            sort_params=True,
        )
        
        # Verify metrics shape is preserved
        metrics = result.get("metrics")
        assert metrics is not None, "metrics must exist"
        assert isinstance(metrics, np.ndarray), "metrics must be np.ndarray"
        assert metrics.shape == (n_params, 3), (
            f"metrics shape should be ({n_params}, 3), got {metrics.shape}"
        )
        
        # Verify perf dict
        perf = result.get("perf", {})
        metrics_rows_computed = perf.get("metrics_rows_computed")
        selected_params_count = perf.get("selected_params_count")
        metrics_computed_mask = perf.get("metrics_computed_mask")
        
        assert metrics_rows_computed == selected_params_count, (
            f"metrics_rows_computed ({metrics_rows_computed}) should equal "
            f"selected_params_count ({selected_params_count})"
        )
        
        # Verify metrics_computed_mask exists and has correct shape
        assert metrics_computed_mask is not None, "metrics_computed_mask must exist in perf"
        assert isinstance(metrics_computed_mask, list), "metrics_computed_mask must be a list"
        assert len(metrics_computed_mask) == n_params, (
            f"metrics_computed_mask length ({len(metrics_computed_mask)}) should equal n_params ({n_params})"
        )
        
        # Convert to numpy array for easier manipulation
        mask_array = np.array(metrics_computed_mask, dtype=bool)
        
        # Verify that mask sum equals selected_params_count
        assert np.sum(mask_array) == selected_params_count, (
            f"metrics_computed_mask sum ({np.sum(mask_array)}) should equal "
            f"selected_params_count ({selected_params_count})"
        )
        
        # Verify that only rows marked True in mask have non-zero metrics (approximately)
        # Count non-zero rows for computed params
        computed_non_zero = np.sum(np.any(np.abs(metrics[mask_array]) > 1e-10, axis=1))
        # Count non-zero rows for uncomputed params (should be 0 or very few due to initialization)
        uncomputed_non_zero = np.sum(np.any(np.abs(metrics[~mask_array]) > 1e-10, axis=1))
        
        # All computed rows should have non-zero metrics (allowing small tolerance for edge cases)
        assert computed_non_zero >= selected_params_count - 2, (
            f"Computed rows with non-zero metrics ({computed_non_zero}) should be >= "
            f"selected_params_count - 2 ({selected_params_count - 2})"
        )
        
        # Uncomputed rows should remain zeros (allowing small tolerance for floating point)
        assert uncomputed_non_zero <= 2, (
            f"Uncomputed rows with non-zero metrics ({uncomputed_non_zero}) should be <= 2 "
            f"(allowing floating point tolerance)"
        )
        
    finally:
        # Restore environment
        if old_trigger_rate is None:
            os.environ.pop("FISHBRO_PERF_TRIGGER_RATE", None)
        else:
            os.environ["FISHBRO_PERF_TRIGGER_RATE"] = old_trigger_rate
        
        if old_param_subsample_rate is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_RATE", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_RATE"] = old_param_subsample_rate
        
        if old_param_subsample_seed is None:
            os.environ.pop("FISHBRO_PERF_PARAM_SUBSAMPLE_SEED", None)
        else:
            os.environ["FISHBRO_PERF_PARAM_SUBSAMPLE_SEED"] = old_param_subsample_seed


================================================================================
FILE: tests/test_vectorization_parity.py
================================================================================

from __future__ import annotations

import numpy as np

from FishBroWFS_V2.data.layout import normalize_bars
from FishBroWFS_V2.engine.engine_jit import simulate_arrays
from FishBroWFS_V2.engine.types import Fill, OrderKind, OrderRole, Side
from FishBroWFS_V2.strategy.kernel import DonchianAtrParams, run_kernel_arrays, run_kernel_object_mode


def _assert_fills_equal(a: list[Fill], b: list[Fill]) -> None:
    assert len(a) == len(b)
    for fa, fb in zip(a, b):
        assert fa.bar_index == fb.bar_index
        assert fa.role == fb.role
        assert fa.kind == fb.kind
        assert fa.side == fb.side
        assert fa.qty == fb.qty
        assert fa.order_id == fb.order_id
        assert abs(fa.price - fb.price) <= 1e-9


def test_strategy_object_vs_array_mode_parity() -> None:
    rng = np.random.default_rng(42)
    n = 300
    close = 100.0 + np.cumsum(rng.standard_normal(n)).astype(np.float64)
    high = close + 1.0
    low = close - 1.0
    open_ = (high + low) * 0.5

    bars = normalize_bars(open_, high, low, close)
    params = DonchianAtrParams(channel_len=20, atr_len=14, stop_mult=2.0)

    out_obj = run_kernel_object_mode(bars, params, commission=0.0, slip=0.0, order_qty=1)
    out_arr = run_kernel_arrays(bars, params, commission=0.0, slip=0.0, order_qty=1)

    _assert_fills_equal(out_obj["fills"], out_arr["fills"])  # type: ignore[arg-type]


def test_simulate_arrays_same_bar_entry_exit_parity() -> None:
    # Construct a same-bar entry then exit scenario (created_bar=-1 activates on bar0).
    bars = normalize_bars(
        np.array([100.0], dtype=np.float64),
        np.array([120.0], dtype=np.float64),
        np.array([80.0], dtype=np.float64),
        np.array([110.0], dtype=np.float64),
    )

    # ENTRY BUY STOP 105, EXIT SELL STOP 95, both active on bar0.
    order_id = np.array([1, 2], dtype=np.int64)
    created_bar = np.array([-1, -1], dtype=np.int64)
    role = np.array([1, 0], dtype=np.int8)  # ENTRY then EXIT (order_id tie-break handles)
    kind = np.array([0, 0], dtype=np.int8)  # STOP
    side = np.array([1, -1], dtype=np.int8)  # BUY, SELL
    price = np.array([105.0, 95.0], dtype=np.float64)
    qty = np.array([1, 1], dtype=np.int64)

    fills = simulate_arrays(
        bars,
        order_id=order_id,
        created_bar=created_bar,
        role=role,
        kind=kind,
        side=side,
        price=price,
        qty=qty,
        ttl_bars=1,
    )

    assert len(fills) == 2
    assert fills[0].role == OrderRole.ENTRY and fills[0].side == Side.BUY and fills[0].kind == OrderKind.STOP
    assert fills[1].role == OrderRole.EXIT and fills[1].side == Side.SELL and fills[1].kind == OrderKind.STOP



