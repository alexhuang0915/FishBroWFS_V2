import os
import sys
import json
from pathlib import Path

# ================= é…ç½®å€ (Config) =================

# 1. è¼¸å‡ºæª”å
OUTPUT_FILE = "SNAPSHOT_CLEAN.jsonl"

# 2. ç¸½å®¹é‡é™åˆ¶ (Bytes) - è¨­å®š 9.5MB (ç•™ä¸€é»ç·©è¡çµ¦ Header)
MAX_TOTAL_SIZE = 9.5 * 1024 * 1024 

# 3. å–®æª”å®¹é‡é™åˆ¶ (Bytes) - å–®å€‹æª”æ¡ˆè¶…é 100KB å°±æˆªæ–· (é¿å…èª¤æ”¶å·¨å¤§æ•¸æ“š)
MAX_FILE_SIZE = 100 * 1024

# 4. [é»‘åå–®] çµ•å°ä¸æƒæçš„è³‡æ–™å¤¾ (åç¨±å®Œå…¨ç¬¦åˆå³è·³é)
# é€™è£¡æŠŠ LOCAL, FishBroData, outputs éƒ½å°æ®ºäº†
EXCLUDE_DIRS = {
    ".git", ".hg", ".svn", ".idea", ".vscode",
    ".venv", "venv", "env", "__pycache__",
    "outputs", "output", "dist", "build", "target",
    "FishBroData", "data", "Data", "db",
    "LOCAL", "local", "Local",  # <--- é€™è£¡æ“‹ä½ä½ çš„ LOCAL
    "SNAPSHOT", "temp", "tmp", "logs"
}

# 5. [ç™½åå–®] åªå…è¨±é€™äº›å‰¯æª”å (é˜²å µ .csv, .parquet æˆ–ç„¡å‰¯æª”åäº‚å…¥)
ALLOW_EXTENSIONS = {
    ".py", ".pyi",
    ".md", ".markdown",
    ".json", ".jsonl", ".toml", ".yaml", ".yml", ".ini",
    ".txt",  # å¦‚æœä½ æœ‰é‡è¦ txt èªªæ˜æª”ï¼Œè«‹ä¿ç•™ï¼›è‹¥ txt éƒ½æ˜¯æ•¸æ“šï¼Œè«‹æ‹¿æ‰é€™è¡Œ
    ".sh", ".bat",
    ".css", ".html", ".js", # å¦‚æœæœ‰ UI ç›¸é—œ
    ".sql"
}

# 6. [ç™½åå–®] å…è¨±çš„ç‰¹å®šç„¡å‰¯æª”åæª”æ¡ˆ
ALLOW_FILENAMES = {
    "Makefile", "Dockerfile", "README", "LICENSE", ".gitignore", ".dockerignore", "requirements.txt"
}

# ================= ä¸»ç¨‹å¼ =================

def is_text_file(file_path):
    """ç°¡å–®æª¢æŸ¥æ˜¯å¦ç‚ºæ–‡å­—æª” (å˜—è©¦è®€å–å‰ 1KB)"""
    try:
        with open(file_path, 'rb') as f:
            chunk = f.read(1024)
            if b'\0' in chunk:  # æœ‰ NULL byte é€šå¸¸æ˜¯äºŒé€²ä½
                return False
            # å˜—è©¦è§£ç¢¼
            chunk.decode('utf-8')
        return True
    except Exception:
        return False

def generate_snapshot(root_dir):
    root_path = Path(root_dir).resolve()
    output_path = root_path / OUTPUT_FILE
    
    current_size = 0
    file_count = 0
    skipped_count = 0
    
    print(f"ğŸš€ é–‹å§‹æƒæ (Root: {root_path})")
    print(f"ğŸš« æ’é™¤ç›®éŒ„: {EXCLUDE_DIRS}")
    print(f"âœ… å…è¨±æ ¼å¼: {ALLOW_EXTENSIONS} + {ALLOW_FILENAMES}")

    with open(output_path, 'w', encoding='utf-8') as out_f:
        # å¯«å…¥ä¸€å€‹ Meta Header
        meta = {
            "type": "META",
            "project": root_path.name,
            "root": str(root_path),
            "generated_by": "snapshot_clean.py"
        }
        out_f.write(json.dumps(meta, ensure_ascii=False) + "\n")

        # ä½¿ç”¨ os.walk éæ­· (ä¸ä¾è³´ Git)
        for dirpath, dirnames, filenames in os.walk(root_path):
            # 1. éæ¿¾ç›®éŒ„ (åŸåœ°ä¿®æ”¹ dirnames ä»¥é˜»æ­¢ os.walk é€²å…¥)
            # ä½¿ç”¨ set intersection å¿«é€Ÿéæ¿¾
            dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS and not d.startswith('.')]
            
            # å°‡è·¯å¾‘è½‰ç‚º Path ç‰©ä»¶
            current_dir = Path(dirpath)
            
            # ç¢ºä¿ä¸æœƒæƒåˆ°è¼¸å‡ºæª”è‡ªå·±æ‰€åœ¨ç›®éŒ„ (å¦‚æœå®ƒåœ¨æ ¹ç›®éŒ„å…¶å¯¦æ²’å·®ï¼Œå› ç‚º filenames æœƒéæ¿¾)
            if "SNAPSHOT" in current_dir.parts:
                continue

            for filename in filenames:
                file_path = current_dir / filename
                
                # è·³éè¼¸å‡ºæª”è‡ªå·±
                if filename == OUTPUT_FILE:
                    continue

                # 2. æª¢æŸ¥æª”åè¦å‰‡
                ext = file_path.suffix.lower()
                is_allowed = (ext in ALLOW_EXTENSIONS) or (filename in ALLOW_FILENAMES)
                
                if not is_allowed:
                    # å†æ¬¡æª¢æŸ¥ï¼Œå¦‚æœæ˜¯ .txt ä½†ä¸åœ¨ data è³‡æ–™å¤¾ä¸‹ï¼Œæˆ–è¨±å¯ä»¥æ”¾è¡Œï¼Ÿ
                    # ç‚ºäº†å®‰å…¨ï¼Œé€™è£¡åš´æ ¼åŸ·è¡Œï¼šä¸åœ¨ç™½åå–®å°±æ®ºã€‚
                    continue

                # 3. æª¢æŸ¥å¤§å°é åˆ¤
                try:
                    stat = file_path.stat()
                    if stat.st_size > MAX_FILE_SIZE:
                        print(f"âš ï¸ è·³ééå¤§æª”æ¡ˆ ({stat.st_size/1024:.1f}KB): {file_path.relative_to(root_path)}")
                        skipped_count += 1
                        continue
                except Exception:
                    continue

                # 4. è®€å–å…§å®¹
                try:
                    if not is_text_file(file_path):
                        continue

                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # å»ºç«‹ JSON ç‰©ä»¶
                    record = {
                        "path": str(file_path.relative_to(root_path)).replace("\\", "/"),
                        "content": content
                    }
                    
                    json_line = json.dumps(record, ensure_ascii=False)
                    line_bytes = len(json_line.encode('utf-8'))

                    # 5. æª¢æŸ¥ç¸½å®¹é‡
                    if current_size + line_bytes > MAX_TOTAL_SIZE:
                        print(f"ğŸ›‘ å®¹é‡å·²é”ä¸Šé™ ({current_size/1024/1024:.2f}MB)ï¼Œåœæ­¢æƒæã€‚")
                        break
                    
                    out_f.write(json_line + "\n")
                    current_size += line_bytes
                    file_count += 1

                except Exception as e:
                    print(f"âŒ è®€å–éŒ¯èª¤ {filename}: {e}")
            
            if current_size > MAX_TOTAL_SIZE:
                break

    print("=" * 40)
    print(f"âœ¨ å¿«ç…§å®Œæˆï¼")
    print(f"ğŸ“‚ è¼¸å‡ºæª”æ¡ˆ: {OUTPUT_FILE}")
    print(f"ğŸ“„ æª”æ¡ˆæ•¸é‡: {file_count}")
    print(f"ğŸ“¦ ç¸½å¤§å°: {current_size / 1024 / 1024:.2f} MB")
    print("=" * 40)

if __name__ == "__main__":
    generate_snapshot(".")