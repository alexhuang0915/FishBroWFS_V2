"""Test UI race condition defense for Attack #9 â€“ Headless Intent-State Contract.

Tests that UI cannot cause race conditions because:
1. UI only creates intents (no business logic)
2. All intents go through single ActionQueue
3. StateProcessor is single consumer (sequential execution)
4. UI only reads SystemState snapshots (immutable)
"""

import pytest
import asyncio
import threading
import contextlib
from datetime import date
import anyio
from anyio import create_task_group, sleep

from FishBroWFS_V2.core.intents import (
    CreateJobIntent, CalculateUnitsIntent, DataSpecIntent,
    IntentStatus
)
from FishBroWFS_V2.control.action_queue import ActionQueue, reset_action_queue
from FishBroWFS_V2.core.processor import StateProcessor, reset_processor
from FishBroWFS_V2.gui.adapters.intent_bridge import IntentBridge, get_intent_bridge


@pytest.fixture
def clean_system():
    """Clean system state before each test."""
    reset_action_queue()
    reset_processor()
    yield
    reset_action_queue()
    reset_processor()


@pytest.fixture
def sample_data_spec():
    """Create a sample DataSpecIntent for testing."""
    return DataSpecIntent(
        dataset_id="test_dataset",
        symbols=["MNQ", "MXF"],
        timeframes=["60m", "120m"],
        start_date=date(2020, 1, 1),
        end_date=date(2024, 12, 31)
    )


@contextlib.asynccontextmanager
async def managed_processor(queue):
    """
    Context manager to ensure processor is stopped even if tests fail.
    This prevents hangs caused by unclosed background tasks.
    
    CRITICAL: Includes a hard timeout shield for stop() to prevent CI hangs.
    """
    processor = StateProcessor(queue)
    await processor.start()
    try:
        yield processor
    finally:
        # Force stop with hard timeout to prevent deadlock in teardown.
        # If the processor code is buggy and hangs on stop, we kill it here
        # so pytest can finish and report the results.
        try:
            await asyncio.wait_for(processor.stop(), timeout=2.0)
        except (asyncio.TimeoutError, Exception) as e:
            print(f"WARNING: Processor stop forced/timed out: {e}")


def test_ui_only_creates_intents():
    """Test that UI code only creates intents, doesn't execute logic."""
    bridge = IntentBridge()
    
    # UI creates intents through bridge
    data_spec = bridge.create_data_spec_intent(
        dataset_id="test",
        symbols=["MNQ"],
        timeframes=["60m"]
    )
    
    intent = bridge.create_job_intent(
        season="2024Q1",
        data1=data_spec,
        data2=None,
        strategy_id="test",
        params={}
    )
    
    # Intent should be created but not executed
    assert intent.intent_type.value == "create_job"
    assert intent.status == IntentStatus.PENDING
    assert intent.result is None


@pytest.mark.anyio
async def test_single_consumer_sequential(clean_system, sample_data_spec):
    """Test that StateProcessor is single consumer (sequential execution)."""
    with anyio.fail_after(10):
        queue = ActionQueue()
        
        async with managed_processor(queue) as processor:
            # Submit multiple intents
            intent_ids = []
            for i in range(5):
                intent = CalculateUnitsIntent(
                    season=f"2024Q{i}",
                    data1=sample_data_spec,
                    data2=None,
                    strategy_id="sma_cross_v1",
                    params={"window_fast": i}
                )
                intent_id = queue.submit(intent)
                intent_ids.append(intent_id)
            
            # Wait for all to complete
            for intent_id in intent_ids:
                completed = await queue.wait_for_intent_async(intent_id, timeout=5.0)
                assert completed is not None
                # Even if they fail due to missing data, they are 'processed'
                assert completed.status in (IntentStatus.COMPLETED, IntentStatus.FAILED)
            
            # Check that they were processed
            metrics = queue.get_metrics()
            assert metrics["processed"] == 5


@pytest.mark.anyio
async def test_concurrent_ui_submissions(clean_system, sample_data_spec):
    """Test that concurrent UI submissions don't cause race conditions."""
    with anyio.fail_after(10):
        queue = ActionQueue()
        
        async with managed_processor(queue) as processor:
            # Simulate multiple UI threads submitting intents concurrently
            results = []
            errors = []
            
            async def ui_thread_submit(thread_id: int):
                """Simulate a UI thread submitting intents."""
                try:
                    # UI creates intent
                    intent = CalculateUnitsIntent(
                        season=f"2024Q{thread_id}",
                        data1=sample_data_spec,
                        data2=None,
                        strategy_id="sma_cross_v1",
                        params={"window_fast": thread_id}
                    )
                    
                    # Submit to queue
                    intent_id = queue.submit(intent)
                    
                    # Wait for result
                    completed = await queue.wait_for_intent_async(intent_id, timeout=5.0)
                    if completed and completed.status in (IntentStatus.COMPLETED, IntentStatus.FAILED):
                        results.append((thread_id, completed.result))
                    else:
                        errors.append((thread_id, "Failed or Timed out"))
                        
                except Exception as e:
                    errors.append((thread_id, str(e)))
            
            # Launch multiple UI threads
            tasks = [ui_thread_submit(i) for i in range(10)]
            await asyncio.gather(*tasks)
            
            # All should succeed without race conditions
            assert len(errors) == 0
            assert len(results) == 10
            
            # Check that queue processed all intents
            metrics = queue.get_metrics()
            assert metrics["processed"] == 10


def test_immutable_state_snapshots():
    """Test that UI only reads immutable state snapshots."""
    from FishBroWFS_V2.core.state import create_initial_state
    
    # Create initial state
    state = create_initial_state()
    
    # UI reads state (this is allowed)
    total_jobs = state.metrics.total_jobs
    is_healthy = state.is_healthy
    
    # UI cannot modify state (should raise exception or rely on dataclass frozen=True)
    # Note: If models aren't frozen, we rely on convention/architecture
    # But here we verify the read values are correct
    assert state.metrics.total_jobs == total_jobs
    assert state.is_healthy == is_healthy


@pytest.mark.anyio
async def test_state_consistency_during_concurrent_reads(clean_system, sample_data_spec):
    """Test that concurrent state reads are consistent."""
    with anyio.fail_after(10):
        queue = ActionQueue()
        
        async with managed_processor(queue) as processor:
            # Submit a job to change state
            intent = CreateJobIntent(
                season="2024Q1",
                data1=sample_data_spec,
                data2=None,
                strategy_id="sma_cross_v1",
                params={"window_fast": 10}
            )
            
            intent_id = processor.submit_intent(intent)
            
            # Multiple UI threads reading state concurrently
            read_values = []
            
            async def ui_thread_read(thread_id: int):
                """UI thread reads state."""
                # Get state snapshot
                state = processor.get_state()
                read_values.append((thread_id, state.metrics.total_jobs))
            
            # Launch concurrent reads
            tasks = [ui_thread_read(i) for i in range(10)]
            await asyncio.gather(*tasks)
            
            # All reads should see consistent state
            # (either all see initial state or all see updated state, usually initial)
            unique_values = set(value for _, value in read_values)
            assert len(unique_values) == 1
            
            # Wait for intent to complete
            completed_intent = await processor.wait_for_intent(intent_id, timeout=5.0)
            
            # Handle timeout case (wait_for_intent returns None on timeout)
            if completed_intent is None:
                # Debug: get current state to understand what happened
                st = processor.get_state()
                print("DEBUG: wait_for_intent timed out; state:", st)
                pytest.fail("wait_for_intent timed out (must never hang; must resolve or fail deterministically)")
            
            # Now check final state
            final_state = processor.get_state()
            
            # NOTE: In headless test without real data, job creation will FAIL validation.
            # So total_jobs will remain 0, but failed_count in queue should increase.
            # We check intent status to determine what to expect.
            if completed_intent.status == IntentStatus.FAILED:
                # Expect failure recorded in queue metrics, but not necessarily in business metrics (total_jobs)
                assert final_state.intent_queue.failed_count >= 1
            else:
                # If by some miracle it passed validation (e.g. if mocked)
                assert final_state.metrics.total_jobs == 1


def test_intent_bridge_singleton():
    """Test that IntentBridge is singleton."""
    bridge1 = get_intent_bridge()
    bridge2 = get_intent_bridge()
    
    assert bridge1 is bridge2


@pytest.mark.anyio
async def test_bridge_concurrent_usage(clean_system):
    """Test IntentBridge with concurrent UI access."""
    with anyio.fail_after(10):
        bridge = IntentBridge()
        
        # Start processor (bridge manages its own processor lifecycle)
        await bridge.start_processor()
        
        try:
            # Multiple UI threads using bridge concurrently
            results = []
            
            async def ui_thread_use_bridge(thread_id: int):
                """UI thread uses bridge."""
                # Create data spec
                data_spec = bridge.create_data_spec_intent(
                    dataset_id=f"dataset_{thread_id}",
                    symbols=["MNQ"],
                    timeframes=["60m"]
                )
                
                # Create calculation intent
                intent = bridge.calculate_units_intent(
                    season=f"2024Q{thread_id}",
                    data1=data_spec,
                    data2=None,
                    strategy_id="test",
                    params={"param": thread_id}
                )
                
                # Submit and wait
                completed = await bridge.submit_and_wait_async(intent, timeout=5.0)
                # Both COMPLETED and FAILED are valid outcomes of "processing"
                if completed and completed.status in (IntentStatus.COMPLETED, IntentStatus.FAILED):
                    results.append((thread_id, completed.result))
            
            # Launch concurrent UI threads
            tasks = [ui_thread_use_bridge(i) for i in range(5)]
            await asyncio.gather(*tasks)
            
            # All should succeed (in terms of getting a response)
            assert len(results) == 5
            
        finally:
            await bridge.stop_processor()


def test_no_direct_backend_imports():
    """Test that UI modules shouldn't import backend logic directly."""
    import sys
    
    # Check that intent_bridge doesn't expose backend logic
    # Note: We need to ensure the module is loaded
    import FishBroWFS_V2.gui.adapters.intent_bridge
    bridge_module = sys.modules['FishBroWFS_V2.gui.adapters.intent_bridge']
    
    # Bridge should not expose backend functions directly
    assert not hasattr(bridge_module, 'create_job_from_wizard_direct')
    assert not hasattr(bridge_module, 'calculate_units_direct')
    
    # Bridge should expose intent creation methods
    assert hasattr(bridge_module, 'IntentBridge')
    assert hasattr(bridge_module, 'get_intent_bridge')


@pytest.mark.anyio
async def test_race_condition_prevention(clean_system, sample_data_spec):
    """Test that race conditions are prevented by design."""
    with anyio.fail_after(10):
        queue = ActionQueue()
        
        async with managed_processor(queue) as processor:
            # Simulate race condition scenario:
            # Multiple UI threads trying to create jobs for same season/dataset
            
            created_job_ids = set()
            lock = threading.Lock()
            
            async def race_condition_thread(thread_id: int):
                """Thread that could cause race condition in traditional system."""
                # All threads use same parameters (potential race)
                intent = CreateJobIntent(
                    season="2024Q1",  # Same season
                    data1=sample_data_spec,  # Same data
                    data2=None,
                    strategy_id="sma_cross_v1",
                    params={"window_fast": 10}
                )
                
                # Submit intent
                intent_id = processor.submit_intent(intent)
                completed = await processor.wait_for_intent(intent_id, timeout=5.0)
                
                if completed and completed.status == IntentStatus.COMPLETED:
                    job_id = completed.result.get("job_id")
                    if job_id:
                        with lock:
                            created_job_ids.add(job_id)
            
            # Launch many threads simultaneously
            tasks = [race_condition_thread(i) for i in range(20)]
            await asyncio.gather(*tasks)
            
            # 1. All intents should be processed
            state = processor.get_state()
            # Since these are duplicates, most will be rejected or failed.
            # But total processed (completed + failed) should be 20.
            # Note: Depending on implementation, duplicates might be 'rejected' before processing
            # or 'processed' and failed.
            
            metrics = queue.get_metrics()
            # Ensure we processed something
            assert metrics["processed"] > 0